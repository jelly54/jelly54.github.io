<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[synchronized的锁升级、锁膨胀]]></title>
    <url>%2Fjava-lock-upgrade%2F</url>
    <content type="text"><![CDATA[本文将将讲解java中synchronized从偏向锁逐步走到轻量级锁、自旋锁再到重量级锁的过程，以及java8中的锁降级优化。 偏向锁 轻量级锁 自旋锁 重量级锁 锁降级 为什么锁信息存放在对象头里 偏向锁偏向第一个拿到锁的线程。 即第一个拿到锁的线程，锁会在对象头Mark Word中通过CAS记录线程ID，该线程以后每次拿锁时都不需要进行CAS（指轻量级锁）。 如果该线程正在执行同步代码块时有其他线程在竞争（指其他线程尝试CAS让Mark Work设置自己的线程ID），会被升级为轻量级锁。 如果其他线程发现Mark Word里记的不是自己，且发现原持有偏向锁的线程已经执行完同步代码块，会尝试CAS把Mark Word中的改为自己的线程ID。 轻量级锁轻量级锁就是通过CAS进行加锁的。 JVM会给线程的栈帧中创建一个叫锁记录Lock Record的空间，把对象头Mark Word复制到该空间里（Displaced Mark Word），并通过CAS尝试把原对象头Mark Word中锁记录指针指向该锁记录。如果成功，表示线程拿到了锁。如果失败，则进行自选（自旋锁），自旋超过一定次数时升级为重量级锁，这时该线程会被内核挂起。 自旋锁轻量级锁膨胀为重量级锁前，线程在执行monitorenter指令进入等待队列时，会通过自旋去尝试获得锁。 如果自旋超过一定次数时还未拿到锁，就会进入阻塞状态，等待内核来调度。此时会发生内核态与用户态之间的上下文切换，所以会影响性能（引入自旋锁就是为了减少这个开销）。 因为后面的线程也进行自选尝试获取锁，所以这对于已被阻塞的那些线程来说，会不公平。 重量级锁重量级锁就是通过内核来操作线程。因为频繁出现内核态与用户态的切换，会严重影响性能。 升级为重量级锁时会在堆中创建monitor对象，并将Mark Work指向该monitor对象。monitor中有cxq（ContentionList），EntryList，WaitSet，owner 锁降级Hotspot在1.8开始有了锁降级。在STW期间JVM进入安全点时如果发现有闲置的monitor（重量级锁对象），就会进行锁降级。 为什么锁信息存放在对象头里死磕Sunchronized底层实现–概论中： 因为在Java中任意对象都可以用作锁，因此必定要有一个映射关系，存储该对象以及其对应的锁信息（比如当前哪个线程持有锁，哪些线程在等待）。一种很直观的方法是，用一个全局map，来存储这个映射关系，但这样会有一些问题：需要对map做线程安全保障，不同的sunchronized之间会互相影响，性能差；另外当同步对象较多时，该map可能会占用比较多的内存。 所以最好的办法是将这个映射关系存储在对象头中，因为对象头本身也有一些hashcode、GC相关的数据，所以如果能将锁信息与这些信息共存在对象头中就好了。 也就是说，如果用一个全局map来存对象的锁信息，还需要对该map做线程安全处理，不同的锁之间会有影响，所以直接存到对象头。]]></content>
      <categories>
        <category>Java锁</category>
      </categories>
      <tags>
        <tag>java锁升级</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[断点续传小解]]></title>
    <url>%2Fnet-break-transport%2F</url>
    <content type="text"><![CDATA[断点续传的原理HTTP 协议是互联网上应用最广泛网络传输协议之一，它基于 TCP/IP 通信协议来传递数据。断点续传的奥秘就隐藏在这 HTTP 协议中了。 我们知道HTTP请求会有一个Request header 和 Response header，在请求头里边有个和Range相关的参数 当下载文件的时候，response header会有如下: 12345Content-Length: 65804256 // 请求的文件的大小，单位 byteAccept-Ranges: bytes // 是否允许指定传输范围，bytes：范围请求的单位是 bytes （字节），none：不支持任何范围请求单位，Last-Modified: Tue, 07 Jul 2020 13:19:46 GMT // 服务端文件最后修改时间，可以用于校验文件是否更改过x-bs-meta-crc32: 3545941535 // crc32，可以用于校验文件是否更改过ETag: dcd0bfef7d90dbb3de50a26b875143fc //Etag 标签，可以用于校验文件是否更改过 可见并不是所有的下载都支持断点续传，只有在response header中有 Accpet-Ranges: bytes字段时，才可以断点续传。 如何使用利用content-range字段，就可以实现断点续传了。只需要在response header中指定Content-Range值就可以了。 使用方式如下： 1234Content-Range: &lt;unit&gt;=&lt;range-start&gt;-&lt;range-end&gt;/&lt;size&gt; // size 为文件总大小,如果不知道可以用 *Content-Range: &lt;unit&gt;=&lt;range-start&gt;-&lt;range-end&gt;/* Content-Range: &lt;unit&gt;=&lt;range-start&gt;-Content-Range: &lt;unit&gt;=*/&lt;size&gt; 举例说明单位 bytes，从第 10 个 bytes 开始下载 1Content-Range: bytes=10- 单位 bytes，从第 10 个 bytes 开始下载，下载到第100个 bytes 1Content-Range: bytes=10-100 重启续传文件时保证文件一致性下载中，如何保证文件的完整性？我们要写的下载器是支持断点续传的，那么在进行续传时，怎么确定文件从我们上次下载时没有进行更新呢？这里通过response header中的几个属性值进行判断。 123Last-Modified: Tue, 07 Jul 2020 13:19:46 GMT // 服务端文件最后修改时间，可以用于校验文件是否更改过ETag: dcd0bfef7d90dbb3de50a26b875143fc //Etag 标签，可以用于校验文件是否更改过x-bs-meta-crc32: 3545941535 // crc32，可以用于校验文件是否更改过 ETag: 根据 HTTP 协议的规定，当文件更新时，是会生成新的 ETag 值的，它类似于文件的指纹信息 Last-Modified: 只是上次修改时间，有时候可能并不能够证明文件内容被修改过 写入阶段，如何保证文件顺序?不管单线程还是多线程，由于要断点续传，在写入时都要在指定位置进行字符追加。 在Java中使用RandomAccessFile类，它可以在使用时指定读写模式，使用 seek 方法可以随意移动要操作的文件指针位置。很适合断点续传的写入场景。使用它你可以快速定位到已知的位置，进行快速检索；也可以在同一个文件的不同位置进行并发读写。 举个例子在 aaa.text 文件中的位置 0 开始写入字符 abcdef，在位置 100 的位置开始写入字符 ddeeff。 12345678// rw 为读写模式try (RandomAccessFile rw = new RandomAccessFile(&quot;test.txt&quot;, &quot;rw&quot;))&#123; // 移动文件内容指针位置 rw.seek(0); rw.writeChars(&quot;abc&quot;); rw.seek(100); rw.writeChars(&quot;ddd&quot;);&#125; 网速贷宽固定，为什么多线程下载可以提速最大网速是固定的，运营商给你 100Mbs的网速，不管你怎么使用，速度最大也就是100/8=12.5MB/s。那么为什么多线程下载可以提高下载速度呢? 理论上来说，单线程下载就可以达到最大的理想网速，但是事实是，网络经常不那么通畅，很难达到理想的最大速度，也就是说只有在网路不那么通畅的时候，多线程下载才能提速。 多线程下载提速原因HTTP 协议在传输时候是基于 TCP 协议传输数据的，TCP 协具有拥塞控制机制。拥塞控制 是TCP 的一个避免网络拥塞的算法，它是基于和性增长/乘性降低这样的控制方法来控制拥塞的。 简单来说就是在 TCP 开始传输数据时，服务端会不断的探测可用带宽。在一个传输内容段被成功接收后，会加倍传输两倍段内容，如果再次被成功接收，就继续加倍，直到发生了丢包，这是这也被叫做慢启动。当达到慢启动阀值（ssthresh）时，慢启动算法就会转换为线性增长的阶段，每次只增加一个分段，放缓增加速度。我觉得其实慢启动的加倍增速过程并不慢，只是一种叫法。 但是当发生了丢包，也就是检测到拥塞时，发送方就会将发送段大小降低一个乘数，比如二分之一，慢启动阈值降为超时前拥塞窗口的一半大小、拥塞窗口会降为1个MSS，并且重新回到慢启动阶段。这时多线程的优势就体现出来了，因为你的多线程会让这个速度减速没有那么猛烈，毕竟这时可能有另一个线程正处在慢启动的在最终加速阶段，这样总体的下载速度就优于单线程了。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存数据库双写不一致问题]]></title>
    <url>%2Fcache-database-cons%2F</url>
    <content type="text"><![CDATA[Cache Aside Pattern 读的时候，先读缓存，缓存没有的话，那么就读数据库，然后取出数据后放入缓存，同时返回响应。 更新的时候先删除缓存，然后再更新数据库 为什么删除而不是更新缓存原因很简单，很多时候，复杂点的缓存的场景，因为缓存有的时候，不简单是数据库中直接取出来的值。 如：商品详情页的系统，修改库存，只是修改了某个表的某些字段，但是要得到最终的库存，可能还需要从其他表查询一些数据，然后进行一些复杂的运算，才能最终计算出现在最新的库存是多少，然后才能将库存更新到缓存中去。 有很多数据并不是热数据，可能更新之后很久不会被访问，修改时更新缓存，反而增加了系统负荷。修改数据的时候，只删除缓存，不用每次都重新做复杂的计算，再下次使用它的时候再进行计算并缓存。 缓存数据库双写不一致？初级的缓存不一致问题先修改数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据出现不一致。 解决思路先删除缓存，再修改数据库。如果删除缓存成功了，如果修改数据库失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。 因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中。 较复杂的数据不一致问题数据发生变更，先删除了缓存，然后要去修改数据库，此时还没修改。 一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中， 数据变更的程序完成了数据库的修改 完了，数据库和缓存中的数据不一样了。。。。 数据库与缓存更新与读取操作进行异步串行化 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部的队列中。 读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个jvm内部的队列中。 一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。 一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新，此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。 优化点：一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。 待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。 如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回; 如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。 高并发的场景下，该解决方案要注意的问题弊端一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况 串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。 读请求长时阻塞由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回 该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库 务必通过一些模拟真实的测试，看看更新数据的频繁是怎样的 另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作 如果一个内存队列里居然会挤压100个商品的库存修改操作，每隔库存修改操作要耗费10ms区完成，那么最后一个商品的读请求，可能等待10 * 100 = 1000ms = 1s后，才能得到数据，这个时候就导致读请求的长时阻塞 一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会hang多少时间，如果读请求在200ms返回，如果你计算过后，哪怕是最繁忙的时候，积压10个更新操作，最多等待200ms，那还可以的 如果一个内存队列可能积压的更新操作特别多，那么你就要加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少 其实根据之前的项目经验，一般来说数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的 针对读高并发，读缓存架构的项目，一般写请求相对读来说，是非常非常少的，每秒的QPS能到几百就不错了 一秒，500的写操作，5份，每200ms，就有100个写操作 单机器，20个内存队列，每个内存队列，可能就积压5个写操作，每个写操作性能测试后，一般在20ms左右就完成 那么针对每个内存队列中的数据的读请求，也就最多hang一会儿，200ms以内肯定能返回了 写QPS扩大10倍，但是经过刚才的测算，就知道，单机支撑写QPS几百没问题，那么就扩容机器，扩容10倍的机器，10台机器，每个机器20个队列，200个队列 大部分的情况下，应该是这样的，大量的读请求过来，都是直接走缓存取到数据的 少量情况下，可能遇到读跟数据更新冲突的情况，如上所述，那么此时更新操作如果先入队列，之后可能会瞬间来了对这个数据大量的读请求，但是因为做了去重的优化，所以也就一个更新缓存的操作跟在它后面 等数据更新完了，读请求触发的缓存更新操作也完成，然后临时等待的读请求全部可以读到缓存中的数据 读请求并发量过高这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时hang在服务上，看服务能不能抗的住，需要多少机器才能抗住最大的极限情况的峰值 但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大 按1:99的比例计算读和写的请求，每秒5万的读QPS，可能只有500次更新操作 如果一秒有500的写QPS，那么要测算好，可能写操作影响的数据有500条，这500条数据在缓存中失效后，可能导致多少读请求，发送读请求到库存服务来，要求更新缓存 一般来说，1:1，1:2，1:3，每秒钟有1000个读请求，会hang在库存服务上，每个读请求最多hang多少时间，200ms就会返回 在同一时间最多hang住的可能也就是单机200个读请求，同时hang住 单机hang200个读请求，还是ok的 1:20，每秒更新500条数据，这500秒数据对应的读请求，会有20 * 500 = 1万 1万个读请求全部hang在库存服务上，就死定了 多服务实例部署的请求路由可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过nginx服务器路由到相同的服务实例上(服务间按照某个请求参数的hash路由) 热点商品的路由问题，导致请求的倾斜万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能造成某台机器的压力过大 就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以更新频率不是太高的话，这个问题的影响并不是特别大 但是的确可能某些机器的负载会高一些 缓存雪崩发生的现象 缓存雪崩的事前事中事后的解决方案 事前：redis高可用，主从+哨兵，redis cluster，避免全盘崩溃 事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL被打死 事后：redis持久化，快速恢复缓存数据 缓存穿透的现象 缓存穿透的解决方法每次系统a从数据库没有查到信息，就在缓存中存一个空值，这样下次就会走缓存而不是穿透到数据库。]]></content>
      <categories>
        <category>Cache</category>
      </categories>
      <tags>
        <tag>cache</tag>
        <tag>一致性问题</tag>
        <tag>缓存穿透</tag>
        <tag>缓存雪崩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么要使用缓存]]></title>
    <url>%2Fcache-why-use%2F</url>
    <content type="text"><![CDATA[为什么要用缓存结合以下两点说自己的项目。 高性能 假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作mysql，半天查出来一个结果，耗时600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？ 缓存啊，折腾600ms查出来的结果，扔缓存里，一个key对应一个value，下次再有人查，别走mysql折腾600ms了。直接从缓存里，通过一个key查出来一个value，2ms搞定。性能提升300倍。 这就是所谓的高性能。 就是把你一些复杂操作耗时查出来的结果，如果确定后面不咋变了，然后但是马上还有很多读请求，那么直接结果放缓存，后面直接读缓存就好了。 高并发 mysql这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql单机支撑到2000qps也开始容易报警了。 所以要是你有个系统，高峰期一秒钟过来的请求有1万，那一个mysql单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放mysql。缓存功能简单，说白了就是key-value式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发so easy。单机承载并发量是mysql单机的几十倍。 缓存常见问题1）缓存与数据库双写不一致2）缓存雪崩3）缓存穿透4）缓存并发竞争]]></content>
      <categories>
        <category>Cache</category>
      </categories>
      <tags>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql主从复制]]></title>
    <url>%2Fmysql-master-slave%2F</url>
    <content type="text"><![CDATA[基本原理slave会从master读取binlog来进行数据同步 三步骤 master将改变记录到二进制日志(binary log)。这些记录过程叫做二进制日志事件，binary log events; slave将master的binary log events拷贝到它的中继日志(relay log); slave重做中继日志中的事件，将改变应用到自己的数据库中。Mysql复制是异步的且串行化的 基本原则 每个slave只有一个master 每个slave只能有唯一的服务器ID 每个master可以有多个salve 最大问题延时 一主已从常见配置mysql版本一致且后台以服务运行；主从都配置在[mysqld]节点下，都是小写。 主机配置文件12345678910111213141516171819202122232425262728# 必须 服务器唯一IDserver-id=1# 必须 启用二进制日志# 如：log-bin=D:/Mysql5.5/data/mysqlbinlog-bin=自己的本地路径/mysqlbin# 可选 启用错误日志# 如：log-bin=D:/Mysql5.5/data/mysqlerrlog-err=自己的本地路径/mysqlerr# 可选 根目录basedir=&quot;D:/Mysql5.5/&quot;# 可选 临时目录tmpdir=&quot;D:/Mysql5.5/&quot;# 可选 数据目录datadir=&quot;D:/Mysql5.5/data/&quot;# 设置读写权限(主机应是读写都可)read-only=0# 可选 设置不要复制的数据库binlog-ignore-db=mysql# 可选 设置需要复制的数据库binlog-do-db=需要复制的主数据库名字 从机配置文件123# 必须 从服务器唯一ID# 可选 启用二进制日志 主机授权从机访问123456789# 授权GRANT REPLICATION SLAVE ON 数据库名.表名 TO 'username'@'从库IP' IDENTIFIED BY 'password';# 刷新权限flush privileges;# 查询主机状态, 记录下File和Position的值# 每次配置都需要记录新的File和Position的值。show master status; 从机设置访问账户12345678910# 设置访问主机的账户、数据起始位置等CHANGE MASTER TO MASTER_HOST='主机IP', MASTER_USER='username', MASTER_PASSWORD='password', MASTER_LOG_FILE='mysqlbin.具体数字', MASTER_LOG_POS=具体数值;# 开启服务器复制功能start slave;# 查询从机状态。以下两个参数都是Yes说明配置成功# Slave_IO_Running:Yes# Slave_SQL_Running:Yesshow slave status\G 停止从机复制服务1stop slave;]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>主从架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql锁]]></title>
    <url>%2Fmysql-lock%2F</url>
    <content type="text"><![CDATA[概述定义锁是计算机协调多个进程或县城并发访问某一资源的机制。 在数据库中，除传统的计算资源(如CPU、RAM、I/O等)的争用之外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据并发访问性能的一个重要因素。从这个角度来说，锁对数据库显得尤为重要，也更复杂。 分类从数据的操作的类型(读/写)分读锁(共享锁)：针对同一份数据，多个读操作是可以同时进行而互相不影响。 写锁(排它锁)：当前写操作没有完成前，它会阻断其他写锁和读锁。 从数据的操作粒度分表锁偏向MyISAM存储引擎，开销小，加锁快；无死锁；锁力度大，发生锁冲突的概率最高，并发度最低。 12345678# 手动加锁 lock table 表名字 read(write), 表名字2; read(write)# 查看表上加过的锁show open tables;# 释放表锁unlock tables; session1 对A表加读锁。 session1 可以读A表，不能读别的表，不能写当前表。 session2 可以读A表，可以读或写别的表。但是对A进行写时会一直阻塞，等待获取锁。 行锁偏向InnoDB存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度最高。 InnoDB与MyISAM最大的不同点： 支持事务(TRANSACTION) 采用了行级锁 事务及其ACID属性事务事务是由一组SQL语句组成的逻辑处理单元，事务具有以下四个属性，通常简称为事务的ACID属性。 Atomicity(原子性)： 事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。 Consistent(一致性)： 在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完善性；事务结束时所有的内部数据结构(如B数索引或双向链表)也都必须是正确得。 Isolation(隔离性)： 数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部都是不可见的，反之亦然。 Durable(持久性)： 事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 并发事务带来的问题更新丢失(Lost Update)当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会出现丢失问题–最后的更新覆盖了由其他事务所做的更新。 脏读(Dirty Reads)一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取这条记录，如果不加控制，第二个事务读取了这些“脏数据”，并据此做进一步的处理，就会产生未提交的数据依赖关系。 事务A读取到事务B已经修改但尚未提交的数据，还在这个数据基础上做了操作。此时，如果B事务回滚，A读取的数据无效，不符合一致性要求。 不可重复读(Non-Repeatable Reads)一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变，或某些记录已经被删除。 事务A读取到了事务B已经提交的修改数据，不符合隔离性。 幻读(Phantom Reads)一个事务按照相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据。 事务A读取到了事务B提交的新增的数据，不符合隔离性。 事务隔离级别 读数据一致性及允许的并发副作用隔离级别 读数据一致性 脏读 不可重复读 幻读 未提交读(Read uncommitted) 最低级别，只能保证不读取物理上被损坏的数据 是 是 是 已提交读(Read committed) 语句级 否 是 是 可重复读(Repeatable read) 事务级 否 否 是 可序列化(Serializable) 最高级别，事务级 否 否 否 12# 查看当前数据库的事务隔离级别show variables like 'tx_isolation;' 数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大。因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然于“并发”是矛盾的。同时，不同的应用对读一致性和事务隔离程度的要求也是不同的。比如，许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。 索引失效行锁变表锁间隙锁当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但不存在的记录，叫做“间隙(GAP)”, InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁(Next-Key锁)。 危害：因为Query执行过程中通过范围查找的话，他会索订整个范围内所有的索引键值，即使这个键值并不存在。间隙锁有一个比较致命的弱点，就是 当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入索订键值范围内的任何数据。 如何锁定一行123456mysql&gt; begin;# for update 锁定某一行之后，其他操作会被阻塞，直到锁定行的会话提交commitmysql&gt; select * from xx_table where a=8 for update;mysql&gt; commit; 锁状态量分析可通过检查INNODB_ROW+LOCK状态量来分析系统上的行锁的情况。 12345678910111213141516mysql&gt; show status like 'innodb_row_lock%;'# 状态量说明innodb_row_lock_current_waits: 当前正在等待锁的数量innodb_row_lock_time:从系统启动到现在锁定 总时间长度。innodb_row_lock_time_avg: 每次等待所花平均时间，innodb_row_lock_time_max:从系统启动到现在等待这段时间innodb_row_lock_waits:系统启动后到现在总共等待的次数。# 尤其是当等待次数很高，而且每次等待时间也不小的时候# 我们就需要 **分析系统之中为什么会有如此多的等待，然后根据分析结果着手指定优化计划**。 优化建议 尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁。 合理设计索引，尽量缩小锁的范围 尽可能较少检索条件，避免间隙锁。 尽量控制事务大小，减少锁定资源量和时间长度。 尽可能低级别事务隔离。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql全局日志]]></title>
    <url>%2Fmysql-global-log%2F</url>
    <content type="text"><![CDATA[永远不要再生产环境开启这个功能 配置启用 my.cnf 12345678# 开启general_log=1# 记录日志文件的路径general_log_file=/path/logfile# 输出格式log_output=FILE 编码启用 1234567# 开启mysql&gt; set global general_log=1mysql&gt; set global log_output='TABLE';# 之后所编写的sql语句，将会记录到mysql库里的general_log表，可以用以下命令查看mysql&gt; select * from mysql.general_log;]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql show profile用法]]></title>
    <url>%2Fmysql-show-profile%2F</url>
    <content type="text"><![CDATA[是什么show profile是mysql提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于sql调优的测量。 默认情况下，参数处于关闭状态，并保存最近15次的运行结果 分析步骤是否支持查看当前mysql版本是否支持 1show variables like 'profiling'; 开启功能默认是关闭的，使用前需要开启 1set profiling = on; 运行sql指生产环境或者测试的sql查询、更新等 查看结果1show profiles; 诊断sql12345678910111213# x 为上一步中查询的id。show profile cpu, block io for query x; # 可选参数：all -- 显示所有的开销block io -- 显示块IO相关开销context switches -- 上下文切换相关开销cpu -- 显示cpu相关开销信息ipc -- 显示发送和接受相关开销信息memory -- 显示内存相关开销信息page faults -- 显示页面错误相关开销信息source -- 显示和source_function, source_file, source_line相关的开销信息swaps -- 显示交换次数相关开销信息 注意12345678910# 查询结果太大，内存都不够用了，转向磁盘converting HEAP to MyISAM # 创建临时表(拷贝数据到临时表，用完再删除)creating tmp table # 把内存中临时表复制到磁盘，危险！copying to tmp table on disk# lock]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-bulk]]></title>
    <url>%2Fmysql-bulk%2F</url>
    <content type="text"><![CDATA[函数：有返回值存储过程：无返回值 sql: create table、create index、create function、create view 设置参数 创建函数，如果报错: This function has none of DETERMINISTIC…由于开启过 慢查询日志，因为我们开启了bin-log，我们必须为我们的function指定一个参数 123show variables like 'log_bin_trust_function_creators';set global log_bin_trust_function_creators=1; 这样添加了参数以后，如果mysql重启，上述参数会消失，写入配置文件my.cnf，可以永久有效。 12[mysqld]log_bin_trust_function_creators=1 创建函数创建一个产生随机字符串的函数 123456789101112DELIMITER $$CREATE FUNCTION rand_string(n INT) RETURNS VARCHAR(255)BEGIN DECLARE chars_str VARCHAR(100) DEFAULT 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'; DECLARE return_str VARCHAR(255) DEFAULT ''; DECLARE i INT DEFAULT 0; WHILE i &lt; n DO SET return_str = CONCAT(return_str, SUBSTRING(chars_str, FLOOR(1+rand()*52),1)); SET i = i+1; END WHILE; RETURN return_strEND $$ 创建一个产生随机数的函数 12345678DELIMITER $$CAEATE FUNCTION rand_num()RETURNS INT(5)BEGIN DECLARE i INT DEFAULT 0; SET i = FLOOR(100+RAND()*10); RETURN i;END $$ 删除函数 1DROP FUNCTION function_name; 创建存储过程12345678910111213# 存储过程可以调用函数，如下面的INSERT 语句中调用 rand_string()、rand_num()函数。DELIMITER $$CREATE PROCEDURE insert_emp (IN strat INT(10), IN max_num INT(10))BEGIN DECLARE i INT DEFAULT 0; SET autocommit = 0; REPEAT SET i = i+1; INSERT INTO XXX (name,age,no) VALUES (rand_string(6),X,rand_num()) UNTIL i = max_num END REPEAT; COMMIT;END $$ 删除存储过程 1DROP PROCEDURE procedure_name; 调用存储过程DELIMITER ; CALL insert_emp(100, 10);]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>批量数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql慢查询]]></title>
    <url>%2Fmysql-slow-query%2F</url>
    <content type="text"><![CDATA[慢查询是什么Mysql的慢查询日志是Mysql提供的一种日志记录，它用来记录在Mysql中响应时间超过阀值的语句。 具体指运行时间超过long_query_time值的sql，则会被记录到慢查询日志中。long_query_time默认是10s。 如何玩默认情况下，Mysql数据库没有开启慢查询日志，需要我们手动来设置这个参数。 当然，如果不是调优需要的话，一般不建议启动该参数，因为慢查询日志会或多或少代来一些性能影响。慢查询日志支持将日志记录写入文件。 查看当前是否开启123456mysql&gt; SHOW VARIABLES LIKE '%slow_query_log%';Variables_name | Valueslow_query_log | OFFslow_query_log_file | /var/lib/mysql/slow.log2 rows in set (0.00 sec) 开启123456789# 使用以下语句只对当前数据库生效，mysql重启后则失效set global_slow_query_log=1;# 永久生效，修改配置文件my.cnf(增加或修改以下两个字段)# 如果没有指定 slow_query_log_file，系统默认host_name-slow.log# 重启mysql服务。[mysqld]slow_query_log=1slow_query_log_file=/var/lib/mysql/slow.log 参数修改1234567891011# 默认查询时间超过这个参数的时间，就会被记录到慢查询日志中。默认为10smysql&gt; SHOW VARIABLES LIKE 'long_query_time%';long_query_time | 10.000000# 可以通过set 在当前数据库生效，mysql重启后失效。也可以在my.cnf中修改。set global long_query_time=3;注： 此时需要重新开一个会话才能看到修改的值。 模拟慢查询12# 模拟一个4s的查询sqlselect sleep(4); 日志分析工具mysqldumpslow1234567891011121314mysqldumpslow --help-s: 是表示访问按照何种方式排序 c: 访问次数 l: 锁定时间 r: 返回记录数 t: 查询时间al: 平均锁定时间ar: 平均返回记录数at: 平均查询时间-t: 即为返回前边多少条的数据-g: 后边搭配一个正则匹配模式，大小写不敏感 常用场景1234567891011# 得到返回记录集最多的10个SQLmysqldumpslow -s r -t 10 /var/lib/mysql/host_name-slow.log# 得到访问次数最多的10个SQLmysqldumpslow -s c -t 10 /var/lib/mysql/host_name-slow.log# 得到按照时间排序的前10条里边含有做链接的查询语句mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/lib/mysql/host_name-slow.log# 建议在使用这些命令时结合| 和 more 使用，否则可能出现爆屏mysqldumpslow -s r -t 10 /var/lib/mysql/host_name-slow.log | more]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>慢查询</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql查询优化]]></title>
    <url>%2Fmysql-query-optimization%2F</url>
    <content type="text"><![CDATA[优化一般性流程 观察。至少跑一天，看看生产的慢sql 开启慢查询日志，设置阙值，比如超过5s的就是慢sql，将它竹取出来 explain + 慢sql分析 show profile 运维经理 or DBA，进行数据库服务器的参数调优 === 总结 慢查询的开启并捕获 expain + 慢SQL分析 show profile查询SQL在MySQL服务器里的执行细节和生命周期情况 SQL数据库服务器的参数调优 小表驱动大表小的数据集驱动大的数据集当B表的数据集小于A表的数据集时，用in 优于 exists。如下: 12345SELECT * FRON A WHERE id IN (SELECT id FROM B);等价于for select id fromfor select * from A where A.id = B.id 当A表的数据集小于B表数据集时，用exist 优于 in。如下： 12345SELECT * FROM A WHERE EXISTS (SELECT 1 FROM B WHERE B.id = A.id)等价于for select * from Afor select * from B where B.id = A.id 注：A表，B表ID字段应建立索引 提示 EXISTS(subquery)只返回True 或 False，因此子查询中的SELECT * 也可以是SELECT 1 或 SELECT ‘x’, 官方说实际执行时会忽略select 清单，因此没有区别。 EXISTS 子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比，如果担忧效率问题，可进行实际检验以确定是否有效率问题。 EXISTS子查询往往也可以用条件表达式、其他子查询或者JOIN来替代，何种最优需要具体问题具体分析 Order by 优化尽量使用index方式排序，避免使用FileSort方式排序order by子句，尽量使用index方式排序，避免使用FileSort方式排序 Mysql支持两种方式的排序，FileSort和Index，Index效率高，它指Mysql扫描索引本身完成排序。FileSort方式效率低。 order by满足两种情况，会使用Index方式排序：①order by 语句使用索引最左前列②使用where子句与order by子句条件列组合满足索引最左前列。 遵照索引建的最佳左前缀尽可能在索引列上完成排序操作，遵照索引建的最佳左前缀 filesort有两种算法如果不在索引列上，filesort有两种算法:mysql启动双路排序和单路排序。 双路排序Mysql4.1 之前是使用双路排序，字面意思就是两次扫描磁盘，最终得到数据。读取行指针和orderby列，对他们进行排序，然后扫描已经排好序的列表，按照列表中的值重新从列表中读取对应的数据输出。 从磁盘取排序字段，在buffer进行排序，再从磁盘取其他字段。 单路排序从磁盘读取查询需要的所有列，按照orderby列在buffer对他们进行排序，然后扫描排序后的列表进行输出。他的效率更快一点，避免了第二次读取数据。并且把随机IO变成了顺序IO，但是它会使用更多的空间，因为他把每一行都保存在内存中了。 结论及引申出的问题 单路算法总体而言好过双路算法 单路算法中的问题。在sort_buffer中，方法B比方法A要占用更多空间，因为方法B是把所有字段都取出，所以有可能取出的数据的总大小超出了sort_buffer的容量，导致每次只能取sort_buffer容量大小的数据，进行排序(创建tmp文件，多路合并)，排完再取sort_buffer容量大小，再排···从而所赐I/O。 本来想省一次I/O操作，反而导致了大量的I/O操作，反而得不偿失。 优化策略 增大sort_buffer_size参数的设置 增大max_length_for_sort_data参数的设置 why? order by时select * 是一个大忌，应只查需要的字段，这点非常重要。这里会影响： 当query的字段大小总和小于max_length_for_sort_data而且排序字段不是TEXT||BLOB类型时，会用改进后的算法–单路排序，否则使用老算法-多路排序。 两种算法的数据都有可能超出sort_buffer的容量，超出之后，会创建tmp文件进行合并排序，导致多次I/O，但是用单路排序算法的风险会更大一些，所以要提高sort_buffer_size。 尝试提高sort_buffer_size不管使用哪种算法，提高这个参数都会提高效率，当然，要根据系统的能力去提高，因为这个参数是针对每个进程的。 尝试提高 max_length_for_sort_data提高这个参数，会增加使用改进算法的概率。但是吐过设的太高，数据总量超出sort_buffer_size的概率就增大，明显症状是 高的磁盘I/O活动 和 低的处理器使用率。 小总结为排序使用索引Mysql两种排序方式：文件排序或扫描优需索引排序Mysql能为排序与查询使用相同的索引 12345678910111213141516171819202122KEY a_b_c (a, b, c)# order by 能使用索引 最左前缀- ORDER BY a- ORDER BY a, b- ORDER BY a, b, c- ORDER BY a DESC, b DESC, c DESC (a,b,c排序都一致可以用索引)# 如果where使用索引的最左前缀定义为常量，则order by能使用索引- WHERE a = const ORDER BY b, c- WHERE a = const AND b=const ORDER BY c- WHERE a = const ORDER BY b, c- WHERE a = const AND b &gt; const ORDER BY b, c# 不能使用索引进行排序- ORDER BY a ASC, b DESC , c DESC /*排序不一致*/- WHERE g = const ORDER BY b, c /*丢失a索引*/- WHERE a = const ORDER BY c /*丢失b索引*/- WHERE a = const ORDER BY a,d /*d不是索引的一部分*/- WHERE a in (···) ORDER BY b, c /*对于排序来说，多个相等条件也是范围查询*/ Group by 优化group by 实质是先排序后进行分组，遵照索引建的最佳左前缀 当无法使用索引列，增大max_length_for_sort_data参数的设置 + 增大 sort_buffer_size参数的设置 where高于having，能写在where限定的条件就不要去having限定了]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>sql优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql索引]]></title>
    <url>%2Fmysql-index%2F</url>
    <content type="text"><![CDATA[简介定义索引是 一种特殊的文件 (InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里 所有记录的引用指针。 更通俗的说，数据库索引好比是一本书前面的目录，能加快数据库的查询速度。 索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的 。除了词典，生活中随处可见索引的例子，如火车站的车次表、图书的目录等。它们的原理都是一样的，通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。 作用在数据量和访问量不大的情况下，mysql访问是非常快的，是否加索引对访问影响不大。但是当数据量和访问量剧增的时候， 就会发现mysql变慢，甚至down掉，这就必须要考虑优化sql了，给数据库建立正确合理的索引，是mysql优化的一个重要手段。 在创建索引时，需要考虑哪些列会用于 SQL 查询，然后为这些列创建一个或多个索引。事实上，索引也是一种表，保存着主键或索引字段，以及一个能将每个记录指向实际表的指针。数据库用户是看不到索引的，它们只是用来加速查询的。数据库搜索引擎使用索引来快速定位记录。 INSERT 与 UPDATE 语句在拥有索引的表中执行会花费更多的时间，而SELECT 语句却会执行得更快。这是因为，在进行插入或更新时，数据库也需要插入或更新索引值。 Mysql索引结构 B-tree索引： Hash索引： Full-text全文索引： R-Tree索引： 使用分类INDEX(单值索引)允许出现相同的索引内容，一个索引只包含单个列，一个表可以有多个单列索引。 复合索引实质上是将多个字段建到一个索引里，列值的组合必须唯一。 UNIQUE(唯一索引)索引列的值必须唯一，可以有NULL值，NULL可以出现多次。 PRIMARY KEY(主键索引)不允许出现相同的值，不为NULL。 FULLTEXT INDEX(全文索引)可以针对值中的某个单词，但效率不高。 创建-删除-查看基本语法12345678910# 创建 CREATE [UNIQUE] INDEX indexName ON mytable(columnname(length));ALTER mytable ADD [UNIQUE] INDEX [indexName] ON (columnname(length));#删除 DROP INDEX [indexName] ON mytable;#查看 SHOW INDEX FROM table_name; 示例使用ALTER TABLE语句创建索性应用于表创建完毕之后再添加。 123456789101112ALTER TABLE 表名 ADD 索引类型 （unique,primary key,fulltext,index）[索引名]（字段名）# 普通索引ALTER TABLE table_name ADD INDEX index_name (column_list) ;# 复合索引ALTER TABLE table_name ADD INDEX index_name_name (column_list1,column_list2); # 唯一索引ALTER TABLE table_name ADD UNIQUE (column_list) ;# 主键索引ALTER TABLE table_name ADD PRIMARY KEY (column_list) ;# 全文索引ALTER TABLE tbl_name ADD FULLTEXT index_name(column_list): ALTER TABLE可用于索引，table_name 是要增加索引的表名，column_list 指出对哪些列进行索引，多列时各列之间用 逗号分隔。索引名index_name可选，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以同时创建多个索引。 使用CREATE INDEX语句对表增加索引CREATE INDEX可用于对表增加普通索引或UNIQUE索引，可用于建表时创建索引。 123456CREATE INDEX index_name ON table_name(username(length)); # 单值索引CREATE INDEX index_name ON table_name (column_list)# 唯一索引CREATE UNIQUE INDEX index_name ON table_name (column_list) table_name、index_name 和 column_list 具有与ALTER TABLE语句中相同的含义，索引名不可选。另外，不能用CREATE INDEX语句创建PRIMARY KEY索引。 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB(binary large object) 和TEXT类型，必须指定 length。 删除索引删除索引可以使用ALTER TABLE 或 DROP INDEX语句来实现。DROP INDEX可以在ALTER TABLE内部作为一条语句处理，其格式如下： 12345DROP INDEX index_name ON table_name ;ALTER TABLE table_name DROP INDEX index_name ;ALTER TABLE table_name DROP PRIMARY KEY ; 其中，在前面的两条语句中，都删除了table_name中的索引index_name。而在最后一条语句中，只在删除PRIMARY KEY索引中使用，因为一个表只可能有一个PRIMARY KEY索引，因此不需要指定索引名。如果没有创建PRIMARY KEY索引，但表具有一个或多个UNIQUE索引，则MySQL将删除第一个UNIQUE索引。 如果从表中删除某列，则索引会受影响。 对于多列组合的索引，如果删除其中的某列，则该列也会从索引中删除。如果删除组成索引的所有列，则整个索引将被删除。 – 探究组合索引&amp;左前缀原则组合索引和前缀索引是对建立索引技巧的一种称呼，并不是索引的类型 示例：1ALTER TABLE user_demo ADD INDEX name_city_age (login_name(16),city,age); 建表时，login_name 长度为100，这里用16(前16位有很好的区分度)，这样会加快索引查询速度，还会减少索引文件的大小，提高INSERT，UPDATE的更新速度。 建立这样的组合索引，就相当于分别建立如下三种组合索引： 123login_name,city,agelogin_name,citylogin_name 为什么没有city, age等这样的组合索引呢？这是因为 mysql组合索引“最左前缀” 的结果。简单的理解就是只从最左边的开始组合，并不是只要包含这三列的查询都会用到该组合索引。也就是说name_city_age(LOGIN_NAME(16),CITY,AGE) 从左到右进行索引，如果没有左前索引，mysql不会执行索引查询。 Tips如果索引列长度过长,这种列索引时将会产生很大的索引文件,不便于操作,可以使用前缀索引方式进行索引，前缀索引应该控制在一个合适的点,控制在0.31黄金值即可(大于这个值就可以创建)。 12# 这个值大于0.31就可以创建前缀索引,Distinct去重复SELECT COUNT(DISTINCT(LEFT(`title`,10))) / COUNT(*) FROM pages; -- 索引分析单表索引 索引index1:(a,b,c)，只会走a、a,b、a,b,c 三种类型的查询。 其实 a,c也走，但是只走a字段索引，不会走c字段。 同时，SELECT * FROM table WHERE a = ‘1’ AND b &gt; ‘2’ AND c=’3’; 这种类型的也只会有a与b走索引，c不会走。 尽量使用等值查询，减少范围查询，能最大程度避免索引失效。 原因如下： 索引是有序的，index1索引在索引文件中的排列是有序的，首先根据a来排序，然后才是根据b来排序，最后是根据c来排序， 像 select * from table where a = ‘1’ and b &gt; ‘2’ and c=’3’; 这种类型的sql语句，在a走完索引后，b使用索引进行范围查找，c肯定是无序了，所以c就没法走索引，数据库会觉得还不如全表扫描c字段来的快。 如果分别给login_name, city, age 建立单列索引，让该表有3个单列索引，查询时和组合索引的效率是大不一样的，甚至远远低于组合索引。 虽然此时有三个索引，但mysql只能用到其中的那个它认为似乎是最有效率的单列索引，另外两个是用不到的，也就是说还是一个全表扫描的过程。 两表索引LEFT JOIN 索引加右表。RIGHT JOIN 索引加在左表。 做链接用于确定如何从右表进行搜索，左边数据一定都会有，所以右表是检索的关键，要加索引。若左表加索引，右表没有则会出现两次全表扫描。 三表索引JOIN 语句优化 尽可能减少join语句中的NestedLoop的循环总次数：永远使用小结果集驱动大结果集。 优先优化NestedLoop的内层循环。 保证join语句中被驱动表上join条件字段已经被索引。 当无法保证被驱动表的join条件字段被索引且内存资源充足的前提下，不要太吝啬JoinBuffer的设置。 索引失效 全值匹配 最佳左前缀法则 不在索引列上做任何操作计算、函数、(自动或手动)类型转换，会导致索引失效，进而导致全表扫描 索引在 范围查询后会失效。 尽量使用覆盖索引 mysql在使用(!=, &lt;&gt;)的时候无法使用索引，会导致全表扫描。 is null，is not null 无法使用索引。is null 会从另外的记录中读取，is not null将会进行全表扫描。 like 以通配符开头(%abc) mysql 索引将会变成全表扫描。 两边都是%的like查询，应使用覆盖索引。即在查询的字段列表中(select xxx from···)只是用索引中的字段。将会使用index 索引。 字符串不加单引号索引失效。会导致自动的类型转换。 少用 or，用它来连接时会索引失效。 BAD SQL12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# -- 正则表达式不使用索引,这应该很好理解# 不会使用索引,因为所有索引列参与了计算SELECT `sname` FROM `stu` WHERE `age`+10=30; # 不会使用索引,因为使用了函数运算,原理与上面相同SELECT `sname` FROM `stu` WHERE LEFT(`date`,4) &lt;1990; # 走索引SELECT * FROM `houdunwang` WHERE `uname` LIKE'后盾%'; # 不走索引SELECT * FROM `houdunwang` WHERE `uname` LIKE "%后盾%";# -- 字符串与数字比较不使用索引;CREATE TABLE `a` (`a` char(10));# 走索引EXPLAIN SELECT * FROM `a` WHERE `a`="1";# 不走索引EXPLAIN SELECT * FROM `a` WHERE `a`=1;# -- 如果条件中有or,即使其中有条件带索引也不会使用。# 换言之,就是要求使用的所有字段,都必须建立索引, 我们建议大家尽量避免使用or 关键字select * from dept where dname='xxx' or loc='xx' or deptno=45;# -- 如果mysql估计使用全表扫描要比使用索引快,则不使用索引# index(a1, a2, a3, a4)# 使用了索引，a3作用在排序而不是查找select * from test_table where a1='a1' and a2='a2' and a4='a4' order by a3;# 用到索引，但是由于a3没有出现，出现了a4，将出现filesort。select * from test_table where a1='a1' and a2='a2' order by a4;# 只使用了a1一个字段索引，但是a2, a3用于排序，无filesort。select * from test_table where a1='a1' and a5='a5' order by a2, a3;# 出现filesort，索引为1，2，3，4 但是order by 没有按顺序。select * from test_table where a1='a1' and a5='a5' order by a3, a2;# 虽然order by顺序错误，但是前边已经定义a2，即a2已经是常量了，排序不关心，不会产生filesort。select * from test_table where a1='a1' and a2='a2' order by a3, a2;# 出现filesort，temporary，where 很惨。select * from test_table where a1='a1' and a4='a4' group by a3,a2; 定值、范围还是排序，一般order by是给个范围 group by基本上都是需要进行排序，会有临时表产生 一般性建议什么时候需要建立索引 主键自动建立唯一索引。 频繁作为查询条件的字段应该创建索引。 查询中与其他表关联的字段，外键关系建立索引。 单键/组合索引的选择。选择组合索引。（高并发倾向于组合索引） Where条件里用不到的字段不创建索引 查询中统计或者分组的字段要创建索引 查询中排序的字段，排序字段若通过索引去访问将大大提高排序速度。 什么时候不建议建立索引 表记录太少。（三百万以下） 经常增删改的表。提高了查询速度，但是会降低更新表的速度，更新表的时候，不仅要保存数据，还要保存索引。 数据重复且分布平均的表字段。 tips 索引不会包含有NULL的列 只要列中包含有NULL值，都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此符合索引就是无效的。 索引列排序 mysql查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作，尽量不要包含多个列的排序，如果需要最好给这些列建复合索引。 like语句操作 一般情况下不鼓励使用like操作，如果非使用不可，注意正确的使用方式。like ‘%aaa%’不会使用索引，而like ‘aaa%’可以使用索引。 不要在列上进行运算 不使用NOT IN 、&lt;&gt;、！=操作，但 &lt;,&lt;=，=，&gt;,&gt;=,BETWEEN,IN是可以用到索引的. 在where和join中出现的列需要建立索引。 如果where字句的查询条件里使用了函数(如：where DAY(column)=…),mysql将无法使用索引。 在join操作中(需要从多个数据表提取数据时)，mysql只有在 主键和外键的数据类型相同时 才能使用索引，否则及时建立了索引也不会使用。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql为什么使用B+树]]></title>
    <url>%2Fmysql-b-tree%2F</url>
    <content type="text"><![CDATA[探讨一下mysql底层的数据结构，是b+树，还是b树。 两种树形结构B树每个节点都存储key和data，所有节点组成这棵树，并且叶子节点指针为null B+树只有叶子节点存储data，叶子节点包含了这棵树的所有键值，叶子节点不存储指针。 后来，在B+树上增加了顺序访问指针，也就是每个叶子节点增加一个指向相邻叶子节点的指针 ，这样一棵树成了数据库系统实现索引的首选数据结构。 原因有很多，最主要的是这棵树矮胖 ，呵呵。一般来说，索引很大，往往以索引文件的形式存储的磁盘上，索引查找时产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的时间复杂度。树高度越小，I/O次数越少。 那为什么是B+树而不是B树呢，因为它内节点不存储data，这样一个节点就可以存储更多的key。 在MySQL中，最常用的两个存储引擎是MyISAM 和InnoDB ，它们对索引的实现方式是不同的。 Mysql存储引擎MyISAdata存的是数据地址。索引是索引，数据是数据。索引放在XX.MYI文件中，数据放在XX.MYD文件中，所以也叫非聚集索引。 InnoDBdata存的是数据本身。索引也是数据。数据和索引存在一个XX.IDB文件中，所以也叫聚集索引。 两种引擎区别了解了数据结构再看索引，一切都不费解了，只是顺着逻辑推而已。另加两种存储引擎的区别： MyISAM是非事务安全的，而InnoDB是事务安全的 MyISAM锁的粒度是表级的，而InnoDB支持行级锁 MyISAM支持全文类型索引，而InnoDB不支持全文索引 MyISAM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyISAM MyISAM表保存成文件形式，跨平台使用更加方便 MyISAM管理非事务表，提供高速存储和检索以及全文搜索能力，如果在应用中执行大量select操作可选择 InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量insert和update操作，可选择。 为什么mysql用B+树做索引而不用B-树或红黑树B-树、B+树、红黑树，都是平衡查找树，那么查询效率上讲，平均都是O(logn)。使用什么哪种数据结构，肯定是出于提高数据库的查询效率的考虑。 B+树做索引而不用B-树Mysql如何衡量查询效率呢？磁盘IO次数。 一般来说索引非常大，尤其是关系性数据库这种数据量大的索引能达到亿级别，所以为了减少内存的占用，索引也会被存储在磁盘上。 B-树/B+树 的特点就是每层节点数目非常多，层数很少，目的就是为了减少磁盘IO次数，但是B-树的每个节点都有data域（指针），这无疑增大了节点大小，说白了增加了磁盘IO次数（磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多，一次IO多耗时），而B+树除了叶子节点其它节点并不存储数据，节点小，磁盘IO次数就少。 B+树只有叶节点存放数据，其余节点用来索引，而B-树是每个索引节点都会有Data域。 B+树所有的Data域在叶子节点，并且所有叶子节点之间都有一个链指针。 这样遍历叶子节点就能获得全部数据，这样就能进行区间访问啦。在数据库中基于范围的查询是非常频繁的，而B树不支持这样的遍历操作。 B+树做索引而不用红黑树 AVL 树（平衡二叉树）和红黑树（二叉查找树）基本都是存储在内存中才会使用的数据结构。 在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁，进而导致效率低下的情况。 为什么会出现这样的情况，我们知道要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。 根据磁盘查找存取的次数往往由树的高度所决定，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树可以有多个子女，从几十到上千，可以降低树的高度。 数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。 为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>b+树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql使用手册]]></title>
    <url>%2Fmysql-handbook%2F</url>
    <content type="text"><![CDATA[手把手叫会零基础的你使用mysql。 登录MySqlwindows环境进入cmd后，输入: mysql –h localhost –u username –p 再输入密码就可以启动mysql linux 进入terminal后直接输入: mysql –h localhost -u username -p随后根据提示输入密码。 其中localhost是mysql服务器所在的ip，如果是本机可以省略-h localhost 或用localhost； username是登录mysql的用户名。 数据库(DATABASE)相关操作12345678910111213141516171819202122-- 建名为db_name的数据库CREATE DATABASE db_name;-- 查看已经存在的数据库show DATABASES; -- 删除名为db_name的数据库DROP DATABASE db_name; -- 操作名为db_name的数据库USE db_name; -- 显示数据库中的表SHOW TABLES; -- 查看表名为table_name的表的结构DESC table_name; 数据库中表(TABLE)的操作查看表的详细结构语句1SHOW CREATE TABLE table_name; 几个概念主键12345678910111213141516-- 创建表且设置了ID为主键 CREATE TABLE table_name(id int primary key, name varchar(50), age int , sex varchar(10));-- 设置了表中stu_id和course_id两个都为主键CREATE TABLE table_name(stu_id int, course_id int, name varchar(20), grade float, PRIMARY KEY(stu_id,course_id)); 外键如果表A的某一个属性值依赖于表B的主键，则称B为父表，A为子表，A中的这个字段为A的外键，如果父表中的信息改变，则对应子表的数据也会改变 12345678910-- table_name02是父表，table_name01是子表，给子表设置了两个外键CREATE TABLE table_name01(id int PRIMARY KEY, stu_id int, course_id int , score float, grade int, CONSTRAINT c_fk(外键别名) FOREIGN KEY(stu_id,course_id) REFERENCES table_name02(stu_id,course_id)); 约束表字段的非空约束指字段中值不能为null 123456-- 设置not null表示字段不能为空，也就是非空CREATE TABLE table_name(id int primary key not null, name varchar(50) not null, stu_id int); 唯一约束指字段中值不能重复 12345678910111213141516-- 其中设置了主键id，且自动增加，且unique设置了stu_id的值必须唯一性，不能有相同的值存在CREATE TABLE table_name(id int primary key auto_increment, stu_id int unique, name varchar(20) not null);-- default 为表设置默认值，即在没有插入数据的时候会用默认值代替; -- 即为Englist字段设置了默认值为zero;CREATE TABLE table_name(id int primary key auto_increment, stu_id int unique, name varchar(50) not null, english varchar(20) default 'zero'); 表的修改操作123456789101112131415161718192021222324252627282930313233343536373839404142-- 修改表名ALTER TABLE old_table_name RENAME [to] new_table_name;-- 修改字段属性ALTER TABLE table_name MODIFY 属性名 数据类型(修改后的类型);-- 修改字段ALTER TABLE table_name CHANGE 旧字段名 新字段名 新数据类型;-- 增加字段-- 在字段2后面增加字段1;如果把字段2改成 FIRST即加在最前面ALTER TABLE table_name ADD 数据类型 AFTER 字段2;-- 删除字段ALTER TABLE table_name drop 字段名;-- 修改字段的位置ALTER TABLE table_name MODIFY 字段名 FIRST(第一个位置，AFTER 字段，指定字段的后面);-- 更改表的引擎名ALTER TABLE table_name engine=Mylsam; -- 删除表的外键约束ALTER TABLE table_name DROP FOREIGN KEY 外键别名; -- 删除表 -- --普通的没有关联的表drop table table_name; -- 删除有关联的表-- 先查看表的详情，看到外键的另名,-- 先删除外键，再删除表格就可以了。 SHOW CREATE TABLE table_name; 数据库的增删改查操作数据库的增(insert into)删(delete)改(update)查(select)操作： 添加数据(INSERT INTO)123456789101112131415161718192021222324-- A增加数据分两种：-- 不指定具体字段名如INSERT INTO table_name VALUES(值1，值2…); -- 指定字段名-- 如果是为指定的字段加数据，只需要写出需要加数据的字段即可INSERT INTO table_name(字段1，字段2….)VALUES(值1,值2….);-- 同时插入多条数据INSERT INTO table_name [字段列表]VALUES(取舍列表1)，(取值列表2)…;-- 将一个表的数据插入到别个一张表中INSERT INTO table_name1(字段列表)SELECT (表2字段) FROM table_name2 WHERE 条件表达式; 更新数据(改)操作(UPDATE)1234-- 可以对一定范围中的数据更改，主要是从where后面的条件来判断UPDATE table_name SET 字段1=值1，字段2=值2…WHERE 条件表达式; 删除数据操作(DELETE)1234567-- 依据条件表达式筛选需要删除的数据。DELETE FROM table_nameWHERE 条件表达式;-- 将会删除所有数据。DELETE FROM table_name; 查询数据(QUERY)123456789SELECT 字段名列表 FROM table_name [WHERE 条件表达式1] [GROUP BY 字段名 [HAVING 条件表达式2]][ORDER BY 字段名 [ASC(升序)/DESC(降序)]] 123456789101112131415161718192021222324252627282930313233343536-- 单表查询SELECT 字段名 FROM table_nameWHERE 条件;-- 带in关键字查询-- 判断某个字段的值是否在指定的集合中，是的话就查出来SELECT 字段名 table_name WHERE 字段名 IN (值1，值2…..) -- 带between and 关键字的查询-- 查找的是范围在值1与值2之间对应的数据;结果是包含两端的值的。SELECT 字段名 FROM table_nameWHERE 字段名 BETWEEN 值1 AND 值2;-- 带like的匹配查询一个完整字符串，可以加%;-- %表示任意长度的字符串如b%k表示以b开头，以k对事的任意字符串，而只表示单个字符，如b_k表示以b开始k结束的3个字符的字符串 。not表示不匹配时.SELECT 字段名 FROM table_name WHERE 字段名 [not] LIKE 条件;-- 空值查询-- 即查询[不]为空的数据SELECT 字段名 FROM table_name WHERE 字段名 IS [not]null; -- and与or的多条件查询-- and表示所以条件都必须成立，而or表示只需要其中任何一个条件成立就可以。SELECT 字段名 FROM table_name WHERE 条件1 AND 条件2; -- 查询结果不重复SELECT DISTINCT 字段名 FROM table_name; 分组查询12345678910111213141516171819202122232425262728-- 单独用 group by 分组，结果只会显示一个分组的一条记录SELECT 字段名 FROM table_name GROUP BY 字段名;-- group by 和group_concat()函数使用-- 功能：将group by产生的同一个分组中的值连接起来，返回一个字符串结果。-- 语法：group_concat( [distinct] 要连接的字段 [order by 排序字段 asc/desc ] [separator '分隔符'] )-- 说明：通过使用distinct可以排除重复值；如果希望对结果中的值进行排序，可以使用order by子句；separator是一个字符串值，缺省为一个逗号-- 每个分组的所有字段都可以显示。SELECT 字段名, GROUP_COUCAT(字段名) FROM table_name GROUP BY 字段名;-- group by与集合函数使用SELECT 字段名, COUNT(字段名) FROM table_name GROUP BY 字段名 HAVING COUNT (字段名) 条件;-- 多字段分组SELECT * FROM table_name GROUP BY 字段1，字段2…;-- group by与with rollup一起用-- ROLLUP 运算符生成的结果集类似于 CUBE 运算符生成的结果集。SELECT 字段名, COUNT(字段名) FROM table_name GROUP BY 字段名 WITH ROLLUP; 用limit限制查询数据1234-- 前者是显示从第一条到a条数据-- 后者是显示从a条到b条间的数据SELECT * FROM table_name LIMIT a 或(LIMIT a,b); 使用集合函数查询数据12345678910111213141516-- count()统计数据条数SELECT COUNT(*) FROM table_name -- sum()求和SELECT 字段名, SUM(字段名) FROM table_name WHERE 条件; -- avg()求平均数SELECT AVG(字段名) FROM table_name GROUP BY 字段名; -- max与min最大与最小值SELECT MAX(字段名)/MIN(字段名) FROM table_name; 多表连接查询内连接查询两个以上表中存在意义相同的字段时，可以用该字段来连接表进行查询.如: 123SELECT 字段1，字段2，字段3…FROM table_name1 INNER JOIN table_name2 ON table_name1.字段a=table_name2.字段b; 外连接查询123-- Letf表示左链接，right表示右链接。SELECT 字段列表 FROM table_name01 LEFT/RIGHT JOIN table_name02 ON table_name01.字段名=talbe_name02.字段名; 用正则表达式查询12345678910-- 查询以特定字符开头的记录。以a头。SELECT * FROM table_name WHERE 字段名 REGEXP '^a'; -- 查询以特定字符结束的记录。以xx结尾。SELECT * FROM table_name WHERE REGEXP 'xx$';-- 用符号"."来代替字符串中任意一个字符。以1开头y结尾，且中间两个字符。SELECT * FROM table_name WHERE name REGEXP '^1..y$'; 表或字段取别名123456-- 表的别名。t就是表的别名。SELECT * FROM table_name t WHERE t.字段=值;-- 字段的别名。用as关键字。SELECT t_id as id FROM table_name WHERE t_id=值 ; 数据库备份1234567891011121314151617181920# mysqldump命令备份.# 其中db_name是数据库的名称, table1..是表名, backupname.sql表示备份文件的名称，前面可以加个绝对路径# 如果没有表名将备份 整个数据库mysqldump –u username –p db_name table1,table2….&gt;backupname.sql; # 备份多个数据库mysqldump -u username –p –databases db_name1 db_name2… &gt; backupname.sql # 备份所有数据库mysqldump –u root –p –all-databases &gt; C:\all.sql # 用Mysqlhotcopy工具快速备份 # 数据库还原# 其中backup.sql是保存的数据库文件mysql –u root –p &lt; backup.sql]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>使用手册</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql5.7 安装教程]]></title>
    <url>%2Fmysql-install%2F</url>
    <content type="text"><![CDATA[手把手教你安装mysql5.7 官方最新下载地址https://dev.mysql.com/downloads/mysql/ 解压压缩包自5.7.16版本以后，解压后，根目录就不带 my-default.ini 或 my.ini 配置文件和data文件夹。首先在根目录创建一个 my.ini 配置文件，my.ini 配置内容如下，注意安装目录和数据库存放目录为实际安装的目录。 12345678910111213141516171819202122[mysql]# 设置mysql客户端默认字符集default-character-set=utf8 [mysqld]#设置3306端口port = 3306 # 设置mysql的安装目录basedir=E:\MySQL\mysql-5.7.21-winx64# 设置mysql数据库的数据的存放目录datadir=E:\MySQL\mysql-5.7.21-winx64\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB 配置环境变量新增 系统变量： 1234变量名：MYSQL_HOME 变量值：E:\MySQL\mysql-5.7.21-winx64 在环境变量Path中添加：%MYSQL_HOME%\bin 安装 MySQL服务以管理员身份运行命令提示符；运行 mysqld install ，执行后提示 Service successfully installed； 初始化mysql数据打开cmd执行如下命令，创建了一个具有空密码的root用户（ 可能需要进入bin目录下输入此命令）： 1mysqld --initialize-insecure --user=mysql 最后的参数 –user=mysql 在 windows 也可以不用添加，但在 unix 等系统下好像很重要。 执行命令后，系统会自动生成相应的 data 目录，并自动创建好空密码的 root 用户。此时表示初始化成功。 运行MySQL服务1234567891011121314# 启动MySQLnet start mysql# 停止MySQLnet stop mysql# 登录mysql -u root –p# 首次修改密码mysqladmin -u root password "newpass" # 如果root已经设置过密码，采用如下方法修改 mysqladmin -u root -p password "newpass" time to show12345# 基本语句mysql&gt; show databases; // 显示所有数据库mysql&gt; use mysql;mysql&gt; select * from user;mysql&gt; ····]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>安装教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis基础、原理全覆盖]]></title>
    <url>%2Fredis-learn%2F</url>
    <content type="text"><![CDATA[Redis 是什么Redis: REmote DIctionary Server(远程字典服务器)完全开源免费，C语言编写遵守BSD协议，一个高性能的（key/value)分布式内存数据库。基于内存运行并支持持久化的NOSQL数据库被称为数据结构服务器。 与其他key-value缓存产品区别？ 性能优秀，数据在内存中，读写速度非常快，支持并发- 10W QPS； 单进程单线程，是线程安全的，采用IO多路复用机制； 丰富的数据类型，支持字符串（strings）、散列（has- hes）、列表（lists）、集合（sets）、有序集合（so- rted sets）等； 支持数据持久化。可以将内存中数据保存在磁盘中，重- 启时加载； 主从复制，哨兵，高可用； 可以用作分布式锁； 可以作为消息中间件使用，支持发布订阅 五种数据类型Redis如何管理先来了解下Redis内部内存管理是如何描述这5种数据类型。 首先redis内部使用一个redisObject对象来表示所有的key和value，redisObject最主要的信息如上图所示：type表示一个value对象具体是何种数据类型;encoding是不同数据类型在redis内部的存储方式。 比如：type=string表示value存储的是一个普通字符串，那么encoding可以是raw或者int。 5种数据类型 string是redis最基本的类型，可以理解成与memcached一模一样的类型，一个key对应一个value。 value不仅是string，也可以是数字。string类型是二进制安全的，意思是redis的string类型可以包含任何数据，比如jpg图片或者序列化的对象。string类型的值最大能存储512M。 Hash是一个键值（key-value）的集合。 redis的hash是一个string的key和value的映射表，Hash特别适合存储对象。常用命令：hget,hset,hgetall等。 list列表是简单的字符串列表，按照插入顺序排序。 可以添加一个元素到列表的头部（左边）或者尾部（右边） 常用命令：lpush、rpush、lpop、rpop、lrange(获取列表片段)等。 应用场景：list应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表都可以用list结构来实现。 数据结构：list就是链表，可以用来当消息队列用。redis提供了List的push和pop操作，还提供了操作某一段的api，可以直接查询或者删除某一段的元素。 实现方式：redis list的是实现是一个双向链表， 既可以支持反向查找和遍历，更方便操作，不过带来了额外的内存开销。 set是string类型的无序集合。 集合是通过hashtable实现的。set中的元素是没有顺序的，而且是没有重复的。 常用命令：sdd、spop、smembers、sunion等。 应用场景：redis set对外提供的功能和list一样是一个列表，特殊之处在于set是自动去重的，而且set提供了判断某个成员是否在一个set集合中。 zset和set一样是string类型元素的集合，且不允许重复的元素。 常用命令：zadd、zrange、zrem、zcard等。 使用场景：sorted set可以通过用户额外提供一个优先级（score）的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set结构。和set相比，sorted set关联了一个double类型权重的参数score，使得集合中的元素能够按照score进行有序排列，redis正是通过分数来为集合中的成员进行从小到大的排序。 实现方式：Redis sorted set的内部使用HashMap和跳跃表(skipList)来保证数据的存储和有序， HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score，使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。 数据类型应用场景总结 Redis缓存结合spring boot使用的。一般有两种方式，一种是直接通过RedisTemplate来使用，另一种是使用spring cache集成Redis（也就是注解的方式） 1234567891011121314151617181920212223242526272829&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Tips spring-boot-starter-data-redis: 在spring boot 2.x以后底层不再使用Jedis，而是换成了Lettuce。 commons-pool2：用作redis连接池，如不引入启动会报错 spring-session-data-redis：spring session引入，用作共享session。 配置文件application.yml的配置： 123456789101112131415161718server: port: 8082 servlet: session: timeout: 30msspring: cache: type: redis redis: host: 127.0.0.1 port: 6379 password: # redis默认情况下有16个分片，这里配置具体使用的分片，默认为0 database: 0 lettuce: pool: # 连接池最大连接数(使用负数表示没有限制),默认8 max-active: 100 RedisTemplate使用方式默认情况下的模板只能支持RedisTemplate&lt;String, String&gt;，也就是只能存入字符串，所以自定义模板很有必要。 添加配置类RedisCacheConfig.java 1234567891011121314@Configuration@AutoConfigureAfter(RedisAutoConfiguration.class)public class RedisCacheConfig &#123; @Bean public RedisTemplate&lt;String, Serializable&gt; redisCacheTemplate(LettuceConnectionFactory connectionFactory) &#123; RedisTemplate&lt;String, Serializable&gt; template = new RedisTemplate&lt;&gt;(); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(new GenericJackson2JsonRedisSerializer()); template.setConnectionFactory(connectionFactory); return template; &#125;&#125; 测试类 12345678910111213141516171819@RestController@RequestMapping("/user")public class UserController &#123; public static Logger logger = LogManager.getLogger(UserController.class); @Autowired private StringRedisTemplate stringRedisTemplate; @Autowired private RedisTemplate&lt;String, Serializable&gt; redisCacheTemplate; @RequestMapping("/test") public void test() &#123; redisCacheTemplate.opsForValue().set("userkey", new User(1, "张三", 25)); User user = (User) redisCacheTemplate.opsForValue().get("userkey"); logger.info("当前获取对象：&#123;&#125;", user.toString()); &#125;&#125; 使用spring cache集成redisspring cache具备很好的灵活性，不仅能够使用SPEL(spring expression language) 来定义缓存的key和各种condition，还提供了开箱即用的缓存临时存储方案，也支持和主流的专业缓存如EhCache、Redis、Guava的集成。 定义接口UserService.java 12345678public interface UserService &#123; User save(User user); void delete(int id); User get(Integer id);&#125; 接口实现类UserServiceImpl.java 1234567891011121314151617181920212223242526272829303132333435@Servicepublic class UserServiceImpl implements UserService&#123; public static Logger logger = LogManager.getLogger(UserServiceImpl.class); private static Map&lt;Integer, User&gt; userMap = new HashMap&lt;&gt;(); static &#123; userMap.put(1, new User(1, "肖战", 25)); userMap.put(2, new User(2, "王一博", 26)); userMap.put(3, new User(3, "杨紫", 24)); &#125; @CachePut(value ="user", key = "#user.id") @Override public User save(User user) &#123; userMap.put(user.getId(), user); logger.info("进入save方法，当前存储对象：&#123;&#125;", user.toString()); return user; &#125; @CacheEvict(value="user", key = "#id") @Override public void delete(int id) &#123; userMap.remove(id); logger.info("进入delete方法，删除成功"); &#125; @Cacheable(value = "user", key = "#id") @Override public User get(Integer id) &#123; logger.info("进入get方法，当前获取对象：&#123;&#125;", userMap.get(id)==null?null:userMap.get(id).toString()); return userMap.get(id); &#125;&#125; 为了方便演示数据库的操作，这里直接定义了一个Map&lt;Integer,User&gt; userMap，这里的核心是三个注解 @Cachable、@CachePut和@CacheEvict 用缓存要注意，启动类要加上一个注解开启缓存 123456789@SpringBootApplication(exclude=DataSourceAutoConfiguration.class)@EnableCachingpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 缓存注解@Cacheable根据方法的请求参数对其结果进行缓存 key：缓存的key，可以为空，如果指定要按照SPEL表达式编写，如果不指定，则按照方法的所有参数进行组合。 value：缓存的名称，必须指定至少一个（如 @Cacheable (value=’user’)或者@Cacheable(value={‘user1’,’user2’})） condition：缓存的条件，可以为空，使用SPEL编写，返回true或者false，只有为true才进行缓存。 @CachePut根据方法的请求参数对其结果进行缓存，和@Cacheable不同的是，它每次都会触发真实方法的调用。参数描述见上。 @CacheEvict根据条件对缓存进行清空 key：同上 value：同上 condition：同上 allEntries：是否清空所有缓存内容，缺省为false，如果指定为true，则方法调用后将立即清空所有缓存 beforeInvocation：是否在方法执行前就清空，缺省为false，如果指定为true，则在方法还没有执行的时候就清空缓存。缺省情况下，如果方法执行抛出异常，则不会清空缓存。 缓存问题缓存和数据库数据一致性问题分布式环境下非常容易出现缓存和数据库间数据一致性问题，针对这一点，如果项目对缓存的要求是强一致性的，那么就不要使用缓存。我们只能采取合适的策略来降低缓存和数据库间数据不一致的概率，而无法保证两者间的强一致性。合适的策略包括合适的缓存更新策略，更新数据库后及时更新缓存、缓存失败时增加重试机制。 缓存雪崩？目前电商首页以及热点数据都会去做缓存，一般缓存都是定时任务去刷新，或者查不到之后去更新缓存的，定时任务刷新就有一个问题。 举个栗子：如果首页所有Key的失效时间都是12小时，中午12点刷新的，我零点有个大促活动大量用户涌入，假设每秒6000个请求，本来缓存可以抗住每秒5000个请求，但是缓存中所有Key都失效了。此时6000个/秒的请求全部落在了数据库上，数据库必然扛不住，真实情况可能DBA都没反应过来直接挂了，此时，如果没什么特别的方案来处理，DBA很着急，重启数据库，但是数据库立马又被新流量给打死了。这就是我理解的缓存雪崩。 同一时间大面积失效，瞬间Redis跟没有一样，那这个数量级别的请求直接打到数据库几乎是灾难性的，你想想如果挂的是一个用户服务的库，那其他依赖他的库所有接口几乎都会报错，如果没做熔断等策略基本上就是瞬间挂一片的节奏，你怎么重启用户都会把你打挂，等你重启好的时候，用户早睡觉去了，临睡之前，骂骂咧咧“什么垃圾产品”。 怎么应对？处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会再同一时间大面积失效。 setRedis（key, value, time+Math.random()*10000）;如果Redis是集群部署，将热点数据均匀分布在不同的Redis库中也能避免全部失效。或者设置热点数据永不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那你刷下缓存就好了，不要设置过期时间），电商首页的数据也可以用这个操作，保险。 缓存穿透和击穿？先说下缓存穿透吧，缓存穿透是指缓存和数据库中都没有的数据，而用户（黑客）不断发起请求，举个栗子：我们数据库的id都是从1自增的，如果发起id=-1的数据或者id特别大不存在的数据，这样的不断攻击导致数据库压力很大，严重会击垮数据库。 至于缓存击穿嘛，这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停地扛着大量的请求，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发直接落到了数据库上，就在这个Key的点上击穿了缓存。 怎么解决？ 缓存穿透我会在接口层增加校验，比如用户鉴权，参数做校验，不合法的校验直接return，比如id做基础校验，id&lt;=0直接拦截。 我记得Redis里还有一个高级用法布隆过滤器（Bloom Filter）这个也能很好的预防缓存穿透的发生，他的原理也很简单，就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查DB刷新KV再return。缓存击穿的话，设置热点数据永不过期，或者加上互斥锁就搞定了。作为暖男，代码给你准备好了，拿走不谢。 123456789101112131415161718192021222324252627public static String getData(String key) throws InterruptedException &#123; //从Redis查询数据 String result = getDataByKV(key); //参数校验 if (StringUtils.isBlank(result)) &#123; try &#123; //获得锁 if (reenLock.tryLock()) &#123; //去数据库查询 result = getDataByDB(key); //校验 if (StringUtils.isNotBlank(result)) &#123; //插进缓存 setDataToKV(key, result); &#125; &#125; else &#123; //睡一会再拿 Thread.sleep(100L); result = getData(key); &#125; &#125; finally &#123; //释放锁 reenLock.unlock(); &#125; &#125; return result;&#125; Redis为何这么快redis作为缓存大家都在用，那redis一定很快咯？当然了，官方提供的数据可以达到100000+的QPS（每秒内的查询次数），这个数据不比Memcached差！ redis这么快，它的“多线程模型”你了解吗？（露出邪魅一笑）这是想问Redis这么快，为什么还是单线程的吧。Redis确实是单进程单线程的模型，因为Redis完全是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章的采用单线程的方案了（毕竟采用多线程会有很多麻烦）。 Redis是单线程的，为什么还能这么快吗？ Redis完全基于内存，绝大部分请求是纯粹的内存操作，非常迅速，数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度是O(1)。 数据结构简单，对数据操作也简单。 采用单线程，避免了不必要的上下文切换和竞争条件，不存在多线程导致的CPU切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗。 使用多路复用IO模型，非阻塞IO。 Redis和Memcached的区别 存储方式上：memcache会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。redis有部分数据存在硬盘上，这样能保证数据的持久性。 数据支持类型上：memcache对数据类型的支持简单，只支持简单的key-value，，而redis支持五种数据类型。 性能对比，redis只使用单核而memcached使用多核，所以平均每一个核上Rdis在存储小数据时比Memcached性能更高。100k以上的数据中，memcached性能更高。 集群模式:memcached没有原生的集群模式，需要依靠客户端来实现向集群中分片写入数据；但是redis目前是原生支持cluster模式的，redis官方就是支持redis cluster集群模式的，比memcached来说要更好。 value的大小：redis可以达到1GB，而memcache只有1MB Redis单线程模型文件事件处理器redis基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler。这个文件事件处理器，是单线程的，redis才叫做单线程的模型，采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器来处理这个事件。 Reactor模式首先是事件驱动的，有一个或多个并发输入源，有一个Service Handler，有多个Request Handlers；这个Service Handler会同步的将输入的请求（Event）多路复用的分发给相应的Request Handler。 如果被监听的socket准备好执行accept、read、write、close等操作的时候，跟操作对应的文件事件就会产生，这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件。 文件事件处理器是单线程模式运行的，但是通过IO多路复用机制监听多个socket，可以实现高性能的网络通信模型，又可以跟内部其他单线程的模块进行对接，保证了redis内部的线程模型的简单性。 文件事件处理器的结构包含4个部分：多个socket，IO多路复用程序，文件事件分派器，事件处理器（命令请求处理器、命令回复处理器、连接应答处理器，等等）。 多个socket可能并发的产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个socket，但是会将socket放入一个队列中排队，每次从队列中取出一个socket给事件分派器，事件分派器把socket给对应的事件处理器。 然后一个socket的事件处理完之后，IO多路复用程序才会将队列中的下一个socket给事件分派器。文件事件分派器会根据每个socket当前产生的事件，来选择对应的事件处理器来处理。 文件事件当socket变得可读时（比如客户端对redis执行write操作，或者close操作），或者有新的可以应答的socket出现时（客户端对redis执行connect操作），socket就会产生一个AE_READABLE事件。 当socket变得可写的时候（客户端对redis执行read操作），socket会产生一个AE_WRITABLE事件。 IO多路复用程序可以同时监听 AE_REABLE和AE_WRITABLE 两种事件，要是一个socket同时产生AE_REABLE和AE_WRITABLE 两种事件，那么文件事件分派器优先处理AE_REABLE事件，然后才是AE_WRITABLE事件。 文件事件处理器 如果是客户端要连接redis，那么会为socket关联连接应答处理器 如果是客户端要写数据到redis，那么会为socket关联命令请求处理器 如果是客户端要从redis读数据，那么会为socket关联命令回复处理器 客户端与redis通信的一次流程 在redis启动初始化的时候，redis会将连接应答处理器跟AE_READABLE事件关联起来，接着如果一个客户端跟redis发起连接，此时会产生一个AE_READABLE事件，然后由连接应答处理器来处理跟客户端建立连接，创建客户端对应的socket，同时将这个socket的AE_READABLE事件跟命令请求处理器关联起来。 当客户端向redis发起请求的时候（不管是读请求还是写请求，都一样），首先就会在socket产生一个AE_READABLE事件，然后由对应的命令请求处理器来处理。这个命令请求处理器就会从socket中读取请求相关数据，然后进行执行和处理。 接着redis这边准备好了给客户端的响应数据之后，就会将socket的AE_WRITABLE事件跟命令回复处理器关联起来，当客户端这边准备好读取响应数据时，就会在socket上产生一个AE_WRITABLE事件，会由对应的命令回复处理器来处理，就是将准备好的响应数据写入socket，供客户端来读取。 命令回复处理器写完之后，就会删除这个socket的AE_WRITABLE事件和命令回复处理器的关联关系。 过期策略定期删除+惰性删除 定期删除，指的是redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。 假设redis里放了10万个key，都设置了过期时间，你每隔几百毫秒，就检查10万个key，那redis基本上就死了，cpu负载会很高的，消耗在你的检查过期key上了。注意，这里可不是每隔100ms就遍历所有的设置过期时间的key，那样就是一场性能上的灾难。实际上redis是每隔100ms随机抽取一些key来检查和删除的。 但是问题是，定期删除可能会导致很多过期key到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个key的时候，redis会检查一下 ，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。 并不是key到时间就被删除掉，而是你查询这个key的时候，redis再懒惰的检查一下 通过上述两种手段结合起来，保证过期的key一定会被干掉。 淘汰策略实际上，如果定期删除漏掉了很多过期key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了，咋整？ 答案是：走内存淘汰机制 补充一下：Redis4.0加入了LFU(least frequency use)淘汰策略，包括volatile-lfu和allkeys-lfu，通过统计访问频率，将访问频率最少，即最不经常使用的KV淘汰。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key（这个一般不太合适） volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的） allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的key给干掉啊 noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了 手写lru算法1234567891011121314151617181920public class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int CACHE_SIZE; // 这里就是传递进来最多能缓存多少数据 public LRUCache(int cacheSize) &#123; // 这块就是设置一个hashmap的初始大小 // 同时最后一个true指的是让linkedhashmap按照访问顺序来进行排序 // 最近访问的放在头，最老访问的就在尾 super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); CACHE_SIZE = cacheSize; &#125; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; // 这个意思就是说当map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据 return size() &gt; CACHE_SIZE; &#125;&#125; 持久化redis的持久化机制？redis为了保证效率，数据缓存在了内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。Redis的持久化策略有两种： RDB：快照形式是直接把内存中的数据保存到一个dump的文件中，定时保存，保存策略。 AOF：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。Redis默认是快照RDB的持久化方式。 当Redis重启的时候，它会优先使用AOF文件来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。你甚至可以关闭持久化功能，让数据只在服务器运行时存。 RDB是怎么工作的？默认Redis是会以快照”RDB”的形式将数据持久化到磁盘的一个二进制文件dump.rdb。 工作原理当Redis需要做持久化时，Redis会fork一个子进程，子进程将数据写到磁盘上一个临时RDB文件中。当子进程完成写临时文件后，将原来的RDB替换掉，这样的好处是可以copy-on-write。 RDB的优这种文件非常适合用于备份：比如，你可以在最近的24小时内，每小时备份一次，并且在每个月的每一天也备份一个RDB文件。这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。RDB非常适合灾难恢复。RDB的缺点是：如果你需要尽量避免在服务器故障时丢失数据，那么RDB不合适你。 AOF是怎么工作的？使用AOF做持久化，每一个写命令都通过write函数追加到appendonly.aof中，配置方式如下： 12345appendfsync yes appendfsync always #每次有数据修改发生时都会写入AOF文件。#每秒钟同步一次，该策略为AOF的缺省策略。appendfsync everysec 工作原理AOF可以做到全程持久化，只需要在配置中开启 appendonly yes。这样redis每执行一个修改数据的命令，都会把它添加到AOF文件中，当redis重启时，将会读取AOF文件进行重放，恢复到redis关闭前的最后时刻。 使用AOF的优点让redis变得非常耐久。可以设置不同的fsync策略，aof的默认策略是每秒钟fsync一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。缺点是对于相同的数据集来说，AOF的文件体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。 该用哪一个呢？如果你非常关心你的数据，但仍然可以承受数分钟内的数据丢失，那么可以额只使用RDB持久。 AOF将Redis执行的每一条命令追加到磁盘中，处理巨大的写入会降低Redis的性能，不知道你是否可以接受。 数据库备份和灾难恢复：定时生成RDB快照非常便于进行数据库备份，并且RDB恢复数据集的速度也要比AOF恢复的速度快。当然了，redis支持同时开启RDB和AOF，系统重启后，redis会优先使用AOF来恢复数据，这样丢失的数据会最少。 主从复制redis单节点存在单点故障问题，为了解决单点问题，一般都需要对redis配置从节点，然后使用哨兵来监听主节点的存活状态，如果主节点挂掉，从节点能继续提供缓存功能。 主从配置结合哨兵模式能解决单点故障问题，提高redis可用性。从节点仅提供读操作，主节点提供写操作。对于读多写少的状况，可给主节点配置多个从节点，从而提高响应效率。 redis replication核心机制 redis 采用异步方式 复制数据到slave节点，不过redis 2.8开始，slave node会周期性的确认自己每次复制的数据量。 一个master node是可以配置多个slave node的。 slave node也可以连接其他的slave node。 slave node做复制的时候，是不会block master node的正常工作的。 slave node在做复制的时候，也不会对自己的查询操作有影响，它会用旧的数据集来提供服务；但是，复制完成的时候，需要删除旧的数据集，加载新的数据集，这个时候就会暂停对外服务了。 slave node主要用来横向扩容，做读写分离，扩容的slave node可以提高读的吞吐量。 master持久化对主从架构的意义如果采用了主从架构，那么建议必须开启master node持久化!! 不建议使用slave node作为master node的数据热备，因为那样的话，如果关掉master的持久化，可能在master宕机重启的时候数据是空的，然后经过复制，slave节点也丢失了。 master：RDB和AOF都关闭了，数据都存在内存中 master宕机，重启，是没有本地数据可以恢复的，然后就会认为自己的IDE数据是空的，然后将空的数据集同步到slave上去，所有slave的数据集全部清空。 造成100%数据丢失。 即使采用了高可用机制，slave node自动接管master node，但是也可能sentinal还没有检测到master failure，master node自动重启了，还是可能会造成slave node数据清空。 复制的过程关于复制过程，是这样的： 从节点启动，执行slaveof [masterIP] [masterPort] (redis.cnf里边的slaveof配置的)， 保存主节点信息 从节点中的定时任务 (每秒检查是否有新的master node要来连接和复制) 发现主节点信息，建立和主节点的socket连接 从节点发送Ping信号，主节点返回Pong，两边能互相通信 口令认证，如果master设置了requirepass，那么slave node必须发送masterauth的口令过去认证 连接建立后，主节点第一次会进行全量复制(将所有数据发送给从节点) 主节点把当前的数据同步给从节点后，便完成了复制的建立过程。接下来，主节点就会持续的把写命令发送给从节点，保证主从数据一致性。 数据同步的过程redis2.8之前使用sync [runId] [offset] 同步命令，redis2.8之后使用psync [runId] [offset] 命令。 两者不同在于，sync命令仅支持全量复制过程，psync支持全量和部分复制。介绍同步之前，先介绍几个概念： runId：每个redis节点启动都会生成唯一的uuid，每次redis重启后，runId都会发生变化。info server 可以看到master run id。如果只根据host+ip定位master node是不靠谱的。若发现slave node发送的同步请求中runId 不同，则触发全量复制，同步给slave node。如果需要不更改run id重启redis，可以使用redis-cli debug reload命令。 offset：主节点和从节点都各自维护自己的主从复制偏移量offset，当主节点有写入命令时，offset=offset+命令的字节长度。从节点在收到主节点发送的命令后，也会增加自己的offset，并把自己的offset发送给主节点。这样，主节点同时保存自己的offset和从节点的offset，通过对比offset来判断主从节点数据是否一致。 repl_backlog_size：保存在主节点上的一个固定长度的先进先出队列，默认大小是1MB。master node给slave node复制数据时，也会将数据在backlog中同步写一份。 psync的执行流程： 从节点发送psync[runId][offset]命令，主节点有三种响应： FULLRESYNC：第一次连接，进行全量复制 CONTINUE：之后的连接，进行部分复制 ERR：不支持psync命令，进行全量复制 从节点第一次连接到主节点时，主节点会发送FULLRESYNC 进行全量复制，之后的每次复制都进行部分复制。 主节点响应写命令时，不但会把命名发送给从节点，还会写入复制积压缓冲区，用于复制命令丢失的数据补救。 全量复制和部分复制 全量复制的流程 从节点发送psync ? -1命令（因为第一次发送，不知道主节点的runId，所以为?，因为是第一次复制，所以offset=-1）。 主节点发现从节点是第一次复制，返回FULLRESYNC {runId} {offset}，runId是主节点的runId，offset是主节点目前的offset。 从节点接收主节点信息后，保存到info中。 主节点在发送FULLRESYNC后，启动bgsave命令，生成RDB文件（数据持久化）。 主节点发送RDB文件给从节点，如果rdb复制事件超过60s(repl-timeout)，那么slave node就会认为复制失败，可以适当调大这个参数。 主节点在生成rdb时，会将所有新的写命令缓存在内存中，在从节点保存了rdb之后，再将新的写命令复制给从节点。 client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败。 从节点收到rdb之后，清空自己的旧数据，然后重新加载RDB文件到内存中，同时基于旧的数据版本对外提供服务。 如果从节点开启了AOF，从节点会异步重写AOF文件。 如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗在1分半到2分钟。 部分复制(增量复制) 部分复制主要是Redis针对全量复制的过高开销做出的一种优化措施，使用psync [runId] [offset] 命令实现。当从节点正在复制主节点时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向主节点要求补发丢失的命令数据，主节点的复制积压缓冲区（backlog）将这部分数据直接发送给从节点，这样就可以保持主从节点复制的一致性。补发的这部分数据一般远远小于全量数据。 主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内的复制积压缓冲区（backlog）依然可以保存最近一段时间的写命令数据。 当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们当做psync参数发送给主节点，要求进行部分复制。 主节点接收到psync命令后首先核对参数runId是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数offset在复制积压缓冲区（backlog）中查找，如果offset之后的数据存在，则对从节点发送+CONTINUE命令，表示可以进行部分复制。因为缓冲区大小固定，若发生缓冲溢出，则进行全量复制。 主节点根据偏移量把复制积压缓冲区（backlog）里的数据发送给从节点，保证主从复制进入正常状态。 心跳机制主从节点互相都会发送heartbeat信息 master默认每隔10秒发送一次heartbeat，slave node每隔1秒发送一次heartbeat。 主从复制断点续传从redis2.8开始，支持主从复制断点续传，如果主从复制过程中，网络连接断了，那么可以接着上次复制的地方，继续复制下去，而不是重新开始。 master node会在内存中创建一个backlog，master和slave都会保存一个replicate offset还有一个master id，offset就是保存在backlog中的。如果master和slave网络链接断掉了，slave会让master 从上次的replicat offset开始继续复制，如果没有找到对应的offset，那么就会执行一次resynchronization。 无磁盘化复制master在内存中直接创建rdb，然后发送给slave，不会再自己本地落地磁盘 123repl-diskless-sync# 等待一定时间在开始复制，因为要等更多的slave重新连接过来repl-diskless-sync-delay 过期Keyslave 不存在过期key，智慧等待master过期key。如果master过期或者LRU淘汰了一个key，那么会模拟一个del命令发送给slave。 主从复制会存在的问题 一旦主节点宕机，从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。 主节点的写能力受到单机的限制。 主节点的存储能力受到单机的限制。 原生复制的弊端在早期的版本中也会比较突出，比如：redis复制中断后，从节点会发起psync。此时如果同步不成功，则会进行全量同步，主库执行全量备份的同时，可能会造成毫秒或秒级的卡顿。 比较主流的解决方案？哨兵。 哨兵 如图，是Redis Sentinel（哨兵）的架构图。Redis Sentinel（哨兵）主要功能包括主节点存活检测、主从运行情况检测、自动故障转移、主从切换。Redis Sentinel最小配置是一主一从。 Redis的Sentinel系统可以用来管理多个Redis服务器，该系统可以执行以下四个任务： 监控：不断检查主服务器和从服务器是否正常运行。 通知：当被监控的某个redis服务器出现问题，Sentinel通过API脚本向管理员或者其他应用程序发出通知。 自动故障转移：当主节点不能正常工作时，Sentinel会开始一次自动的故障转移操作，它会将与失效主节点是主从关系的其中一个从节点升级为新的主节点，并且将其他的从节点指向新的主节点，这样人工干预就可以免了。 配置提供者：在Redis Sentinel模式下，客户端应用在初始化时连接的是Sentinel节点集合，从中获取主节点的信息。 哨兵的工作原理 每个Sentinel节点都需要定期执行以下任务：每个Sentinel以每秒一次的频率，向它所知的主服务器、从服务器以及其他的Sentinel实例发送一个PING命令。（如图） 如果一个实例距离最后一次有效回复PING命令的时间超过down-after-milliseconds所指定的值，那么这个实例会被Sentinel标记为主观下线。（如图） 如果一个主服务器被标记为主观下线，那么正在监视这个服务器的所有Sentinel节点，要以每秒一次的频率确认主服务器的确进入了主观下线状态。 如果一个主服务器被标记为主观下线，并且有足够数量的Sentinel（至少要达到配置文件指定的数量）在指定的时间范围内同意这一判断，那么这个主服务器被标记为客观下线。 一般情况下，每个Sentinel会以每10秒一次的频率向它已知的所有主服务器和从服务器发送INFO命令，当一个主服务器被标记为客观下线时，Sentinel向下线主服务器的所有从服务器发送INFO命令的频率，会从10秒一次改为每秒一次。 Sentinel和其他Sentinel协商客观下线的主节点的状态，如果处于SDOWN状态，则投票自动选出新的主节点，将剩余从节点指向新的主节点进行数据复制。 当没有足够数量的Sentinel同意主服务器下线时，主服务器的客观下线状态就会被移除。当主服务器重新向Sentinel的PING命令返回有效回复时，主服务器的主观下线状态就会被移除 生产环境中redis是怎么部署的机器什么配置32G内存 + 8核CPU + 1T磁盘。分配给redis是10g内存。(生产环境，redis内存尽量不超过10g) redis cluster10台机器，5台机器部署了redis主实例，另外5台机器部署了redis的从实例，每个主实例挂了一个从实例，5个节点对外提供写服务，每个节点的读写高峰QPS可能达到每秒5万，5台机器最多是每秒25万读写请求。 高峰请求 3500请求/s. 因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis从实例会自动变成主实例继续提供读写服务。 内存中写的是什么数据？每条数据大小是多少？商品数据，每条数据10kb.100条是1mb，10万条数据是1g。常驻内存是200万条数据，占用内存是20g，仅仅不到中内存的50%。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>缓存穿透</tag>
        <tag>缓存雪崩</tag>
        <tag>原理</tag>
        <tag>redis</tag>
        <tag>主从复制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis为什么用跳表而不用平衡树？]]></title>
    <url>%2Fredis-skiplist-why%2F</url>
    <content type="text"><![CDATA[Redis里面使用skiplist是为了实现sorted set这种对外的数据结构。sorted set提供的操作非常丰富，可以满足非常多的应用场景。这也意味着，sorted set相对来说实现比较复杂。同时，skiplist这种数据结构对于很多人来说都比较陌生，因为大部分学校里的算法课都没有对这种数据结构进行过详细的介绍。因此，为了介绍得足够清楚，本文会比这个系列的其它几篇花费更多的篇幅。 我们将大体分成三个部分进行介绍： 介绍经典的skiplist数据结构，并进行简单的算法分析。这一部分的介绍，与Redis没有直接关系。我会尝试尽量使用通俗易懂的语言进行描述。 讨论Redis里的skiplist的具体实现。为了支持sorted set本身的一些要求，在经典的skiplist基础上，Redis里的相应实现做了若干改动。 讨论sorted set是如何在skiplist, dict和ziplist基础上构建起来的。 我们在讨论中还会涉及到两个Redis配置（在redis.conf中的ADVANCED CONFIG部分）： zset-max-ziplist-entries 128 zset-max-ziplist-value 64我们在讨论中会详细解释这两个配置的含义。 注：本文讨论的代码实现基于Redis源码的3.2分支。 skiplist数据结构简介skiplist本质上也是一种查找结构，用于解决算法中的查找问题（Searching），即根据给定的key，快速查到它所在的位置（或者对应的value）。 我们在《Redis内部数据结构详解》系列的第一篇中介绍dict的时候，曾经讨论过：一般查找问题的解法分为两个大类：一个是基于各种平衡树，一个是基于哈希表。但skiplist却比较特殊，它没法归属到这两大类里面。 这种数据结构是由William Pugh发明的，最早出现于他在1990年发表的论文《Skip Lists: A Probabilistic Alternative to Balanced Trees》。对细节感兴趣的同学可以下载论文原文来阅读。 skiplist，顾名思义，首先它是一个list。实际上，它是在有序链表的基础上发展起来的。 我们先来看一个有序链表，如下图（最左侧的灰色节点表示一个空的头结点）： 在这样一个链表中，如果我们要查找某个数据，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点，或者找到第一个比给定数据大的节点为止（没找到）。也就是说，时间复杂度为O(n)。同样，当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置。 假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图： 这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半（上图中是7, 19, 26）。现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的： 23首先和7比较，再和19比较，比它们都大，继续向后比较。 但23和26比较的时候，比26要小，因此回到下面的链表（原链表），与22比较。 23比22要大，沿下面的指针继续向后和26比较。23比26小，说明待查数据23在原链表中不存在，而且它的插入位置应该在22和26之间。 在这个查找过程中，由于新增加的指针，我们不再需要与链表中每个节点逐个进行比较了。需要比较的节点数大概只有原来的一半。 利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。如下图： 在这个新的三层链表结构上，如果我们还是查找23，那么沿着最上层链表首先要比较的是19，发现23比19大，接下来我们就知道只需要到19的后面去继续查找，从而一下子跳过了19前面的所有节点。可以想象，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。 skiplist正是受这种多层链表的想法的启发而设计出来的。实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。 skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程： 从上面skiplist的创建和插入过程可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。这在后面我们还会提到。 根据上图中的skiplist结构，我们很容易理解这种数据结构的名字的由来。skiplist，翻译成中文，可以翻译成“跳表”或“跳跃表”，指的就是除了最下面第1层链表之外，它会产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点（而且越高层的链表跳过的节点越多）。这就使得我们在查找数据的时候能够先在高层的链表中进行查找，然后逐层降低，最终降到第1层链表来精确地确定数据位置。在这个过程中，我们跳过了一些节点，从而也就加快了查找速度。 刚刚创建的这个skiplist总共包含4层链表，现在假设我们在它里面依然查找23，下图给出了查找路径： 需要注意的是，前面演示的各个节点的插入过程，实际上在插入之前也要先经历一个类似的查找过程，在确定插入位置后，再完成插入操作。 至此，skiplist的查找和插入操作，我们已经很清楚了。而删除操作与插入操作类似，我们也很容易想象出来。这些操作我们也应该能很容易地用代码实现出来。 当然，实际应用中的skiplist每个节点应该包含key和value两部分。前面的描述中我们没有具体区分key和value，但实际上列表中是按照key进行排序的，查找过程也是根据key在比较。 但是，如果你是第一次接触skiplist，那么一定会产生一个疑问：节点插入时随机出一个层数，仅仅依靠这样一个简单的随机数操作而构建出来的多层链表结构，能保证它有一个良好的查找性能吗？为了回答这个疑问，我们需要分析skiplist的统计性能。 在分析之前，我们还需要着重指出的是，执行插入操作时计算随机数的过程，是一个很关键的过程，它对skiplist的统计特性有着很重要的影响。这并不是一个普通的服从均匀分布的随机数，它的计算过程如下： 首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。 如果一个节点有第i层(i&gt;=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。 节点最大的层数不允许超过一个最大值，记为MaxLevel。 这个计算随机层数的伪码如下所示： randomLevel() level := 1 // random()返回一个[0...1)的随机数 while random() &lt; p and level &lt; MaxLevel do level := level + 1 return level复制代码randomLevel()的伪码中包含两个参数，一个是p，一个是MaxLevel。在Redis的skiplist实现中，这两个参数的取值为： p = 1/4 MaxLevel = 32复制代码skiplist的算法性能分析在这一部分，我们来简单分析一下skiplist的时间复杂度和空间复杂度，以便对于skiplist的性能有一个直观的了解。如果你不是特别偏执于算法的性能分析，那么可以暂时跳过这一小节的内容。 我们先来计算一下每个节点所包含的平均指针数目（概率期望）。节点包含的指针数目，相当于这个算法在空间上的额外开销(overhead)，可以用来度量空间复杂度。 根据前面randomLevel()的伪码，我们很容易看出，产生越高的节点层数，概率越低。定量的分析如下： 节点层数至少为1。而大于1的节点层数，满足一个概率分布。 节点层数恰好等于1的概率为1-p。 节点层数大于等于2的概率为p，而节点层数恰好等于2的概率为p(1-p)。 节点层数大于等于3的概率为p2，而节点层数恰好等于3的概率为p2(1-p)。 节点层数大于等于4的概率为p3，而节点层数恰好等于4的概率为p3(1-p)。 …… 因此，一个节点的平均层数（也即包含的平均指针数目），计算如下： 现在很容易计算出： 当p=1/2时，每个节点所包含的平均指针数目为2； 当p=1/4时，每个节点所包含的平均指针数目为1.33。这也是Redis里的skiplist实现在空间上的开销。 接下来，为了分析时间复杂度，我们计算一下skiplist的平均查找长度。查找长度指的是查找路径上跨越的跳数，而查找过程中的比较次数就等于查找长度加1。以前面图中标出的查找23的查找路径为例，从左上角的头结点开始，一直到结点22，查找长度为6。 为了计算查找长度，这里我们需要利用一点小技巧。我们注意到，每个节点插入的时候，它的层数是由随机函数randomLevel()计算出来的，而且随机的计算不依赖于其它节点，每次插入过程都是完全独立的。所以，从统计上来说，一个skiplist结构的形成与节点的插入顺序无关。 这样的话，为了计算查找长度，我们可以将查找过程倒过来看，从右下方第1层上最后到达的那个节点开始，沿着查找路径向左向上回溯，类似于爬楼梯的过程。我们假设当回溯到某个节点的时候，它才被插入，这虽然相当于改变了节点的插入顺序，但从统计上不影响整个skiplist的形成结构。 现在假设我们从一个层数为i的节点x出发，需要向左向上攀爬k层。这时我们有两种可能： 如果节点x有第(i+1)层指针，那么我们需要向上走。这种情况概率为p。 如果节点x没有第(i+1)层指针，那么我们需要向左走。这种情况概率为(1-p)。 这两种情形如下图所示： 用C(k)表示向上攀爬k个层级所需要走过的平均查找路径长度（概率期望），那么： C(0)=0 C(k)=(1-p)×(上图中情况b的查找长度) + p×(上图中情况c的查找长度)代入，得到一个差分方程并化简： C(k)=(1-p)(C(k)+1) + p(C(k-1)+1) C(k)=1/p+C(k-1) C(k)=k/p这个结果的意思是，我们每爬升1个层级，需要在查找路径上走1/p步。而我们总共需要攀爬的层级数等于整个skiplist的总层数-1。 那么接下来我们需要分析一下当skiplist中有n个节点的时候，它的总层数的概率均值是多少。这个问题直观上比较好理解。根据节点的层数随机算法，容易得出： 第1层链表固定有n个节点； 第2层链表平均有n*p个节点； 第3层链表平均有n*p2个节点； … 所以，从第1层到最高层，各层链表的平均节点数是一个指数递减的等比数列。容易推算出，总层数的均值为log1/pn，而最高层的平均节点数为1/p。 综上，粗略来计算的话，平均查找长度约等于： C(log1/pn-1)=(log1/pn-1)/p即，平均时间复杂度为O(log n)。 当然，这里的时间复杂度分析还是比较粗略的。比如，沿着查找路径向左向上回溯的时候，可能先到达左侧头结点，然后沿头结点一路向上；还可能先到达最高层的节点，然后沿着最高层链表一路向左。但这些细节不影响平均时间复杂度的最后结果。另外，这里给出的时间复杂度只是一个概率平均值，但实际上计算一个精细的概率分布也是有可能的。详情还请参见William Pugh的论文《Skip Lists: A Probabilistic Alternative to Balanced Trees》。 skiplist与平衡树、哈希表的比较 skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。 在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。 从算法实现难度上来比较，skiplist比平衡树要简单得多。 Redis中的skiplist实现在这一部分，我们讨论Redis中的skiplist实现。 在Redis中，skiplist被用于实现暴露给外部的一个数据结构：sorted set。准确地说，sorted set底层不仅仅使用了skiplist，还使用了ziplist和dict。这几个数据结构的关系，我们下一章再讨论。现在，我们先花点时间把sorted set的关键命令看一下。这些命令对于Redis里skiplist的实现，有重要的影响。 sorted set的命令举例sorted set是一个有序的数据集合，对于像类似排行榜这样的应用场景特别适合。 现在我们来看一个例子，用sorted set来存储代数课（algebra）的成绩表。原始数据如下： Alice 87.5 Bob 89.0 Charles 65.5 David 78.0 Emily 93.5 Fred 87.5 这份数据给出了每位同学的名字和分数。下面我们将这份数据存储到sorted set里面去： 对于上面的这些命令，我们需要的注意的地方包括： 前面的6个zadd命令，将6位同学的名字和分数(score)都输入到一个key值为algebra的sorted set里面了。注意Alice和Fred的分数相同，都是87.5分。 zrevrank命令查询Alice的排名（命令中的rev表示按照倒序排列，也就是从大到小），返回3。排在Alice前面的分别是Emily、Bob、Fred，而排名(rank)从0开始计数，所以Alice的排名是3。注意，其实Alice和Fred的分数相同，这种情况下sorted set会把分数相同的元素，按照字典顺序来排列。按照倒序，Fred排在了Alice的前面。 zscore命令查询了Charles对应的分数。 zrevrange命令查询了从大到小排名为0~3的4位同学。 zrevrangebyscore命令查询了分数在80.0和90.0之间的所有同学，并按分数从大到小排列。 总结一下，sorted set中的每个元素主要表现出3个属性： 数据本身（在前面的例子中我们把名字存成了数据）。 每个数据对应一个分数(score)。 根据分数大小和数据本身的字典排序，每个数据会产生一个排名(rank)。可以按正序或倒序。 Redis中skiplist实现的特殊性我们简单分析一下前面出现的几个查询命令： zrevrank由数据查询它对应的排名，这在前面介绍的skiplist中并不支持。 zscore由数据查询它对应的分数，这也不是skiplist所支持的。 zrevrange根据一个排名范围，查询排名在这个范围内的数据。这在前面介绍的skiplist中也不支持。 zrevrangebyscore根据分数区间查询数据集合，是一个skiplist所支持的典型的范围查找（score相当于key）。 实际上，Redis中sorted set的实现是这样的： 当数据较少时，sorted set是由一个ziplist来实现的。 当数据多的时候，sorted set是由一个dict + 一个skiplist来实现的。简单来讲，dict用来查询数据到分数的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。 这里sorted set的构成我们在下一章还会再详细地讨论。现在我们集中精力来看一下sorted set与skiplist的关系，： zscore的查询，不是由skiplist来提供的，而是由那个dict来提供的。 为了支持排名(rank)，Redis里对skiplist做了扩展，使得根据排名能够快速查到数据，或者根据分数查到数据之后，也同时很容易获得排名。而且，根据排名的查找，时间复杂度也为O(log n)。 zrevrange的查询，是根据排名查数据，由扩展后的skiplist来提供。 zrevrank是先在dict中由数据查到分数，再拿分数到skiplist中去查找，查到后也同时获得了排名。 前述的查询过程，也暗示了各个操作的时间复杂度： zscore只用查询一个dict，所以时间复杂度为O(1) zrevrank, zrevrange, zrevrangebyscore由于要查询skiplist，所以zrevrank的时间复杂度为O(log n)，而zrevrange, zrevrangebyscore的时间复杂度为O(log(n)+M)，其中M是当前查询返回的元素个数。 总结起来，Redis中的skiplist跟前面介绍的经典的skiplist相比，有如下不同： 分数(score)允许重复，即skiplist的key允许重复。这在最开始介绍的经典skiplist中是不允许的。 在比较时，不仅比较分数（相当于skiplist的key），还比较数据本身。在Redis的skiplist实现中，数据本身的内容唯一标识这份数据，而不是由key来唯一标识。另外，当多个元素分数相同的时候，还需要根据数据内容来进字典排序。 第1层链表不是一个单向链表，而是一个双向链表。这是为了方便以倒序方式获取一个范围内的元素。 在skiplist中可以很方便地计算出每个元素的排名(rank)。 skiplist的数据结构定义#define ZSKIPLIST_MAXLEVEL 32 #define ZSKIPLIST_P 0.25 typedef struct zskiplistNode { robj *obj; double score; struct zskiplistNode *backward; struct zskiplistLevel { struct zskiplistNode *forward; unsigned int span; } level[]; } zskiplistNode; typedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level; } zskiplist;这段代码出自server.h，我们来简要分析一下： 开头定义了两个常量，ZSKIPLIST_MAXLEVEL和ZSKIPLIST_P，分别对应我们前面讲到的skiplist的两个参数：一个是MaxLevel，一个是p。 zskiplistNode定义了skiplist的节点结构。 obj字段存放的是节点数据，它的类型是一个string robj。本来一个string robj可能存放的不是sds，而是long型，但zadd命令在将数据插入到skiplist里面之前先进行了解码，所以这里的obj字段里存储的一定是一个sds。有关robj的详情可以参见系列文章的第三篇：《Redis内部数据结构详解(3)——robj》。这样做的目的应该是为了方便在查找的时候对数据进行字典序的比较，而且，skiplist里的数据部分是数字的可能性也比较小。 score字段是数据对应的分数。 backward字段是指向链表前一个节点的指针（前向指针）。节点只有1个前向指针，所以只有第1层链表是一个双向链表。 level[]存放指向各层链表后一个节点的指针（后向指针）。每层对应1个后向指针，用forward字段表示。另外，每个后向指针还对应了一个span值，它表示当前的指针跨越了多少个节点。span用于计算元素排名(rank)，这正是前面我们提到的Redis对于skiplist所做的一个扩展。需要注意的是，level[]是一个柔性数组（flexible array member），因此它占用的内存不在zskiplistNode结构里面，而需要插入节点的时候单独为它分配。也正因为如此，skiplist的每个节点所包含的指针数目才是不固定的，我们前面分析过的结论——skiplist每个节点包含的指针数目平均为1/(1-p)——才能有意义。 zskiplist定义了真正的skiplist结构，它包含： 头指针header和尾指针tail。 链表长度length，即链表包含的节点总数。注意，新创建的skiplist包含一个空的头指针，这个头指针不包含在length计数中。 level表示skiplist的总层数，即所有节点层数的最大值。 下图以前面插入的代数课成绩表为例，展示了Redis中一个skiplist的可能结构： 注意：图中前向指针上面括号中的数字，表示对应的span的值。即当前指针跨越了多少个节点，这个计数不包括指针的起点节点，但包括指针的终点节点。 假设我们在这个skiplist中查找score=89.0的元素（即Bob的成绩数据），在查找路径中，我们会跨域图中标红的指针，这些指针上面的span值累加起来，就得到了Bob的排名(2+2+1)-1=4（减1是因为rank值以0起始）。需要注意这里算的是从小到大的排名，而如果要算从大到小的排名，只需要用skiplist长度减去查找路径上的span累加值，即6-(2+2+1)=1。 可见，在查找skiplist的过程中，通过累加span值的方式，我们就能很容易算出排名。相反，如果指定排名来查找数据（类似zrange和zrevrange那样），也可以不断累加span并时刻保持累加值不超过指定的排名，通过这种方式就能得到一条O(log n)的查找路径。 Redis中的sorted set我们前面提到过，Redis中的sorted set，是在skiplist, dict和ziplist基础上构建起来的: 当数据较少时，sorted set是由一个ziplist来实现的。 当数据多的时候，sorted set是由一个叫zset的数据结构来实现的，这个zset包含一个dict + 一个skiplist。dict用来查询数据到分数(score)的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。 在这里我们先来讨论一下前一种情况——基于ziplist实现的sorted set。在本系列前面关于ziplist的文章里，我们介绍过，ziplist就是由很多数据项组成的一大块连续内存。由于sorted set的每一项元素都由数据和score组成，因此，当使用zadd命令插入一个(数据, score)对的时候，底层在相应的ziplist上就插入两个数据项：数据在前，score在后。 ziplist的主要优点是节省内存，但它上面的查找操作只能按顺序查找（可以正序也可以倒序）。因此，sorted set的各个查询操作，就是在ziplist上从前向后（或从后向前）一步步查找，每一步前进两个数据项，跨域一个(数据, score)对。 随着数据的插入，sorted set底层的这个ziplist就可能会转成zset的实现（转换过程详见t_zset.c的zsetConvert）。那么到底插入多少才会转呢？ 还记得本文开头提到的两个Redis配置吗？ zset-max-ziplist-entries 128 zset-max-ziplist-value 64这个配置的意思是说，在如下两个条件之一满足的时候，ziplist会转成zset（具体的触发条件参见t_zset.c中的zaddGenericCommand相关代码）： 当sorted set中的元素个数，即(数据, score)对的数目超过128的时候，也就是ziplist数据项超过256的时候。 当sorted set中插入的任意一个数据的长度超过了64的时候。 最后，zset结构的代码定义如下： typedef struct zset { dict *dict; zskiplist *zsl; } zset;Redis为什么用skiplist而不用平衡树？在前面我们对于skiplist和平衡树、哈希表的比较中，其实已经不难看出Redis里使用skiplist而不用平衡树的原因了。现在我们看看，对于这个问题，Redis的作者 @antirez 是怎么说的： There are a few reasons: 1) They are not very memory intensive. It’s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees. 2) A sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees. 3) They are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code. 这段话原文出处： news.ycombinator.com/item?id=117… 这里从内存占用、对范围查找的支持和实现难易程度这三方面总结的原因，我们在前面其实也都涉及到了。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群搭建]]></title>
    <url>%2Fredis-cluster%2F</url>
    <content type="text"><![CDATA[手把手教你搭建一个redis集群 脚本部署123456789101112131415161718192021222324252627282930313233343536#!/bin/bash # auto start redis programmkdir /usr/local/rediscd /usr/local/redistar -zxvf /redis-5.0.4.tar.gzcd redis-5.0.4/src# 编译make make MALLOC=libc# 让端口可用firewall-cmd --add-port=16379/tcp --permanentfirewall-cmd --add-port=6379/tcp --permanentmkdir /usr/local/redis/data# 把redis。conf配置文件复制到src文件夹下cp /usr/local/redis/redis-5.0.4/redis.conf /usr/local/redis/redis-5.0.4/src mkdir /usr/local/redis/log# 修改日志文档sed -i &apos;s/logfile &quot;&quot;/logfile \/usr\/local\/redis\/log\/redis.log/g&apos; redis.conf # redis在后台运行sed -i &apos;s/daemonize no/daemonize yes/g&apos; redis.conf# 修改bind的ip地址sed -i &apos;s/bind 127.0.0.1/bind 0.0.0.0/g&apos; redis.conf # 设定开始故障转移的时间sed -i &apos;s/# cluster-node-timeout 15000/cluster-node-timeout 15000/g&apos; redis.conf# 判断是否有故障转移的资格sed -i &apos;s/# cluster-replica-validity-factor 10/cluster-replica-validity-factor 10/g&apos; redis.conf# 确定故障转移需要几个节点sed -i &apos;s/# cluster-migration-barrier 1/cluster-migration-barrier 1/g&apos; redis.conf# 修改dir文件目录sed -i &apos;s/dir .\//dir \/usr\/local\/redis\/data/g&apos; redis.conf# 开启集群模式sed -i &apos;s/# cluster-enabled yes/cluster-enabled yes/g&apos; redis.conf# 启动redis服务/usr/local/redis/redis-5.0.4/src/redis-server /usr/local/redis/redis-5.0.4/src/redis.conf#集群搭建/usr/local/redis/redis-5.0.4/src/redis-cli --cluster create 192.100.3.90:6379 192.100.3.91:6379 192.100.3.92:6379 --cluster-replicas 0 docker部署12345678910111213141516171819#拉取镜像docker pull redis:5.0.2#创建容器docker create --name redis-node01 --net host -v /data/redis-data/node01:/dataredis:5.0.2 --cluster-enabled yes --cluster-config-file nodes-node-01.conf --port6379docker create --name redis-node02 --net host -v /data/redis-data/node02:/dataredis:5.0.2 --cluster-enabled yes --cluster-config-file nodes-node-02.conf --port6380docker create --name redis-node03 --net host -v /data/redis-data/node03:/dataredis:5.0.2 --cluster-enabled yes --cluster-config-file nodes-node-03.conf --port6381#启动容器docker start redis-node01 redis-node02 redis-node03#进入redis-node01容器进行操作docker exec -it redis-node01 /bin/bash#172.16.55.185是主机的ip地址redis-cli --cluster create 172.16.55.185:6379 172.16.55.185:6380 172.16.55.185:6381--cluster-replicas 0 Redis5 高可用集群概述HA(High Available，高可用性群集)机集群系统简称，是保证业务连续性的有效解决方案，一般有两个或两个以上的节点，且分为活动节点及备用节点。通常把正在执 行业务的称为活动节点，而作为活动节点的一个备份的则称为备用节点。当活动节点出现问题，导致正在运行的业务（任务）不能正常运行时，备用节点此时就会侦测到，并立即接续活动节点来执行业务。从而实现业务的不中断或短暂中断。 Redis 一般以主/从方式部署（这里讨论的应用从实例主要用于备份，主实例提供读写）该方式要实现 HA 主要有如下几种方案： keepalived： 通过 keepalived 的虚拟 IP，提供主从的统一访问，在主出现问题时， 通过 keepalived 运行脚本将从提升为主，待主恢复后先同步后自动变为主，该方案的好处是主从切换后，应用程序不需要知道(因为访问的虚拟 IP 不变)，坏处是引入 keepalived 增加部署复杂性，在有些情况下会导致数据丢失 zookeeper： 通过 zookeeper 来监控主从实例， 维护最新有效的 IP， 应用通过 zookeeper 取得 IP，对 Redis 进行访问，该方案需要编写大量的监控代码 sentinel： 通过 Sentinel 监控主从实例，自动进行故障恢复，该方案有个缺陷：因为主从实例地址( IP &amp; PORT )是不同的，当故障发生进行主从切换后，应用程序无法知道新地址，故在 Jedis2.2.2 中新增了对 Sentinel 的支持，应用通过 redis.clients.jedis.JedisSentinelPool.getResource() 取得的 Jedis 实例会及时更新到新的主实例地址 注意： sentinel 是解决 HA 问题的，cluster 是解决主从复制问题的，不重复，并且经常一起用 Redis SentinelRedis 集群可以在一组 redis 节点之间实现高可用性和 sharding。在集群中会有 1 个 master 和多个 slave 节点。当 master 节点失效时，应选举出一个 slave 节点作为新的 master。然而 Redis 本身 (包括它的很多客户端) 没有实现自动故障发现并进行主备切换的能力，需要外部的监控方案来实现自动故障恢复。 Redis Sentinel 是官方推荐的高可用性解决方案。它是 Redis 集群的监控管理工具，可以提供节点监控、通知、自动故障恢复和客户端配置发现服务。 基于 Docker 安装 Redis 集群2018 年 10 月 Redis 发布了稳定版本的 5.0 版本，推出了各种新特性，其中一点是放弃 Ruby 的集群方式，改为 使用 C 语言编写的 redis-cli 的方式，使集群的构建方式复杂度大大降低 下载所需镜像 Redis (5.x 测试有效)：docker pull redis Redis Trib (用于创建集群)：docker pull zvelo/redis-trib 创建配置文件官方配置文件地址：http://download.redis.io/redis-stable/redis.conf ，我们部署 3 个节点，需要分别创建 3 个配置文件，路径如下 renode1：cluster/node1/redis.conf renode2：cluster/node2/redis.conf renode3：cluster/node3/redis.conf 配置文件内容如下 (端口号不要重复) 1234567891011121314151617181920bind 0.0.0.0# 关闭保护模式protected-mode no# 绑定自定义端口port 6379# 禁止 Redis 后台运行# daemonize yespidfile /var/run/redis_6379.pid# 开启集群cluster-enabled yes# 集群的配置，配置文件首次启动自动生成cluster-config-file nodes_6379.conf# 开启 AOF# appendonly yes# 集群的 IPcluster-announce-ip 192.168.x.x# 集群的端口cluster-announce-port 6379# 集群的总线端口cluster-announce-bus-port 16379 创建资源配置docker-compose.yml 配置文件如下 1234567891011121314151617181920212223242526272829303132333435version: &apos;3.1&apos;services: renode1: image: redis container_name: renode1 restart: always ports: - 6379:6379 - 16379:16379 volumes: - ./cluster/node1:/usr/local/etc/redis command: redis-server /usr/local/etc/redis/redis.conf renode2: image: redis container_name: renode2 restart: always ports: - 6380:6380 - 16380:16380 volumes: - ./cluster/node2:/usr/local/etc/redis command: redis-server /usr/local/etc/redis/redis.conf renode3: image: redis container_name: renode3 restart: always ports: - 6381:6381 - 16381:16381 volumes: - ./cluster/node3:/usr/local/etc/redis command: redis-server /usr/local/etc/redis/redis.conf 1docker-compose up -d 创建集群123456789101112131415161718192021222324252627282930docker run --rm -it zvelo/redis-trib create 192.168.141.220:6379 192.168.141.220:6380 192.168.141.220:6381# 输出如下&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 3 nodes...Using 3 masters:192.168.141.220:6379192.168.141.220:6380192.168.141.220:6381M: 9250c85592b7bb8a19636b90e4cf22590bd3334f 192.168.141.220:6379 slots:0-5460 (5461 slots) masterM: 7373de7b44ee50a1e4f653bfba1bb808138e7e3a 192.168.141.220:6380 slots:5461-10922 (5462 slots) masterM: ec7e6e4cdd142249e3aa83541044932655d75b66 192.168.141.220:6381 slots:10923-16383 (5461 slots) masterCan I set the above configuration? (type &apos;yes&apos; to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join..&gt;&gt;&gt; Performing Cluster Check (using node 192.168.141.220:6379)M: 9250c85592b7bb8a19636b90e4cf22590bd3334f 192.168.141.220:6379 slots:0-5460 (5461 slots) masterM: 7373de7b44ee50a1e4f653bfba1bb808138e7e3a 192.168.141.220:6380 slots:5461-10922 (5462 slots) masterM: ec7e6e4cdd142249e3aa83541044932655d75b66 192.168.141.220:6381 slots:10923-16383 (5461 slots) master[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 验证集群是否成功 交互式进入容器 1docker exec -it renode1 /bin/bash 登录 Redis 1redis-cli -p 6379 查看集群信息 123456789101112131415161718127.0.0.1:6379&gt; cluster info# 输出如下cluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:3cluster_size:3cluster_current_epoch:3cluster_my_epoch:1cluster_stats_messages_ping_sent:860cluster_stats_messages_pong_sent:870cluster_stats_messages_sent:1730cluster_stats_messages_ping_received:868cluster_stats_messages_pong_received:860cluster_stats_messages_meet_received:2cluster_stats_messages_received:1730 查看集群节点 12345127.0.0.1:6379&gt; cluster nodes# 输出如下ec7e6e4cdd142249e3aa83541044932655d75b66 192.168.141.220:6381@16381 master - 0 1569665070102 3 connected 10923-163837373de7b44ee50a1e4f653bfba1bb808138e7e3a 192.168.141.220:6380@16380 master - 0 1569665069094 2 connected 5461-109229250c85592b7bb8a19636b90e4cf22590bd3334f 192.168.141.220:6379@16379 myself,master - 0 1569665069000 1 connected 0-5460 查看集群插槽 123456789101112131415161727.0.0.1:6379&gt; cluster slots# 输出如下1) 1) (integer) 10923 2) (integer) 16383 3) 1) &quot;192.168.141.220&quot; 2) (integer) 6381 3) &quot;ec7e6e4cdd142249e3aa83541044932655d75b66&quot;2) 1) (integer) 5461 2) (integer) 10922 3) 1) &quot;192.168.141.220&quot; 2) (integer) 6380 3) &quot;7373de7b44ee50a1e4f653bfba1bb808138e7e3a&quot;3) 1) (integer) 0 2) (integer) 5460 3) 1) &quot;192.168.141.220&quot; 2) (integer) 6379 3) &quot;9250c85592b7bb8a19636b90e4cf22590bd3334f&quot; 基于 Docker 安装 Redis Sentinel创建配置文件我们部署 3 个 Sentinel 节点，需要分别创建 3 个配置文件，路径如下 resentinel1：cluster/node1/sentinel.conf resentinel2：cluster/node2/sentinel.conf resentinel3：cluster/node3/sentinel.conf 配置文件内容如下 (端口号不要重复) 123456789bind 0.0.0.0port 26379dir /tmp# 自定义集群名，其中 192.168.141.220 为 Redis Master 的 IP，6379 为 Redis Master 的端口，2 为最小投票数（因为有 3 台 Sentinel 所以可以设置成 2）sentinel monitor rmaster 192.168.141.220 6379 2sentinel down-after-milliseconds rmaster 30000sentinel parallel-syncs rmaster 1sentinel failover-timeout rmaster 180000sentinel deny-scripts-reconfig yes 创建资源配置docker-compose.yml 配置文件如下 1234567891011121314151617181920212223242526version: &apos;3.1&apos;services: resentinel1: image: redis container_name: resentinel1 ports: - 26379:26379 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - ./cluster/node1/sentinel.conf:/usr/local/etc/redis/sentinel.conf resentinel2: image: redis container_name: resentinel2 ports: - 26380:26380 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - ./cluster/node2/sentinel.conf:/usr/local/etc/redis/sentinel.conf resentinel3: image: redis container_name: resentinel3 ports: - 26381:26381 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - ./cluster/node3/sentinel.conf:/usr/local/etc/redis/sentinel.conf 验证集群是否成功 交互式进入容器 1docker exec -it resentinel1 /bin/bash 登录 Redis Sentinel 1redis-cli -p 26379 查看集群 Master 信息 123456789101112131415161718192021222324252627282930313233343536373839404142127.0.0.1:26379&gt; sentinel master rmaster# 输出如下 1) &quot;name&quot; 2) &quot;rmaster&quot; 3) &quot;ip&quot; 4) &quot;192.168.141.220&quot; 5) &quot;port&quot; 6) &quot;6379&quot; 7) &quot;runid&quot; 8) &quot;30055483aeb9d75f35c0046aaec03440731e3e88&quot; 9) &quot;flags&quot;10) &quot;master&quot;11) &quot;link-pending-commands&quot;12) &quot;0&quot;13) &quot;link-refcount&quot;14) &quot;1&quot;15) &quot;last-ping-sent&quot;16) &quot;0&quot;17) &quot;last-ok-ping-reply&quot;18) &quot;413&quot;19) &quot;last-ping-reply&quot;20) &quot;413&quot;21) &quot;down-after-milliseconds&quot;22) &quot;30000&quot;23) &quot;info-refresh&quot;24) &quot;2878&quot;25) &quot;role-reported&quot;26) &quot;master&quot;27) &quot;role-reported-time&quot;28) &quot;143537&quot;29) &quot;config-epoch&quot;30) &quot;0&quot;31) &quot;num-slaves&quot;32) &quot;0&quot;33) &quot;num-other-sentinels&quot;34) &quot;2&quot;35) &quot;quorum&quot;36) &quot;2&quot;37) &quot;failover-timeout&quot;38) &quot;180000&quot;39) &quot;parallel-syncs&quot;40) &quot;1&quot;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>安装教程</tag>
        <tag>redis</tag>
        <tag>集群</tag>
        <tag>doker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬链接、软连接引出的inode]]></title>
    <url>%2Flinux-inode%2F</url>
    <content type="text"><![CDATA[inode定义inode是linux系统中用作数据索引的标识符。简单来说，inode指示了一个文件的基本信息，如inode编号、修改时间、文件的位置等。 如同一本书的目录，会直接告诉你想看的章节是在第几页。不同的是，书是以页为单位的，而Linux文件存取是以“块”为单位的。 找寻文件操作系统在读取硬盘的时候，会一次性读取一个“块”（一个“块”的大小往往是4KB，包含了连续8个扇区，每个扇区存储512个字节）。而inode就告诉了文件位于哪个“块”，于是系统就会从这个“块”开始读取内容，我们就可以看到文件的内容。 每个文件都有对应的inode，存储着这个文件的基本信息。Linux系统不使用文件名，而使用inode号来识别文件。对于使用者，我们是通过文件名寻找、打开文件；对于系统，是通过以下三步找到的： 系统找到这个文件名对应的inode号 通过inode号，获取inode信息 根据inode信息，找到文件数据所在的block，读取内容 inode内容inode 包含了文件的以下基本信息： 文件的字节数 node 编号 文件拥有者的 Uid 文件所属group的 Gid 文件的读、写、执行权限 文件的时间戳，共有三个： change：inode 上一次变动的时间 modify：文件内容上一次变动的时间 access：文件上一次打开的时间 链接数，即有多少文件名指向这个inode 文件数据 block 的位置 我们可以使用 stat 命令查看文件的inode信息，如： 123456789$ stat v0.1.0.zip File: ‘v0.1.0.zip’ Size: 94267 Blocks: 192 IO Block: 4096 regular fileDevice: 811h/2065d Inode: 5659765 Links: 1Access: (0640/-rw-r-----) Uid: ( 3457/mart_bda) Gid: ( 3457/mart_bda)Access: 2018-06-12 14:22:18.434027485 +0800Modify: 2018-06-12 14:18:00.840994081 +0800Change: 2018-06-12 14:18:00.840994081 +0800 Birth: - 也可以在 ls 后加上 -i 直接获取inode编号: 12$ ls -i v0.1.0.zip 5659765 v0.1.0.zip inode大小inode存储了文件的基本信息，虽然信息很少，但是也会占用空间。硬盘格式化的时候，操作系统自动将硬盘分为两个区域： 数据区：存放文件内容 inode 区：存放 inode 包含的信息，也叫作 inode table 每个 inode 节点的大小，一般是 128 字节或 256 字节。inode节点的总数，在硬盘格式化时就固定了。一般，数据区每1KB或2KB，inode区就会增加一个 inode。 假如在一块 1GB 的硬盘中，每个 inode 节点的大小为 128 字节，那么 inode 表的大小就会达到 128 MB，占整块硬盘的 12.8%。既然 inode 节点总数是有限的，那么分区的节点数就有用完的时候，一旦 inode 用完，即使磁盘空间还有剩余，也不能再存放任何数据，因为需要保证每个文件必须有一个 inode。 查看每个硬盘分区的 inode 或者磁盘容量的使用情况，可以使用 df 命令加上参数 -i 或者 -h，如： 文件-h, –human-readable 使用人类可读的格式(预设值是不加这个选项的…) 文件-H, –si 很像 -h, 但是用 1000 为单位而不是用 1024 文件-i, –inodes 列出 inode 资讯，不列出已使用 block 12345678910111213141516171819202122$ df -iFilesystem Inodes IUsed IFree IUse% Mounted on/dev/sda5 275436544 801853 274634691 1% /devtmpfs 8192960 524 8192436 1% /devtmpfs 8195307 4 8195303 1% /dev/shmtmpfs 8195307 765 8194542 1% /runtmpfs 8195307 13 8195294 1% /sys/fs/cgroup/dev/sda2 204800 342 204458 1% /boot/dev/sdb1 11443200 3329257 8113943 30% /data0tmpfs 8195307 1 8195306 1% /run/user/0tmpfs 8195307 1 8195306 1% /run/user/3457$ df -hFilesystem Size Used Avail Use% Mounted on/dev/sda5 263G 134G 130G 51% /devtmpfs 32G 0 32G 0% /devtmpfs 32G 12K 32G 1% /dev/shmtmpfs 32G 394M 31G 2% /runtmpfs 32G 0 32G 0% /sys/fs/cgroup/dev/sda2 197M 139M 58M 71% /boot/dev/sdb1 11T 5.2T 5.2T 51% /data0tmpfs 6.3G 0 6.3G 0% /run/user/0tmpfs 6.3G 0 6.3G 0% /run/user/3457 关于 df -h -i 的区别，可以参考 Linux df命令。 文件操作对 inode 的影响要理解文件的操作对 inode 的影响，先要理解目录的原理。目录对外表现是一个容器，存放着子文件和子目录，实际上在系统内部，目录本身也是一个文件，目录文件的内容即是该目录下的文件名与 inode 号的映射表（即一个个的目录项）。 因此，linux访问一个文件时，要先查询到上一级目录，根据目录内容查找到文件对应的 inode号，然后读取对应的 block。 cp 命令系统内部会执行以下操作： 分配一个未被使用的 inode 号，在 inode 表中新添一个项目。如果是覆盖复制，则 inode号不变，沿用之前同名文件的 inode 号。 在目录中新建一个目录项，并指向步骤 1 中的 inode。 把数据复制到 block 中。 rm 命令系统内部会执行以下操作： 减少待删除文件名所对应的 inode 的链接数量，如果链接数变为0，则释放 inode，同时数据块放到可用空间中（对外表现为数据已删除，因为随时可以覆盖。如果没有覆盖，数据还可以恢复；一旦覆盖了，那么删除的数据无法恢复。）。 删除目录中的目录项。 mv 命令如果目标文件和源文件属于同一个文件系统： 在目标文件的目录中新建目录项 删除源文件的目录中的目录项 目标文件名会指向源文件名的 inode。因此该操作对 inode 没有影响（除了时间戳），对数据的位置也没有影响，不移动任何数据。 如果目标文件和源文件属于不同文件系统: 相当于 cp + rm。 ln 命令硬链接一般情况下，文件名和 inode 号是一一对应，但是也有可能多个文件名指向同一个inode号，即硬链接。 硬链接可以实现用不同的文件名访问同一个文件； 对文件内容修改，会影响到所有的文件名； 但是，删除一个文件名，不影响其他文件名的访问。 举个栗子创建硬链接的命令： 1ln [source file] [new file] 如： 12345678$ ll -h -itotal 479M5659849 -rw-r----- 1 mart_bda mart_bda 479M Jun 13 10:57 test_file$ ln test_file test_file_hardlink$ ll -i -htotal 957M5659849 -rw-r----- 2 mart_bda mart_bda 479M Jun 13 10:57 test_file5659849 -rw-r----- 2 mart_bda mart_bda 479M Jun 13 10:57 test_file_hardlink 这样，两个文件的 inode 号均为 5659849。 具体查看两个文件的 inode 内容： 123456789101112131415161718$ stat test_file File: ‘test_file’ Size: 501577774 Blocks: 979656 IO Block: 4096 regular fileDevice: 811h/2065d Inode: 5659849 Links: 2Access: (0640/-rw-r-----) Uid: ( 3457/mart_bda) Gid: ( 3457/mart_bda)Access: 2018-06-13 10:57:13.961409755 +0800Modify: 2018-06-13 10:57:14.931383436 +0800Change: 2018-06-13 10:58:11.382851699 +0800 Birth: -$ stat test_file_hardlink File: ‘test_file_hardlink’ Size: 501577774 Blocks: 979656 IO Block: 4096 regular fileDevice: 811h/2065d Inode: 5659849 Links: 2Access: (0640/-rw-r-----) Uid: ( 3457/mart_bda) Gid: ( 3457/mart_bda)Access: 2018-06-13 10:57:13.961409755 +0800Modify: 2018-06-13 10:57:14.931383436 +0800Change: 2018-06-13 10:58:11.382851699 +0800 Birth: - 可以看到，两个文件的 inode 内容完全相同，且 Links 变成了 2。修改任何一个文件名的内容，另一个文件名的内容也会同时改变，因为访问的就是硬盘中的同一块数据。 如果再将 test_file_hardlink 删掉，会使得 Links 变回 1。当这个值减到 0 时，说明没有文件名指向这个 inode，系统就会回收这个号码，以及所对应的 block 区域。 另外，对于目录的链接数，创建一个目录时，默认会生成两个目录项：. 和 .. 前者的 inode 号就是当前目录的 inode 号，等同于当前目录的硬链接；后者的 inode 号是父目录的 inode 号，等同于父目录的硬链接。 因此，任何一个目录的硬链接总数，总是等于 2 加上它的子目录总数（含隐藏目录，且除去. 和 ..）。 软链接软链接也可以通过不同的文件名访问同一块数据，但是与硬链接不同的是，两个文件名的 inode 是不一样的。 那如何访问同一块区域呢？ 比如文件 A 是文件 B 的软连接，那么文件 A 的内容存放的是文件 B 的路径名（可以通过这个找到文件 B 的目录项）。因此访问 A 时，会读取文件 B 的路径，进而读取文件 B 的内容。这样，对外表现来看，文件 A 和文件 B 的内容就相同了。类似于 windows 系统下的快捷方式。 举个栗子建立软链接的命令： 1ln -s [source file] [new file] 如： 12345678$ lltotal 489824-rw-r----- 1 mart_bda mart_bda 501577774 Jun 13 11:21 test_file$ ln -s test_file test_file_soft$ ll -h -itotal 479M5659853 -rw-r----- 1 mart_bda mart_bda 479M Jun 13 11:21 test_file5659854 lrwxrwxrwx 1 mart_bda mart_bda 9 Jun 13 11:22 test_file_soft -&gt; test_file 如果是对文件夹简历软链接，则为： 1ln -s /tmp/test_directory ./ 会自动地在当前目录建立一个文件夹 test_directory ，并指向 /tmp/test_directory 两个文件的 inode 号是不同的。 既然文件 A 是依赖文件 B 存在的，那么如果删除了文件 B，打开文件 A 就会报错：No such file or directory； 如果删除了文件 A，则对文件 B 的打开无影响，因为只是删除了“快捷方式”而已。 软连接的建立，不会影响到文件 B 的 inode 的任何信息，包括 Links。 硬链接和软链接的不同 本质不同：硬链接是指向同一个文件，软链接指向的不是同一个文件。 删除时：硬链接不受影响，软链接失效 创建链接时：创建硬链接链接数加1，创建软链接连接数不变 是否可以跨分区：硬链接不可以跨分区，软链接可以跨分区 目录是否可以创建链接：硬链接不可以对目录创建，软链接可以对目录创建 硬链接的inode号相同，软链接inode号不同 硬链接和软链接的占用空间分析硬链接不占用磁盘空间，软链接占用的空间只是存储路径所占用的极小空间。 ll –h 或者 ls –h这命令进行统计文件总大小的时候并不是从磁盘进行统计的，而是根据文件属性中的大小叠加得来的。而硬链接的文件属性中的大小就是就是inode号对应的数据块的大小，所以total中进行统计就把各个文件属性中的大小加起来作为总和，这种统计是不标准，也不具有代表性的， 真正的查看某个文件夹占用磁盘空间大小命令是：du –h 这个命令是从磁盘上进行统计，不会被文件的属性中大小影响，所以更准确]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>原理</tag>
        <tag>Linux</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态代理简介]]></title>
    <url>%2Fjava-dynamic-proxy%2F</url>
    <content type="text"><![CDATA[动态代理可以理解为，本来应该自己做的事情，却交给别人代为处理，这个过程就叫做动态代理。 动态代理的使用场景动态代理被广为人知的使用场景是 Spring 中的面向切面编程（AOP）。例如，依赖注入 @Autowired 和事务注解 @Transactional 等，都是利用动态代理实现的。 动态代理还可以封装一些 RPC 调用，也可以通过代理实现一个全局拦截器等。 动态代理和反射的关系JDK 原生提供的动态代理就是通过反射实现的，但动态代理的实现方式还可以是 ASM（一个短小精悍的字节码操作框架）、cglib（基于 ASM）等，并不局限于反射。 下面我们分别来看：JDK 原生动态代理和 cglib 的实现。 JDK原生动态代理123456789101112131415161718192021222324252627282930313233343536373839404142434445interface Animal &#123; void eat();&#125;class Dog implements Animal &#123; @Override public void eat() &#123; System.out.println("The dog is eating"); &#125;&#125;class Cat implements Animal &#123; @Override public void eat() &#123; System.out.println("The cat is eating"); &#125; &#125;// JDK 代理类class AnimalProxy implements InvocationHandler &#123; private Object target; // 代理对象 public Object getInstance(Object target) &#123; this.target = target; // 取得代理对象 return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("调用前"); Object result = method.invoke(target, args); // 方法调用 System.out.println("调用后"); return result; &#125;&#125;public static void main(String[] args) &#123; // JDK 动态代理调用 AnimalProxy proxy = new AnimalProxy(); Animal dogProxy = (Animal) proxy.getInstance(new Dog()); dogProxy.eat();&#125; 以上代码，我们实现了通过动态代理，在所有请求前、后都打印了一个简单的信息。 注意： JDK Proxy 只能代理实现接口的类（即使是 extends 继承类也是不可以代理的）。 cglib 动态代理要是用 cglib 实现要添加对 cglib 的引用，naven就增加依赖： 1234567891011&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.ow2.asm&lt;/groupId&gt; &lt;artifactId&gt;asm&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt;&lt;/dependency&gt; 相关代码如下： 12345678910111213141516171819202122232425262728293031323334class Panda &#123; public void eat() &#123; System.out.println("The panda is eating"); &#125;&#125;class CglibProxy implements MethodInterceptor &#123; private Object target; // 代理对象 public Object getInstance(Object target) &#123; this.target = target; Enhancer enhancer = new Enhancer(); // 设置父类为实例类 enhancer.setSuperclass(this.target.getClass()); // 回调方法 enhancer.setCallback(this); // 创建代理对象 return enhancer.create(); &#125; public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("调用前"); Object result = methodProxy.invokeSuper(o, objects); // 执行方法调用 System.out.println("调用后"); return result; &#125;&#125;public static void main(String[] args) &#123; // cglib 动态代理调用 CglibProxy proxy = new CglibProxy(); Panda panda = (Panda)proxy.getInstance(new Panda()); panda.eat();&#125; 现在，我们来看看运行结果： 123调用前The panda is eating调用后 由以上代码可以知道，cglib 的调用通过实现 MethodInterceptor 接口的 intercept 方法，调用 invokeSuper 进行动态代理的。它可以直接对普通类进行动态代理，并不需要像 JDK 代理那样，需要通过接口来完成，值得一提的是 Spring 的动态代理也是通过 cglib 实现的。 注意： cglib 底层是通过子类继承被代理对象的方式实现动态代理的，因此代理类不能是最终类（final），否则就会报错 java.lang.IllegalArgumentException: Cannot subclass final class xxx。由于是继承方式,如果是 static方法,private方法,final方法等描述的方法是不能被代理的。 面试基本问什么？动态代理解决了什么问题？答：首先它是一个代理机制，代理可以看作是对调用目标的一个包装，这样我们对目标代码的调用不是直接发生的，而是通过代理完成，通过代理可以让调用者与实现者之间解耦。比如进行 RPC 调用，通过代理，可以提供更加友善的界面；还可以通过代理，做一个全局的拦截器。 动态代理和反射的关系是什么？答：反射可以用来实现动态代理，但动态代理还有其他的实现方式，比如 ASM（一个短小精悍的字节码操作框架）、cglib 等。 cglib和jdk动态代理性能？以下描述错误的是？ A：cglib 的性能更高 B：Spring 中有使用 cglib 来实现动态代理 C：Spring 中有使用 JDK 原生的动态代理 D：JDK 原生动态代理性能更高 答：D 题目解析：Spring 动态代理的实现方式有两种：cglib 和 JDK 原生动态代理。 请补全以下代码？12345678910111213141516class MyReflect &#123; // 私有方法 private void privateMd() &#123; System.out.println("Private Method"); &#125;&#125;class ReflectTest &#123; public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, InvocationTargetException, IllegalAccessException, InstantiationException &#123; Class myClass = Class.forName("MyReflect"); Object object = myClass.newInstance(); // 补充此行代码 method.setAccessible(true); method.invoke(object); &#125;&#125; 答：Method method = myClass.getDeclaredMethod(“privateMd”); 解析：此题主要考的是私有方法的获取，私有方法的获取并不是通过 getMethod() 方式，而是通过 getDeclaredMethod() 获取的。 cglib 可以代理任何类这句话对吗？为什么？答：这句话不完全对，因为 cglib 只能代理可以有子类的普通类，对于像最终类（final）cglib 是不能实现动态代理的，因为 cglib 的底层是通过继承代理类的子类来实现动态代理的，所以不能被继承类无法使用 cglib。 JDK 原生动态代理和 cglib 有什么区别？答：JDK 原生动态代理和 cglib 区别如下： JDK 原生动态代理是基于接口实现的，不需要添加任何依赖，可以平滑的支持 JDK 版本的升级； cglib 不需要实现接口，可以直接代理普通类，需要添加依赖包，性能更高。 为什么 JDK 原生的动态代理必须要通过接口来完成？答：这是由于 JDK 原生设计的原因，来看动态代理的实现方法 newProxyInstance() 的源码： 12345678/*** ......* @param loader the class loader to define the proxy class* @param interfaces the list of interfaces for the proxy class to implement* ......*/ @CallerSensitivepublic static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException&#123;// 省略其他代码 来看前两个参数的声明： loader：为类加载器，也就是 target.getClass().getClassLoader() interfaces：接口代理类的接口实现列表 看了上面的参数说明，我们就明白了，要使用 JDK 原生的动态只能通过实现接口来完成。 小结通过本文可以知道 JDK 原生动态代理是使用反射实现的，但动态代理的实现方式不止有反射，还可以是 ASM（一个短小精悍的字节码操作框架）、cglib（基于 ASM）等。 其中 JDK 原生的动态代理是通过接口实现的，而 cglib 是通过子类实现的，因此 cglib 不能代理最终类（final）。 反射不但可以反射调用静态方法，还可以反射调用普通方法和私有方法，其中调用私有方法时要设置 setAccessible 为 true。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>动态代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java反射机制]]></title>
    <url>%2Fjava-reflect%2F</url>
    <content type="text"><![CDATA[Java反射机制的定义Java反射机制是指在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 用一句话总结就是反射可以实现在运行时可以知道任意一个类的属性和方法。俗称”超级工具箱“。 反射都用于哪些场景 用于代码编辑工具中，如Eclipse或者idea，我们在代码编写的时候，是不是经常自动的给我们各种提示呢，这就是用到了反射的原因。 一些框架的开发，为了程序更加的优雅和便携，就会用到反射机制。比如，spring的bean的自动注入，看如下代码： 1&lt;bean id=&quot;person&quot; class=&quot;com.study.beans.User&quot; init-method=&quot;initUser&quot;&gt; 还有Mybatis 在 Mapper 使用外部类的 Sql 构建查询时,也是用到反射: 123456789101112@SelectProvider(type = UserSql.class, method = &quot;getListSql&quot;)List&lt;User&gt; getList();public class UserSql &#123; public String getListSql() &#123; String sql = new SQL() &#123;&#123; SELECT(&quot;*&quot;); FROM(&quot;user&quot;); &#125;&#125;.toString(); return sql; &#125;&#125; 数据库连接池。使用反射调用不同数据库驱动 12345String url = &quot;jdbc:mysql://127.0.0.1:3306/database&quot;;String username = &quot;root&quot;;String password = &quot;root&quot;;Class.forName(&quot;com.mysql.jdbc.Driver&quot;);Connection connection = DriverManager.getConnection(url, username, password); 反射机制的优缺点为什么要用反射机制？直接创建对象不就可以了吗，这就涉及到了动态与静态的概念 静态编译：在编译时确定类型，绑定对象,即通过。 动态编译：运行时确定类型，绑定对象。动态编译最大限度发挥了java的灵活性，体现了多态的应用，有以降低类之间的藕合性。 优点可以实现动态创建对象和编译，体现出很大的灵活性，特别是在J2EE的开发中它的灵活性就表现的十分明显。 比如，一个大型的软件，不可能一次就把把它设计的很完美，当这个程序编译后，发布了，当发现需要更新某些功能时，我们不可能要用户把以前的卸载，再重新安装新的版本，假如这样的话，这个软件肯定是没有多少人用的。 采用静态的话，需要把整个程序重新编译一次才可以实现功能的更新，而采用反射机制的话，它就可以不用卸载，只需要在运行时才动态的创建和编译，就可以实现该功能。 缺点对性能有影响。使用反射基本上是一种解释操作，我们可以告诉JVM，我们希望做什么并且它满足我们的要求。这类操作总是慢于只直接执行相同的操作。 理解Class类和类类型想要了解反射首先理解一下Class类，它是反射实现的基础。 类是java.lang.Class类的实例对象，而Class是所有类的类（There is a class named Class）对于普通的对象，我们一般都会这样创建和表示： 1Code code = new Code(); 上面说了，所有的类都是Class的对象，那么如何表示呢，可不可以通过如下方式呢： 1Class c = new Class(); 但是我们查看Class的源码时，是这样写的： 123private Class(ClassLoader loader) &#123; classLoader = loader; &#125; 可以看到构造器是私有的，只有JVM可以创建Class的对象，因此不可以像普通类一样new一个Class对象，虽然我们不能new一个Class对象，但是却可以通过已有的类得到一个Class对象，共有三种方式，如下： 12345678910// 这说明任何一个类都有一个隐含的静态成员变量class，// 这种方式是通过获取类的静态成员变量class得到的Class c1 = Code.class;// code1是Code的一个对象，这种方式是通过// 一个类的对象的getClass()方法获得的Class c2 = code1.getClass();// 这种方法是Class类调用forName方法，通过一个类的全量限定名获得Class c3 = Class.forName("com.jelly.reflect.Code"); 这里，c1、c2、c3都是Class的对象，他们是完全一样的，而且有个学名，叫做Code的类类型（class type）。 这里就让人奇怪了，前面不是说Code是Class的对象吗，而c1、c2、c3也是Class的对象，那么Code和c1、c2、c3不就一样了吗？为什么还叫Code什么类类型？ 这里不要纠结于它们是否相同，只要理解类类型是干什么的就好了，顾名思义，类类型就是类的类型，也就是描述一个类是什么，都有哪些东西，所以我们可以通过类类型知道一个类的属性和方法，并且可以调用一个类的属性和方法，这就是反射的基础。 举个简单例子代码： 123456789101112131415161718192021public class ReflectDemo &#123; public static void main(String[] args) throws ClassNotFoundException &#123; //第一种：Class c1 = Code.class; 方式 Class class1=ReflectDemo.class; System.out.println(class1.getName()); //第二种：Class c2 = code1.getClass(); 方式 ReflectDemo demo2= new ReflectDemo(); Class c2 = demo2.getClass(); System.out.println(c2.getName()); //第三种：Class c3 = Class.forName("com.jelly.reflect.Code"); 方式 Class class3 = Class.forName("com.jelly.reflect.ReflectDemo"); System.out.println(class3.getName()); &#125;&#125;// 执行结果：com.jelly.reflect.ReflectDemocom.jelly.reflect.ReflectDemocom.jelly.reflect.ReflectDemo Java反射相关操作前面我们知道了怎么获取Class，那么我们可以通过这个Class干什么呢？ 总结如下： 获取成员方法Method 获取成员变量Field 获取构造函数Constructor 获取对象 获取Class类 获取成员方法单独获取某一个方法是通过Class类的以下方法获得的： 12345// 得到该类所有的方法，不包括父类的public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) // 得到该类所有的public方法，包括父类的public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 两个参数分别是方法名和方法参数类的类类型列表。 举个栗子例如类A有如下一个方法： 123public void fun(String name,int age) &#123; System.out.println("我叫"+name+",今年"+age+"岁");&#125; 现在知道A有一个对象a，那么就可以通过： 1234567891011// 生成classClass c = Class.forName("com.jelly.reflect.Person"); // newInstance可以初始化一个实例Object o = c.newInstance();// 获取方法Method method = c.getMethod("fun", String.class, int.class);// 调用方法method.invoke(o, "jelly", 10); 完整代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Person &#123; private String name; private int age; private String msg="hello wrold"; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public Person() &#123; &#125; private Person(String name) &#123; this.name = name; System.out.println(name); &#125; public void fun() &#123; System.out.println("fun"); &#125; public void fun(String name,int age) &#123; System.out.println("我叫"+name+",今年"+age+"岁"); &#125;&#125;public class ReflectDemo &#123; public static void main(String[] args)&#123; try &#123; Class c = Class.forName("com.jelly.reflect.Person"); Object o = c.newInstance(); Method method = c.getMethod("fun", String.class, int.class); method.invoke(o, "jelly", 10); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果： 1jelly,今年10岁 怎样，是不是感觉很厉害，我们只要知道这个类的路径全称就能玩弄它于鼓掌之间。 获取所有成员方法有时候我们想获取类中所有成员方法的信息，要怎么办。可以通过以下几步来实现：1.获取所有方法的数组： 123456Class c = Class.forName("com.jelly.reflect.Person");// 得到该类所有的方法，不包括父类的Method[] methods = c.getDeclaredMethods();// 或者,得到该类所有的public方法，包括父类的Method[] methods = c.getMethods(); 2.然后循环这个数组就得到每个方法了： 完整代码如下：person类跟上面一样，这里以及后面就不贴出来了，只贴关键代码 1234567891011121314151617181920212223public class ReflectDemo &#123; public static void main(String[] args)&#123; try &#123; Class c = Class.forName("com.jelly.reflect.Person"); Method[] methods = c.getDeclaredMethods(); for(Method m:methods)&#123; String methodName= m.getName(); System.out.println(methodName); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;//执行结果：getNamesetNamesetAgefunfungetAge 这里如果把c.getDeclaredMethods();改成c.getMethods();执行结果如下，多了很多方法，因为把Object里面的方法也打印出来了，因为Object是所有类的父类： 123456789101112131415getNamesetNamegetAgesetAgefunfunwaitwaitwaitequalstoStringhashCodegetClassnotifynotifyAll 获取成员变量想一想成员变量中都包括什么：成员变量类型+成员变量名 类的成员变量也是一个对象，它是java.lang.reflect.Field的一个对象，所以我们通过java.lang.reflect.Field里面封装的方法来获取这些信息。 单独获取某个成员变量，通过Class类的以下方法实现： 12345// 获得该类自身声明的所有变量，不包括其父类的变量public Field getDeclaredField(String name) // 获得该类自所有的public成员变量，包括其父类变量public Field getField(String name) 参数是成员变量的名字。 举个栗子例如一个类A有如下成员变量： 1private int n; 如果A有一个对象a，那么就可以这样得到其成员变量： 12Class c = a.getClass();Field field = c.getDeclaredField("n"); 完整代码如下： 123456789101112131415161718192021public class ReflectDemo &#123; public static void main(String[] args)&#123; try &#123; Class c = Class.forName("com.jelly.reflect.Person"); //获取成员变量 Field field = c.getDeclaredField("msg"); //因为msg变量是private的，所以不能用getField方法 Object o = c.newInstance(); //设置是否允许访问，因为该变量是private的， //所以要手动设置允许访问，如果msg是public的就不需要这行了。 field.setAccessible(true); Object msg = field.get(o); System.out.println(msg); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;//执行结果：hello wrold 获取所有成员变量1.获取所有成员变量的数组： 1Field[] fields = c.getDeclaredFields(); 2.遍历变量数组，获得某个成员变量field 完整代码： 12345678910111213141516171819public class ReflectDemo &#123; public static void main(String[] args)&#123; try &#123; Class c = Class.forName("com.jelly.reflect.Person"); Field[] fields = c.getDeclaredFields(); for(Field field :fields)&#123; System.out.println(field.getName()); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;//执行结果：nameagemsg 获取构造函数最后再想一想构造函数中都包括什么：构造函数参数 同上，类的成构造函数也是一个对象，它是java.lang.reflect.Constructor的一个对象，所以我们通过java.lang.reflect.Constructor里面封装的方法来获取这些信息。 单独获取某个构造函数,通过Class类的以下方法实现： 12345// 获得该类所有的构造器，不包括其父类的构造器public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) // 获得该类所以public构造器，包括父类public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 这个参数为构造函数参数类的类类型列表。 举个栗子例如类A有如下一个构造函数： 123public A(String a, int b) &#123; // code body&#125; 那么就可以通过： 1Constructor constructor = a.getDeclaredConstructor(String.class, int.class); 来获取这个构造函数。 完整代码： 123456789101112131415161718public class ReflectDemo &#123; public static void main(String[] args)&#123; try &#123; Class c = Class.forName("com.jelly.reflect.Person"); //获取构造函数 Constructor constructor = c.getDeclaredConstructor(String.class); //设置是否允许访问，因为该构造器是private的， //所以要手动设置允许访问，如果构造器是public的就不需要这行了。 constructor.setAccessible(true); constructor.newInstance("jelly"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;// 执行结果：jelly 注意：Class的newInstance方法，只能创建只包含无参数的构造函数的类，如果某类只有带参数的构造函数，那么就要使用另外一种方式： 1fromClass.getDeclaredConstructor(String.class).newInstance(“jelly”); 获取所有的构造函数1.获取该类的所有构造函数，放在一个数组中： 1Constructor[] constructors = c.getDeclaredConstructors(); 2.遍历构造函数数组，获得某个构造函数constructor: 完整代码： 123456789101112131415public class ReflectDemo &#123; public static void main(String[] args)&#123; Constructor[] constructors = c.getDeclaredConstructors(); for(Constructor constructor:constructors)&#123; System.out.println(constructor); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;//执行结果：public com.jelly.reflect.Person()public com.jelly.reflect.Person(java.lang.String) 通过反射了解集合泛型的本质 Java中集合的泛型，是防止错误输入的，只在编译阶段有效，绕过编译到了运行期就无效了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 集合泛型的本质 */public class GenericEssence &#123; public static void main(String[] args) &#123; // 没有泛型 List list1 = new ArrayList(); // 有泛型 List&lt;String&gt; list2 = new ArrayList&lt;String&gt;(); /* * 1.首先观察正常添加元素方式，在编译器检查泛型 * 这个时候如果list2添加int类型会报错 */ list2.add("hello"); // 报错！list2有泛型限制，只能添加String，添加int报错 // list2.add(20); // 此时list2长度为 1 System.out.println("list2的长度是：" + list2.size()); /* * 2.然后通过反射添加元素方式，在运行期动态加载类，首先得到list1和list2的类类型相同， * 然后再通过方法反射绕过编译器来调用add方法，看能否插入int型的元素 */ Class c1 = list1.getClass(); Class c2 = list2.getClass(); // 结果：true，说明类类型完全相同 System.out.println(c1 == c2); // 验证：我们可以通过方法的反射来给list2添加元素，这样可以绕过编译检查 try &#123; // 通过方法反射得到add方法 Method m = c2.getMethod("add", Object.class); //给list2添加一个int型的，上面显示在编译器是会报错的 m.invoke(list2, 20); //结果：2，说明list2长度增加了，并没有泛型检查 System.out.println("list2的长度是：" + list2.size()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;// 执行结果：list2的长度是：1truelist2的长度是：2 综上可以看出，在编译器的时候，泛型会限制集合内元素类型保持一致，但是编译器结束进入运行期以后，泛型就不再起作用了，即使是不同类型的元素也可以插入集合。 通过反射取得并修改数组的信息12345678910111213package net.xsoftlab.baike;import java.lang.reflect.Array;public class TestReflect &#123; public static void main(String[] args) throws Exception &#123; int[] temp = &#123; 1, 2, 3, 4, 5 &#125;; Class&lt;?&gt; demo = temp.getClass().getComponentType(); System.out.println("数组类型： " + demo.getName()); System.out.println("数组长度 " + Array.getLength(temp)); System.out.println("数组的第一个元素: " + Array.get(temp, 0)); Array.set(temp, 0, 100); System.out.println("修改之后数组第一个元素为： " + Array.get(temp, 0)); &#125;&#125; 通过反射机制修改数组的大小1234567891011121314151617181920212223242526272829303132package net.xsoftlab.baike;import java.lang.reflect.Array;public class TestReflect &#123; public static void main(String[] args) throws Exception &#123; int[] temp = &#123; 1, 2, 3, 4, 5, 6, 7, 8, 9 &#125;; int[] newTemp = (int[]) arrayInc(temp, 15); print(newTemp); String[] atr = &#123; "a", "b", "c" &#125;; String[] str1 = (String[]) arrayInc(atr, 8); print(str1); &#125; // 修改数组大小 public static Object arrayInc(Object obj, int len) &#123; Class&lt;?&gt; arr = obj.getClass().getComponentType(); Object newArr = Array.newInstance(arr, len); int co = Array.getLength(obj); System.arraycopy(obj, 0, newArr, 0, co); return newArr; &#125; // 打印 public static void print(Object obj) &#123; Class&lt;?&gt; c = obj.getClass(); if (!c.isArray()) &#123; return; &#125; System.out.println("数组长度为： " + Array.getLength(obj)); for (int i = 0; i &lt; Array.getLength(obj); i++) &#123; System.out.print(Array.get(obj, i) + " "); &#125; System.out.println(); &#125;&#125; 将反射机制应用于工厂模式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package net.xsoftlab.baike;interface fruit &#123; public abstract void eat();&#125;class Apple implements fruit &#123; public void eat() &#123; System.out.println("Apple"); &#125;&#125;class Orange implements fruit &#123; public void eat() &#123; System.out.println("Orange"); &#125;&#125;class Factory &#123; public static fruit getInstance(String ClassName) &#123; fruit f = null; try &#123; f = (fruit) Class.forName(ClassName).newInstance(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return f; &#125;&#125;/** * 对于普通的工厂模式当我们在添加一个子类的时候，就需要对应的修改工厂类。 当我们添加很多的子类的时候，会很麻烦。 * Java 工厂模式可以参考 * http://baike.xsoftlab.net/view/java-factory-pattern * * 现在我们利用反射机制实现工厂模式，可以在不修改工厂类的情况下添加任意多个子类。 * * 但是有一点仍然很麻烦，就是需要知道完整的包名和类名，这里可以使用properties配置文件来完成。 * * java 读取 properties 配置文件 的方法可以参考 * http://baike.xsoftlab.net/view/java-read-the-properties-configuration-file * * @author xsoftlab.net */public class TestReflect &#123; public static void main(String[] args) throws Exception &#123; fruit f = Factory.getInstance("net.xsoftlab.baike.Apple"); if (f != null) &#123; f.eat(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的异常和处理详解]]></title>
    <url>%2Fjava-exception%2F</url>
    <content type="text"><![CDATA[简介Throwable类是Java异常类型的顶层父类，一个对象只有是 Throwable 类的（直接或者间接）实例，他才是一个异常对象，才能被异常处理机制识别。JDK中内建了一些常用的异常类，我们也可以自定义异常。 Java标准库内建了一些通用的异常，这些类以Throwable为顶层父类。 Throwable又派生出Error类和Exception类。 错误： Error类以及他的子类的实例，代表了JVM本身的错误。错误不能被程序员通过代码处理，Error很少出现。因此，程序员应该关注Exception为父类的分支下的各种异常类。 异常： Exception以及他的子类，代表程序运行时发送的各种不期望发生的事件。可以被Java异常处理机制使用，是异常处理的核心。 Java异常的分类和类结构图 分类总体上我们根据Javac对异常的处理要求，将异常类分为2类。 非检查异常（unckecked exception）： Error 和 RuntimeException 以及他们的子类。javac在编译时，不会提示和发现这样的异常，不要求在程序处理这些异常。所以如果愿意，我们可以编写代码处理（使用try…catch…finally）这样的异常，也可以不处理。对于这些异常，我们应该修正代码，而不是去通过异常处理器处理 。这样的异常发生的原因多半是代码写的有问题。如除0错误ArithmeticException，错误的强制类型转换错误ClassCastException，数组索引越界ArrayIndexOutOfBoundsException，使用了空对象NullPointerException等等。 检查异常（checked exception）： 除了Error 和 RuntimeException的其它异常。javac强制要求程序员为这样的异常做预备处理工作（使用try…catch…finally或者throws）。在方法中要么用try-catch语句捕获它并处理，要么用throws子句声明抛出它，否则编译不会通过。这样的异常一般是由程序的运行环境导致的。因为程序可能被运行在各种未知的环境下，而程序员无法干预用户如何使用他编写的程序，于是程序员就应该为这样的异常时刻准备着。如SQLException , IOException,ClassNotFoundException 等。 需要明确的是： 检查和非检查是对于javac来说的，这样就很好理解和区分了。 自定义异常自定义异常如果要自定义异常类，则扩展Exception类即可，因此这样的自定义异常都属于检查异常（checked exception）。如果要自定义非检查异常，则扩展自RuntimeException。 按照国际惯例，自定义的异常应该总是包含如下的构造函数： 一个无参构造函数 一个带有String参数的- 构造函数，并传递给父- 类的构造函数。 一个带有String参数和T- hrowable参数，并都传- 递给父类构造函数 一个带有Throwable 参数的构造函数，并传递给父类的构造函数。 下面是IOException类的完整源代码，可以借鉴。 123456789101112131415161718192021222324public class IOException extends Exception&#123; static final long serialVersionUID = 7818375828146090155L; public IOException() &#123; super(); &#125; public IOException(String message) &#123; super(message); &#125; public IOException(String message, Throwable cause) &#123; super(message, cause); &#125; public IOException(Throwable cause) &#123; super(cause); &#125;&#125;]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java接口和抽象类的区别]]></title>
    <url>%2Fjava-interface2class%2F</url>
    <content type="text"><![CDATA[接口是like关系，指b像a的问题；抽象类是is关系，指b是a的关系。当然他们内部还有很多不一样。 抽象类我们都知道在面向对象的领域一切都是对象，同时所有的对象都是通过类来描述的，但是并不是所有的类都是来描述对象的。如果一个类没有足够的信息来描述一个具体的对象，而需要其他具体的类来支撑它，那么这样的类我们称它为抽象类。 抽象类是用来捕捉子类的通用特性的 。它不能被实例化，只能被用作子类的超类。抽象类是被用来创建继承层级里子类的模板。 示例以JDK中的GenericServlet为例： 123456789public abstract class GenericServlet implements Servlet, ServletConfig, Serializable &#123; // abstract method abstract void service(ServletRequest req, ServletResponse res); void init() &#123; // Its implementation &#125; // other method related to Servlet&#125; 当HttpServlet类集成GenericServlet时，它提供了service方法的实现： 123456789101112131415public class HttpServlet extends GenericServlet &#123; void service(ServletRequest req, ServletResponse res) &#123; // implementation &#125; protected void doGet(HttpServletRequest req, HttpServletResponse resp) &#123; // Implementation &#125; protected void doPost(HttpServletRequest req, HttpServletResponse resp) &#123; // Implementation &#125; // some other methods related to HttpServlet&#125; 创建抽象类和抽象方法非常有用,因为他们可以使类的抽象性明确起来,并告诉用户和编译器打算怎样使用他们.抽象类还是有用的重构器,因为它们使我们可以很容易地将公共方法沿着继承层次结构向上移动。 注意点在使用抽象类时需要注意几点： 抽象类不能被实例化，实例化的工作应该交由它的子类来完成，它只需要有一个引用即可。 抽象方法必须由子类来进行重写。 只要包含一个抽象方法的抽象类，该方法必须要定义成抽象类，不管是否还包含有其他方法。 抽象类中可以包含具体的方法，当然也可以不包含抽象方法。 子类中的抽象方法不能与父类的抽象方法同名。 abstract不能与final并列修饰同一个类。 abstract 不能与private、static、final或native并列修饰同一个方法。 接口接口是抽象方法的集合。如果一个类实现了某个接口，那么它就继承了这个接口的抽象方法。这就像契约模式，如果实现了这个接口，那么就必须确保使用这些方法。接口只是一种形式，接口自身不能做任何事情。 示例以Externalizable接口为例： 123456public interface Externalizable extends Serializable &#123; void writeExternal(ObjectOutput out) throws IOException; void readExternal(ObjectInput in) throws IOException, ClassNotFoundException;&#125; 当你实现这个接口时，你就需要实现接口种的所有的抽象方法。 12345678910111213141516171819public class Employee implements Externalizable &#123; int employeeId; String employeeName; @Override public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException &#123; employeeId = in.readInt(); employeeName = (String) in.readObject(); &#125; @Override public void writeExternal(ObjectOutput out) throws IOException &#123; out.writeInt(employeeId); out.writeObject(employeeName); &#125;&#125; 注意点在使用接口过程中需要注意如下几个问题： 个Interface的方所有法访问权限自动被声明为public。确切的说只能为public，当然你可以显示的声明为protected、private，但是编译会出错！ 接口中可以定义“成员变量”，或者说是不可变的常量，因为接口中的“成员变量”会自动变为为public static final。可以通过类命名直接访问：ImplementClass.name。 接口中不存在实现的方法。(java8 接口可以有default方法) 实现接口的非抽象类必须要实现该接口的所有方法。抽象类可以不用实现。 不能使用new操作符实例化一个接口，但可以声明一个接口变量，该变量必须引用（refer to)一个实现该接口的类的对象。可以使用 instanceof 检查一个对象是否实现了某个特定的接口。例如：if(anObject instanceof Comparable){}。 在实现多接口的时候一定要避免方法名的重复。 二者区别 参数 抽象类 接口 实现 子类使用extends关键字来继承抽象类。如果子类不是抽象类的话，它需要提供抽象类中所有声明的方法的实现 子类使用关键字implements来实现接口。它需要提供接口中所有声明的方法的实现 成员变量 可以有普通成员变量，可以有任意访问类型的静态成员变量 没有普通成员变量，只能有public static final类型的成员变量 构造器 抽象类可以有构造器 接口无构造器 方法实现 可以包含静态方法、非抽象的普通方法 接口中的所有方法必须都是抽象的，不能有非抽象的普通方法、无静态方法。但是在java8里的接口可以有default方法 访问修饰符 抽象方法可以有public、protected、default 接口方法默认是public main方法 抽象方法可以有main方法并且我们可以运行它 接口没有main方法，因此我们不能运行它。 与正常Java类的区别 除了不能实例化抽象类之外，它和普通Java类没有任何区别 接口是完全不同的类型 多继承 抽象方法可以继承一个类和实现多个接口 接口只可以继承一个或多个其它接口 速度 它比接口速度要快 接口是稍微有点慢的，因为它需要时间去寻找在类中实现的方法。 添加新方法 如果你往抽象类中添加新的方法，你可以给它提供默认的实现。因此你不需要改变你现在的代码。 如果你往接口中添加方法，那么你必须改变实现该接口的类。 小结 抽象类在java语言中所表示的是一种继承关系，一个子类只能存在一个父类，但是可以存在多个接口。 在抽象类中可以拥有自己的成员变量和非抽象类方法，但是接口中只能存在静态的不可变的成员数据（不过一般都不在接口中定义成员数据），而且它的所有方法都是抽象的。 抽象类和接口所反映的设计理念是不同的，抽象类所代表的是“is-a”的关系，而接口所代表的是“like-a”的关系。 例题 Java抽象类可以有构造函数吗？ 可以有，抽象类可以声明并定义构造函数。因为你不可以创建抽象类的实例，所以构造函数只能通过构造函数链调用（Java中构造函数链指的是从其他构造函数调用一个构造函数），例如，当你创建具体的实现类。现在一些面试官问，如果你不能对抽象类实例化那么构造函数的作用是什么？好吧，它可以用来初始化抽象类内部声明的通用变量，并被各种实现使用。另外，即使你没有提供任何构造函数，编译器将为抽象类添加默认的无参数的构造函数，没有的话你的子类将无法编译，因为在任何构造函数中的第一条语句隐式调用super()，Java中默认超类的构造函数。 Java抽象类可以实现接口吗？它们需要实现所有的方法吗？ 可以，抽象类可以通过使用关键字implements来实现接口。因为它们是抽象的，所以它们不需要实现所有的方法。好的做法是，提供一个抽象基类以及一个接口来声明类型 。这样的例子是，java.util.List接口和相应的java.util.AbstractList抽象类。因为AbstractList实现了所有的通用方法，具体的实现像LinkedList和ArrayList不受实现所有方法的负担，它们可以直接实现List接口。这对两方面都很好，你可以利用接口声明类型的优点和抽象类的灵活性在一个地方实现共同的行为。Effective Java有个很好的章节，介绍如何使用Java的抽象类和接口，值得阅读。 Java抽象类可以是final的吗？ 不可以，Java抽象类不能是final的。将它们声明为final的将会阻止它们被继承，而这正是使用抽象类唯一的方法。它们也是彼此相反的，关键字abstract强制继承类，而关键字final阻止类被扩张。在现实世界中，抽象表示不完备性，而final是用来证明完整性。底线是，你不能让你的Java类既abstract又final，同时使用，是一个编译时错误。 Java抽象类可以有static方法吗？ 可以，抽象类可以声明并定义static方法，没什么阻止这样做。但是，你必须遵守Java中将方法声明为static的准则，因为在面向对象的设计中是不受欢迎的，因为Java中的static方法是不可以被重载的。在抽象类中看到static方法是罕见的，但正如我所说的，如果你有很好的理由这样做的话，那没有什么可以阻止你。 可以创建抽象类的实例吗？ 不可以，你不能创建Java抽象类的实例，它们是不完全的。即使你的抽象类不包含任何抽象方法，你也不能对它实例化。将类声明为abstract的，就等你你告诉编译器，它是不完全的不应该被实例化。当一段代码尝试实例化一个抽象类时Java编译器会抛错误。 抽象类必须有抽象方法吗？ 不需要，抽象类有抽象方法不是强制性的。你只需要使用关键字abstract就可以将类声明为抽象类。编译器会强制所有结构的限制来适用于抽象类，例如，现在允许创建一些实例。是否在抽象类中有抽象方法是引起争论的。我的观点是，抽象类应该有抽象方法，因为这是当程序员看到那个类并做假设的第一件事。这也符合最小惊奇原则。 Java抽象类和接口有何不同？ 这是最重要的经典Java面试题之一。我已经记不清多少次看到这个问题了。这个问题有趣的原因是可以举出例子。很容易回答核心OOPS的概念，如抽象，封装，多态和继承，但是，当涉及到微妙点就是这样，候选人往往失手。你可以从本文看出抽象类和接口之间的所有语法的差异或者《Java抽象类和接口的面试题》。 何时选用抽象类而不是接口？ 这是对之前抽象类和接口对比问题的后续。如果你知道语法差异，你可以很容易回答这个问题，因为它们可以令你做出抉择。当关心升级时，因为不可能在一个发布的接口中添加一个新方法，用抽象类会更好。类似地，如果你的接口中有很多方法，你对它们的实现感到很头疼，考虑提供一个抽象类作为默认实现。这是Java集合包中的模式，你可以使用提供默认实现List接口的AbstractList。 Java中的抽象方法是什么？ 抽象方法是一个没有方法体的方法。你仅需要声明一个方法，不需要定义它并使用关键字abstract声明。Java接口中所有方法的声明默认是abstract的。这是抽象方法的例子 1public void abstract printVersion(); 现在，为了实现这个方法，你需要继承该抽象类并重载这个方法。 Java抽象类中可以包含main方法吗？ 是的，抽象类可以包含main方法，它只是一个静态方法，你可以使用main方法执行抽象类，但不可以创建任何实例。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>接口</tag>
        <tag>抽象类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java序列化]]></title>
    <url>%2Fjava-serialize%2F</url>
    <content type="text"><![CDATA[含义、意义使用场景序列化：将对象写入到IO流中 反序列化：从IO流中恢复对象 意义：序列化机制允许将实现序列化的Java对象转换位字节序列，这些字节序列可以保存在磁盘上，或通过网络传输，以达到以后恢复成原来的对象。序列化机制使得对象可以脱离程序的运行而独立存在。 使用场景：所有可在网络上传输的对象都必须是可序列化的，比如RMI（remote method invoke,即远程方法调用），传入的参数或返回的对象都是可序列化的，否则会出错；所有需要保存到磁盘的java对象都必须是可序列化的。通常建议：程序创建的每个JavaBean类都实现Serializeable接口。 序列化的实现方式如果需要将某个对象保存到磁盘上或者通过网络传输，那么这个类应该实现Serializable接口或者Externalizable接口之一。 Serializable普通序列化Serializable接口是一个标记接口，不用实现任何方法。一旦实现了此接口，该类的对象就是可序列化的。 创建对象类 1234567891011121314151617public class Person implements Serializable &#123; private String name; private int age; //我不提供无参构造器 public Person(String name, int age) &#123; System.out.println("调用有参构造方法"); this.name = name; this.age = age; &#125; @Override public String toString() &#123; return "Person&#123;" + "name='" + name + '\'' + ", age=" + age + '&#125;'; &#125;&#125; 序列化步骤步骤一：创建一个ObjectOutputStream输出流； 步骤二：调用ObjectOutputStream对象的writeObject输出可序列化对象 123456789101112131415public class WriteObject &#123; public static void main(String[] args) &#123; try &#123; //创建一个ObjectOutputStream输出流 ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("object.txt")); //将对象序列化到文件s Person person = new Person("9龙", 23); oos.writeObject(person); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;// 输出结果：调用有参构造方法 反序列化步骤步骤一：创建一个ObjectInputStream输入流； 步骤二：调用ObjectInputStream对象的readObject()得到序列化的对象。 我们将上面序列化到person.txt的person对象反序列化回来 1234567891011121314public class WriteObject &#123; public static void main(String[] args) &#123; try &#123; //创建一个ObjectOutputStream输出流 ObjectInputStream ois = new ObjectInputStream(new FileInputStream("person.txt")); Person brady = (Person) ois.readObject(); System.out.println(brady); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;//输出结果：Person&#123;name='9龙', age=23&#125; 输出告诉我们，反序列化并不会调用构造方法。反序列的对象是由JVM自己生成的对象，不通过构造方法生成。 成员为引用的序列化如果一个可序列化的类的成员不是基本类型，也不是String类型，那这个引用类型也必须是可序列化的；否则，会导致此类不能序列化。 看例子，我们新增一个Teacher类。将Person去掉实现Serializable接口代码 123456789101112131415161718192021public class Person &#123; // 省略。与上边代码相同&#125;public class Teacher implements Serializable &#123; private String leval; private Person person; public Teacher(String leval, Person person) &#123; this.leval = leval; this.person = person; &#125; public static void main(String[] args) throws Exception &#123; try (ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("teacher.txt"))) &#123; Person person = new Person("路飞", 20); Teacher teacher = new Teacher("雷利", person); oos.writeObject(teacher); &#125; &#125;&#125; 控制台输出： 123456789调用有参构造方法Exception in thread "main" java.io.NotSerializableException: com.jelly.java.serialize.Person at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1184) at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548) at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509) at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432) at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178) at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348) at com.jelly.java.serialize.Teacher.main(Teacher.java:20) 因为Person类的对象是不可序列化的，这导致了Teacher的对象不可序列化 对同一个对象序列化多次1234567891011121314151617181920212223242526272829303132333435363738 public static void writeMutObject() &#123; try &#123; //创建一个ObjectOutputStream输出流 ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("object.txt")); //将对象序列化到文件s Person p1 = new Person("1龙", 23); Person p2 = new Person("9龙", 30); oos.writeObject(p1); oos.writeObject(p2); oos.writeObject(p2); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void readMutObject() &#123; try &#123; //创建一个ObjectOutputStream输出流 ObjectInputStream ois = new ObjectInputStream(new FileInputStream("object.txt")); Person p1 = (Person) ois.readObject(); Person p2 = (Person) ois.readObject(); Person p3 = (Person) ois.readObject(); System.out.println(p1); System.out.println(p2); System.out.println(p3); System.out.println("p1==p2? :" + p1.equals(p2)); System.out.println("p2==p3? :" + p2.equals(p3)); System.out.println("p1==p3? :" + p1.equals(p3)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123;// writeMutObject(); readMutObject(); &#125; 输出 123456Person&#123;name=&apos;1龙&apos;, age=23&#125;Person&#123;name=&apos;9龙&apos;, age=30&#125;Person&#123;name=&apos;9龙&apos;, age=30&#125;p1==p2? :falsep2==p3? :truep1==p3? :false 从输出结果可以看出，Java序列化同一对象，并不会将此对象序列化多次得到多个对象。 序列化算法 所有保存到磁盘的对象都有一个序列化编码号 当程序试图序列化一个对象时，会先检查此对象是否已经序列化过，只有此对象从未（在此虚拟机）被序列化过，才会将此对象序列化为字节序列。 如果此对象已经序列化过，则直接存储对应的编号即可。 序列化算法潜在问题由于java序利化算法不会重复序列化同一个对象，只会记录已序列化对象的编号。如果序列化一个可变对象（对象内的内容可更改）后，更改了对象内容，再次序列化，并不会再次将此对象转换为字节序列，而只是保存序列化编号，那么就会造成数据丢失。 1234567891011121314151617181920212223242526272829public static void execp() &#123; try &#123; ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("person.txt")); //将对象序列化到文件s Person p1 = new Person("1龙", 23); oos.writeObject(p1); p1.setName("9龙"); oos.writeObject(p1); oos.close(); oos.flush(); 创建一个ObjectOutputStream输出流 ObjectInputStream ois = new ObjectInputStream(new FileInputStream("person.txt")); Person pp1 = (Person) ois.readObject(); Person pp2 = (Person) ois.readObject(); System.out.println(pp1); System.out.println(pp2); &#125; catch (Exception e) &#123; System.out.println("exception " + e); &#125;&#125;public static void main(String[] args) &#123; execp();&#125;// 输出：调用有参构造方法Person&#123;name='1龙', age=23&#125;Person&#123;name='1龙', age=23&#125; 定制序列化方式序列化时忽略字段 (transient)有些时候，我们有这样的需求，某些属性不需要序列化。使用transient关键字选择不需要序列化的字段。 使用transient修饰的属性，java序列化时，会忽略掉此字段，所以反序列化出的对象，被transient修饰的属性是默认值。对于引用类型，值是null；基本类型，值是0；boolean类型，值是false。 自定义序列化方法使用transient虽然简单，但将此属性完全隔离在了序列化之外。java提供了可选的。可以进行控制序列化的方式，或者对序列化数据进行编码加密等。 123private void writeObject (java.io.ObjectOutputStream out) throws IOException；private void readObject (java.io.ObjectIutputStream in) throws IOException, ClassNotFoundException;private void readObjectNoData () throws ObjectStreamException; 通过重写writeObject与readObject方法，可以自己选择哪些属性需要序列化，哪些属性不需要。如果writeObject使用某种规则序列化，则相应的readObject需要相反的规则反序列化，以便能正确反序列化出对象。 这里展示对名字进行反转加密。 12345678910111213141516public class Person implements Serializable &#123; private String name; private int age; //将名字反转写入二进制流 private void writeObject(ObjectOutputStream out) throws IOException &#123; out.writeObject(new StringBuffer(this.name).reverse()); out.writeInt(age); &#125; //将读出的字符串反转恢复回来 private void readObject(ObjectInputStream ins) throws IOException, ClassNotFoundException &#123; this.name = ((StringBuffer) ins.readObject()).reverse().toString(); this.age = ins.readInt(); &#125;&#125; 当序列化流不完整时，readObjectNoData()方法可以用来正确地初始化反序列化的对象。例如，使用不同类接收反序列化对象，或者序列化流被篡改时，系统都会调用readObjectNoData()方法来初始化反序列化的对象。 Externalizable通过实现Externalizable接口，必须实现writeExternal、readExternal方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public interface Externalizable extends java.io.Serializable &#123; void writeExternal(ObjectOutput out) throws IOException; void readExternal(ObjectInput in) throws IOException, ClassNotFoundException;&#125;public class ExPerson implements Externalizable &#123; private String name; private int age; //注意，必须加上pulic 无参构造器 public ExPerson() &#123; &#125; public ExPerson(String name, int age) &#123; this.name = name; this.age = age; &#125; //将name反转后写入二进制流 @Override public void writeExternal(ObjectOutput out) throws IOException &#123; StringBuffer reverse = new StringBuffer(name).reverse(); System.out.println(reverse.toString()); out.writeObject(reverse); out.writeInt(age); &#125; //将读取的字符串反转后赋值给name实例变量 @Override public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException &#123; this.name = ((StringBuffer) in.readObject()).reverse().toString(); System.out.println(name); this.age = in.readInt(); &#125; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; try (ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("ExPerson.txt")); ObjectInputStream ois = new ObjectInputStream(new FileInputStream("ExPerson.txt"))) &#123; oos.writeObject(new ExPerson("brady", 23)); ExPerson ep = (ExPerson) ois.readObject(); System.out.println(ep); &#125; &#125;&#125;//输出结果ydarb bradyExPerson&#123;name='brady', age=23&#125; 注意：Externalizable接口不同于Serializable接口，实现此接口必须实现接口中的两个方法实现自定义序列化，这是强制性的；特别之处是必须提供pulic的无参构造器，因为在反序列化的时候需要反射创建对象。 二者对比 实现Serializable接口 实现Externalizable接口 系统自动存储必要的信息 程序员决定存储哪些信息 Java内建支持，易于实现，只需要实现该接口即可，无需任何代码支持 必须实现接口内的两个方法 性能略差 性能略好 — 序列化版本号serialVersionUID我们知道，反序列化必须拥有class文件，但随着项目的升级，class文件也会升级，序列化怎么保证升级前后的兼容性呢？java序列化提供了一个 1private static final long serialVersionUID = -81298930239; 的序列化版本号，只有版本号相同，即使更改了序列化属性，对象也可以正确被反序列化回来。 如果反序列化使用的class的版本号与序列化时使用的不一致，反序列化会报InvalidClassException异常。 序列化版本号指定可以自由指定，如果不指定JVM会根据类信息自己计算一个版本号，这样随着class的升级，就无法正确反序列化；不指定版本号另一个明显隐患是，不利于jvm间的移植，可能class文件没有更改，但不同jvm可能计算的规则不一样，这样也会导致无法反序列化。 什么情况下需要修改serialVersionUID呢？分三种情况。 如果只是修改了方法，反序列化不影响，则无需修改版本号； 如果只是修改了静态变量，瞬态变量（transient修饰的变量），反序列化不受影响，无需修改版本号； 如果修改了非瞬态变量，则可能导致反序列化失败。如果新类中实例变量的类型与序列化时类的类型不一致，则会反序列化失败，这时候需要更改serialVersionUID。如果只是新增了实例变量，则反序列化回来新增的是默认值；如果减少了实例变量，反序列化时会忽略掉减少的实例变量。 总结 所有需要网络传输的对象都需要实现序列化接口，通过建议所有的javaBean都实现Serializable接口。 对象的类名、实例变量（包括基本类型，数组，对其他对象的引用）都会被序列化；方法、类变量、transient实例变量都不会被序列化。 如果想让某个变量不被序列化，使用transient修饰。 序列化对象的引用类型成员变量，也必须是可序列化的，否则，会报错。 反序列化时必须有序列化对象的class文件。 当通过文件、网络来读取序列化后的对象时，必须按照实际写入的顺序读取。 单例类序列化，需要重写readResolve()方法；否则会破坏单例原则。 同一对象序列化多次，只有第一次序列化为二进制流，以后都只是保存序列化编号，不会重复序列化。 建议所有可序列化的类加上serialVersionUID 版本号，方便项目升级。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[==，equals，hashCode区别]]></title>
    <url>%2Fjava-equal-hashcode%2F</url>
    <content type="text"><![CDATA[==，equals，hashCode经常会用到，如果不知道它的规则，岂不是容易出现隐藏的bug么？ 基础概念==运算符，用于比较两个变量是否相等。 如果作用于基本数据类型，则直接比较其存储的“值”是否相等; 如果作用于引用类型的变量，则比较的是所指向的对象的地址 equalsObject 的实例方法，比较两个对象的content是否相同。 默认Object类的equals方法是比较两个对象的地址，跟==的结果一样。 Object的equals方法如下： 123public boolean equals(Object obj) &#123; return (this == obj);&#125; 但在一些类库当中这个方法被覆盖掉了，如String, Integer, Date在这些类当中equals有其自身的实现，而不再是比较类在堆内存中的存放地址了。 hashCodeObject 的 native方法 , 获取对象的哈希值，用于确定该对象在哈希表中的索引位置。 它实际上是一个int型整数，所以如果没有重写hashCode方法，任何对象的hashCode方法是不相等的。 无论何时，对同一个对象调用hashCode都应该产生同一个值。 如果重写了equals方法就必须要重写hashCode方法，以便用户将对象插入到散列表中。 使用注意equals和hashCode 如果两个对象equals，Java运行时环境会认为他们的hashcode一定相等。 如果两个对象不equals，他们的hashcode有可能相等。 如果两个对象hashcode相等，他们不一定equals。 如果两个对象hashcode不相等，他们一定不equals。 从而在集合操作的时候有如下规则：将对象放入到集合中时，首先判断要放入对象的hashcode值与集合中的任意一个元素的hashcode值是否相等，如果不相等直接将该对象放入集合中。 如果hashcode值相等，然后再通过equals方法判断要放入对象与集合中的任意一个对象是否相等，如果equals判断不相等，直接将该元素放入到集合中，否则不放入。 回过来说get的时候，HashMap也先调key.hashCode()算出数组下标，然后看equals如果是true就是找到了，所以就涉及了equals。 覆盖equals方法的时，必须遵守它的通用约定。 自反性。对于任何非null的引用值x，x.equals(x)必须返回true。 对称性。对于任何非null的引用值x和y，当且仅当y.equals(x)返回true时，x.equals(y)必须返回true 传递性。对于任何非null的引用值x、y和z，如果x.equals(y)返回true，并且y.equals(z)也返回true，那么x.equals(z)也必须返回true。 一致性。对于任何非null的引用值x和y，只要equals的比较操作在对象中所用的信息没有被修改，多次调用该x.equals(y)就会一直地返回true，或者一致地返回false。 对于任何非null的引用值x，x.equals(null)必须返回false。 实现高质量equals方法的诀窍： 使用==符号检查“参数是否为这个对象的引用”。如果是，则返回true。这只不过是一种性能优化，如果比较操作有可能很昂贵，就值得这么做。 使用instanceof操作符检查“参数是否为正确的类型”。如果不是，则返回false。一般来说，所谓“正确的类型”是指equals方法所在的那个类。 把参数转换成正确的类型。因为转换之前进行过instanceof测试，所以确保会成功. 对于该类中的每个“关键”域，检查参数中的域是否与该对象中对应的域相匹配。如果这些测试全部成功，则返回true;否则返回false。 当编写完成了equals方法之后，检查“对称性”、“传递性”、“一致性”。 覆盖equals时总要覆盖hashCode一个很常见的错误根源在于没有覆盖hashCode方法。在每个覆盖了equals方法的类中，也必须覆盖hashCode方法。如果不这样做的话，就会违反Object.hashCode的通用约定，从而导致该类无法结合所有基于散列的集合一起正常运作，这样的集合包括HashMap、HashSet和Hashtable。 在应用程序的执行期间，只要对象的equals方法的比较操作所用到的信息没有被修改，那么对这同一个对象调用多次，hashCode方法都必须始终如一地返回同一个整数。在同一个应用程序的多次执行过程中，每次执行所返回的整数可以不一致。 如果两个对象根据equals()方法比较是相等的，那么调用这两个对象中任意一个对象的hashCode方法都必须产生同样的整数结果。 如果两个对象根据equals()方法比较是不相等的，那么调用这两个对象中任意一个对象的hashCode方法，则不一定要产生相同的整数结果。但是程序员应该知道，给不相等的对象产生截然不同的整数结果，有可能提高散列表的性能。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java运算符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[static关键字]]></title>
    <url>%2Fjava-static%2F</url>
    <content type="text"><![CDATA[Java中static可以修饰类、变量、方法甚至可以构成静态块，让我们来了解下它们各自的使用以及加载顺序吧。 基本用法static关键字修饰类java里面用static修饰内部类，普通类是不允许声明为静态的，只有内部类才可以。 1234567891011121314151617public class StaticTest &#123; //static关键字修饰内部类 public static class InnerClass&#123; InnerClass()&#123; System.out.println("============= 静态内部类============="); &#125; public void InnerMethod() &#123; System.out.println("============= 静态内部方法============="); &#125; &#125; public static void main(String[] args) &#123; //直接通过StaticTest类名访问静态内部类InnerClass InnerClass inner=new StaticTest.InnerClass(); //静态内部类可以和普通类一样使用 inner.InnerMethod(); &#125;&#125; 如果没有用static修饰InterClass，则只能new 一个外部类实例。再通过外部实例创建内部类。 static关键字修饰方法修饰方法的时候，其实跟类一样，可以直接通过类名来进行调用： 123456789101112public class StaticMethod &#123; public static void test() &#123; System.out.println("============= 静态方法============="); &#125;; public static void main(String[] args) &#123; //方式一：直接通过类名 StaticMethod.test(); //方式二：通过对象调用 StaticMethod fdd=new StaticMethod(); fdd.test(); &#125;&#125; static关键字修饰变量被static修饰的成员变量叫做静态变量，也叫做类变量，说明这个变量是属于这个类的，而不是属于是对象，没有被static修饰的成员变量叫做实例变量，说明这个变量是属于某个具体的对象的。 我们同样可以使用上面的方式进行调用变量： 12345678public class StaticVar &#123; private static String name="java技术栈"; public static void main(String[] args) &#123; //直接通过类名 StaticVar.name; &#125;&#125; static关键字修饰代码块静态代码块在类第一次被载入时执行，在这里主要是想验证一下，类初始化的顺序。 12345678910111213父类静态变量父类静态代码块子类静态变量子类静态代码块父类普通变量父类普通代码块父类构造函数子类普通变量子类普通代码块子类构造函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344//首先我们定义一个父类public class Father &#123; // 父类静态变量 public static String str1 = "father static str"; // 父类普通变量 public String str2 = "father common str"; // 父类静态代码块 static &#123; System.out.println("father static block"); &#125; // 父类普通代码块 &#123; System.out.println("father common block"); &#125; // 父类构造方法 public Father() &#123; System.out.println("father constructor"); &#125;&#125;//然后定义一个子类public class Child extends Father &#123; // 子类静态变量 public static String str1 = "child static str"; // 子类普通变量 public String str2 = "child common str"; // 子类静态代码块 static &#123; System.out.println("child static block"); &#125; // 子类普通代码块 &#123; System.out.println("child common block"); &#125; // 子类构造方法 public Child() &#123; System.out.println("child constructor"); &#125;&#125;// 测试public static void main(String[] args) &#123; new Child();&#125; 输出为： 123456father static blockchild static blockfather common blockfather constructorchild common blockchild constructor 原理讲解 上图为jvm运行时数据区，静态变量存放在方法区中，并且是被所有线程所共享的。 方法区中包含的都是在整个程序中永远唯一的元素，如类信息、static变量等。 举例定义一个类，包含静态变量、静态方法。 12345678910111213141516171819202122232425262728public class Person&#123; //静态变量 static String firstName; String lastName; public void showName()&#123; System.out.println(firstName+lastName); &#125; //静态方法 public static void viewName()&#123; System.out.println(firstName); &#125; public static void main(String[] args) &#123; Person p =new Person(); Person.firstName = "张"; p.lastName="三"; p.showName(); Person p2 =new Person(); Person.firstName="李"; p2.lastName="四"; p2.showName(); &#125;&#125;//输出。张三、李四 从内存的角度看一下： 从上面可以看到，我们的方法在调用静态方法、变量的时候，是从方法区调用的，但是调用普通变量是从堆内存中调用的，堆内存中的成员变量lastname是随着对象的产生而产生，随着对象的消失而消失。静态变量是所有线程共享的，所以不会消失。 小结特点 static是一个修饰符，用于修饰成员。（成员变量，成员函数）static修饰的成员变量称之为静态变量或类变量。 static修饰的成员被所有的对象共享。 static优先于对象存在，因为static的成员在类的加载时初始化。 static修饰的成员多了一种调用方式，可以直接被类名所调用，（类名.静态成员）。 static修饰的数据是共享数据，对象中的变量的是特有的数据。 成员变量和静态变量的区别 生命周期的不同： 成员变量随着对象的创建而存在随着对象的回收而释放。 静态变量随着类的加载而存在随着类的消失而消失。 调用方式不同： 成员变量只能被对象调用。 静态变量可以被对象调用，也可以用类名调用。（推荐用类名调用） 别名不同： 成员变量也称为实例变量。 静态变量称为类变量。 数据存储位置不同： 成员变量数据存储在堆内存的对象中，所以也叫对象的特有数据。 静态变量数据存储在方法区（共享数据区）的静态区，所以也叫对象的共享数据。 静态使用时需要注意的事项： 静态方法只能访问静态成员。（非静态既可以访问静态，又可以访问非静态） 静态方法中不可以使用this或者super关键字。 主函数是静态的]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java关键字</tag>
        <tag>类加载顺序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[final、finally、finalize的区别]]></title>
    <url>%2Fjava-finalxxx%2F</url>
    <content type="text"><![CDATA[final、finally、finalize傻傻分不清楚，今天让你彻底弄清楚 基础概念区分final修饰符 将类声明为final,意味着它不能再派生新的子类，不能作为父类被继承。final类中的所有成员方法都会被隐式地指定为final方法。(因此一个类不能及被声明为abstract，又被声明为final的。) 将方法声明为final，只能使用，不能被子类方法重写。 将变量声明为final，必须在声明时给定初值。如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。 finally异常处理语句结构的一部分，表示总是执行。 try-catch-finally(可省略) finalizeObject类的一个方法 在垃圾回收器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。 该方法更像是一个对象生命周期的临终方法，当该方法被系统调用则代表该对象即将“死亡”，但是需要注意的是，我们主动行为上去调用该方法并不会导致该对象“死亡”，这是一个被动的方法(其实就是回调方法)，不需要我们调用。 在GC要回收某个对象时，这个对象：“最后一刻，我还能再抢救一下！”。因此JVM要对它进行额外处理。finalize成为了CG回收的阻碍者，导致这个对象经过多个垃圾收集周期才能被回收。 1234567891011121314151617181920212223242526272829303132public class Person &#123; private String name; private int age; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; public String toString() &#123; return "姓名：" + this.name + "，年龄：" + this.age; &#125; public void finalize() throws Throwable &#123;//对象释放空间是默认调用此方法 System.out.println("对象被释放--&gt;" + this);//直接输出次对象，调用toString()方法 &#125;&#125;class SystemDemo &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub Person per = new Person("zhangsan", 30); per = null;//断开引用，释放空间 //方法1： System.gc();//强制性释放空间 //方法2：// Runtime run=Runtime.getRuntime();// run.gc(); &#125;&#125; try、catch、finally执行顺序try、catch、finally为异常捕获结构，其中finally为非必需项，可有可无。当finally存在时，finally块中的代码都会执行。 try-catch结构；try-catch-finally结构；try-finally结构也是可以的。 特殊场景：仅在以下四种情况下不会执行finally块中语句。 如果在try或catch语句中执行了System.exit(0); 在执行finally之前jvm崩溃了 try语句中执行死循环 电源断电 不管有无异常，finally中代码都会执行123456789101112131415161718192021222324252627public class FinallyTest &#123; // 当传入参数str 为 "null" 时抛出异常 public static void throwTest(String str) &#123; if ("null".equals(str)) &#123; throw new NullPointerException(); &#125; &#125; public static String method(String str) &#123; try &#123; System.out.println("try"); throwTest(str); &#125; catch (Exception e) &#123; System.out.println("exception: " + e); &#125; finally &#123; System.out.println("finally"); &#125; return str; &#125; public static void main(String[] args) &#123; System.out.println("-----无异常-----"); method("nl"); System.out.println("-----有异常-----"); method("null"); &#125;&#125; 上述代码做了正常执行和抛出异常的测试，结果如下： 1234567-----无异常-----tryfinally-----有异常-----tryexception: java.lang.NullPointerExceptionfinally try中有return时，finally依然会执行123456789101112131415public static String method(String str) &#123; try &#123; System.out.println("try--"); return str; &#125; catch (Exception e) &#123; System.out.println("exception-- " + e); &#125; finally &#123; System.out.println("finally--"); &#125; return "end";&#125;public static void main(String[] args) &#123; System.out.println(method("str"));&#125; 上述代码做了try中返回测试，结果如下： 123try--finally--str finally对返回值的做修改，不会影响到try的返回值12345678910111213141516public static String method(String str) &#123; try &#123; System.out.println("try--"); return str; &#125; catch (Exception e) &#123; System.out.println("exception-- " + e); &#125; finally &#123; System.out.println("finally--"); str = "finally"; &#125; return "end";&#125;public static void main(String[] args) &#123; System.out.println(method("str"));&#125; 上述代码做了在finally中修改返回值的测试，最终返回依然为”str”，结果如下： 123try--finally--str finally是在return后面的表达式运算后执行的（此时并没有返回运算后的值，而是先把要返回的值保存起来，不管finally中的代码怎么样，返回的值都不会改变，任然是之前保存的值），所以函数返回值是在finally执行前确定的。 finally中包含return语句，程序会在finally中提前退出123456789101112131415161718public static String method(String str) &#123; try &#123; System.out.println("try--"); return str; &#125; catch (Exception e) &#123; System.out.println("exception-- " + e); &#125; finally &#123; System.out.println("finally--"); str = "finally"; // 在finally中的return 语句，会造成程序提前退出 return str; &#125;&#125;public static void main(String[] args) &#123; System.out.println(method("str"));&#125; 上述代码做了在finally中，使用return语句的测试，程序会在finally中提前退出，结果如下： 123try--finally--finally 经典测试题面题目输出什么？ 12345678910111213public static int demo5() &#123; try &#123; return printX(); &#125; finally &#123; System.out.println("finally trumps return... sort of"); &#125;&#125;public static int printX() &#123; System.out.println("X"); return 0;&#125; 输出结果： 123Xfinally trumps return... sort of0 上面这道题目含金量很高，程序顺序执行时先执行printX（）函数，此时得到返回值0并且将0保存到variable中对应的用于保存返回值的区域; 此时程序在执行finally语句因为finally语句中没有return语句，所以程序将返回值区域的0返回给上一级函数。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>异常</tag>
        <tag>Java关键字</tag>
        <tag>垃圾回收</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java自动装箱与拆箱]]></title>
    <url>%2Fjava-auto-box%2F</url>
    <content type="text"><![CDATA[什么是自动装箱和拆箱 自动装箱 就是Java自动将原始类型值转换成对应的对象，比如将int 的变量转换成Integer对象，这个过程叫做装箱，反之将Integer对象转换成int类型值，这个过程叫做拆箱。因为这里的装箱和拆箱是自动进行的非人为转换，所以就称作为自动装箱和拆箱。 原始类型byte, short, char, int, long, float, double 和 boolean 对应的封装类为Byte, Short, Character, Integer, Long, Float, Double, Boolean。下面例子是自动装箱和拆箱带来的疑惑 123456789101112131415161718192021222324252627public class Test &#123; public static void main(String[] args) &#123; test(); &#125; public static void test() &#123; int i = 40; int i0 = 40; Integer i1 = 40; Integer i2 = 40; Integer i3 = 0; Integer i4 = new Integer(40); Integer i5 = new Integer(40); Integer i6 = new Integer(0); Double d1=1.0; Double d2=1.0; System.out.println("i=i0\t" + (i == i0)); System.out.println("i1=i2\t" + (i1 == i2)); System.out.println("i1=i2+i3\t" + (i1 == i2 + i3)); System.out.println("i4=i5\t" + (i4 == i5)); System.out.println("i4=i5+i6\t" + (i4 == i5 + i6)); System.out.println("d1=d2\t" + (d1==d2)); System.out.println(); &#125; &#125; 请看下面的输出结果跟你预期的一样吗？ 1234567输出的结果：i=i0 truei1=i truei1=i2+i3 truei4=i5 falsei4=i5+i6 trued1=d2 false 为什么会这样？带着疑问继续往下看。 自动装箱和拆箱的原理自动装箱时编译器调用 valueOf() 将原始类型值转换成对象。同时自动拆箱时，编译器通过调用类似 intValue()，doubleValue() 这类的方法将对象转换成原始类型值。 明白自动装箱和拆箱的原理后，我们带着上面的疑问进行分析下Integer的自动装箱的实现源码。如下： 12345678910111213141516171819202122232425262728293031323334353637public static Integer valueOf(int i) &#123; //判断i是否在-128和127之间，存在则从ItegerCache中获取包装类的实例，否则ne一个新实例 if (i &gt;= IntegerCache.low &amp;&amp; i &lt;=IntegerCache.high) return IntegerCache.cache[i +(-IntegerCache.low)]; return new Integer(i);&#125;//使用亨元模式，来减少对象的创建（亨元设模式大家有必要了解一下，我认为是最简单的计模式，也许大家经常在项目中使用，不知道的名字而已）private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; //静态方法，类加载的时候进行初始化cace[],静态变量存放在常量池中 static &#123; // high value may be configured byproperty int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(java.lang.Integer.IntegerCach.high"); if (integerCacheHighPropValue !=null) &#123; try &#123; int i =parseInt(integerCacheHighropValue); i = Math.max(i, 127); // Maximum array size isInteger.MAX_VALUE h = Math.min(i,Integer.MAX_VALUE - (-low)-1); &#125; catch( NumberFormatExceptionnfe) &#123; // If the property cannotbe parsed into an int,ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) +1]; int j = low; for(int k = 0; k &lt; cache.length;k++) cache[k] = new Integer(j++); // range [-128, 127] must beinterned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125;&#125; Integer i1 = 40; 自动装箱，相当于调用了 Integer.valueOf(40); 方法。 首先 判断i值是否在 -128~127 之间，如果在 -128~127 之间则直接从 IntegerCache.cache 缓存中获取指定数字的包装类；不存在则new出一个新的包装类。 IntegerCache内部实现了一个Integer的静态常量数组，在类加载的时候，执行static静态块进行初始化-128到127之间的Integer对象，存放到cache数组中。cache属于常量，存放在java的方法区中。 如果你不了解方法区请点击这里查看JVM内存模型 接着看下面是java8种基本类型的自动装箱代码实现。如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//boolean原生类型自动装箱成Booleanpublic static Boolean valueOf(boolean b) &#123; return (b ? TRUE : FALSE);&#125;//byte原生类型自动装箱成Bytepublic static Byte valueOf(byte b) &#123; final int offset = 128; return ByteCache.cache[(int)b + offset];&#125;//byte原生类型自动装箱成Bytepublic static Short valueOf(short s) &#123; final int offset = 128; int sAsInt = s; if (sAsInt &gt;= -128 &amp;&amp; sAsInt &lt;= 127) &#123; // must cache return ShortCache.cache[sAsInt + offset]; &#125; return new Short(s);&#125;//char原生类型自动装箱成Characterpublic static Character valueOf(char c) &#123; if (c &lt;= 127) &#123; // must cache return CharacterCache.cache[(int)c]; &#125; return new Character(c);&#125; //int原生类型自动装箱成Integerpublic static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125;//int原生类型自动装箱成Longpublic static Long valueOf(long l) &#123; final int offset = 128; if (l &gt;= -128 &amp;&amp; l &lt;= 127) &#123; // will cache return LongCache.cache[(int)l + offset]; &#125; return new Long(l);&#125;//double原生类型自动装箱成Doublepublic static Double valueOf(double d) &#123; return new Double(d);&#125;//float原生类型自动装箱成Floatpublic static Float valueOf(float f) &#123; return new Float(f);&#125; 通过分析源码发现，只有double和float的自动装箱代码没有使用缓存，每次都是new 新的对象，其它的6种基本类型都使用了缓存策略。 使用缓存策略是因为，缓存的这些对象都是经常使用到的（如字符、-128至127之间的数字），防止每次自动装箱都创建一次对象的实例。 而double、float是浮点型的，没有特别的热的（经常使用到的）数据的，缓存效果没有其它几种类型使用效率高。下面在看下装箱和拆箱问题解惑。 123456789101112//1、这个没解释的就是trueSystem.out.println("i=i0\t" + (i == i0)); //true//2、int值只要在-128和127之间的自动装箱对象都从缓存中获取的，所以为trueSystem.out.println("i1=i2\t" + (i1 == i2)); //true//3、涉及到数字的计算，就必须先拆箱成int再做加法运算，所以不管他们的值是否在-128和127之间，只要数字一样就为trueSystem.out.println("i1=i2+i3\t" + (i1 == i2 + i3));//true //比较的是对象内存地址，所以为falseSystem.out.println("i4=i5\t" + (i4 == i5)); //false//5、同第3条解释，拆箱做加法运算，对比的是数字，所以为trueSystem.out.println("i4=i5+i6\t" + (i4 == i5 + i6));//true //double的装箱操作没有使用缓存，每次都是new Double，所以falseSystem.out.println("d1=d2\t" + (d1==d2));//false 相信你看到这就应该能明白上面的程序输出的结果为什么是true,false了，只要掌握原理，类似的问题就迎刃而解了]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>自动装箱</tag>
        <tag>基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象六大设计原则]]></title>
    <url>%2Fjava-design-parten%2F</url>
    <content type="text"><![CDATA[面向对象设计（OOD：Object Oriented Design） 缩写 英文名称 中文名称 SRP Single Responsibility Principle 单一职责原则 OCP Open Close Principle 开闭原则 LSP Liskov Substitution Principle 里氏替换原则 LoD Law of Demeter （ Least Knowledge Principle） 迪米特法则（最少知道原则） ISP Interface Segregation Principle 接口分离原则 DIP Dependency Inversion Principle 依赖倒置原则 单一职责原则定义一个类只允许有一个职责，即只有一个导致该类变更的原因。 类职责的变化往往就是导致类变化的原因：也就是说如果一个类具有多种职责，就会有多种导致这个类变化的原因，从而导致这个类的维护变得困难。 往往在软件开发中随着需求的不断增加，可能会给原来的类添加一些本来不属于它的一些职责，从而违反了单一职责原则。如果我们发现当前类的职责不仅仅有一个，就应该将本来不属于该类真正的职责分离出去。 不仅仅是类，函数（方法）也要遵循单一职责原则，即：一个函数（方法）只做一件事情。如果发现一个函数（方法）里面有不同的任务，则需要将不同的任务以另一个函数（方法）的形式分离出去。 优点如果类与方法的职责划分得很清晰，不但可以提高代码的可读性，更实际性地更降低了程序出错的风险，因为清晰的代码会让bug无处藏身，也有利于bug的追踪，也就是降低了程序的维护成本。 开闭原则定义一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 用抽象构建框架，用实现扩展细节 不以改动原有类的方式来实现新需求，而是应该以实现事先抽象出来的接口(或具体类集成抽象类)的方式来实现。 优点实践开闭原则的优点在于可以在不改动原有代码的前提下给程序扩展功能。增加了程序的可扩展性，同时也降低了程序的维护成本。 里氏替换原则定义所有引用基类的地方必须能透明地使用其子类的对象，也就是说子类对象可以替换其父类对象，而程序执行效果不变。 在继承体系中，子类中可以增加自己特有的方法，也可以实现父类的抽象方法 但是不能重写父类的非抽象方法，否则该继承关系就不是一个正确的继承关系。 优点可以检验继承使用的正确性，约束继承在使用上的泛滥。 迪米特法则定义一个对象应该对尽可能少的对象有接触，也就是只接触那些真正需要接触的对象。 迪米特法则也叫做最少知道原则（Least Know Principle） 一个类应该只和它的成员变量，方法的输入，返回参数中的类作交流，而不应该引入其他的类（间接交流）。 优点实践迪米特法则可以良好地降低类与类之间的耦合，减少类与类之间的关联程度，让类与类之间的协作更加直接。 接口分离原则定义多个特定的客户端接口要好于一个通用性的总接口。 客户端不应该依赖它不需要实现的接口。 不建立庞大臃肿的接口，应尽量细化接口，接口中的方法应该尽量少。 优点避免同一个接口里面包含不同类职责的方法，接口责任划分更加明确，符合高内聚低耦合的思想。 依赖倒置原则定义依赖抽象，而不是依赖实现。 抽象不应该依赖细节；细节应该依赖抽象。 高层模块不能依赖低层模块，二者都应该依赖抽象。 针对接口编程，而不是针对实现编程。 尽量不要从具体的类派生，而是以继承抽象类或实现接口来实现。 关于高层模块与低层模块的划分可以按照决策能力的高低进行划分。业务层自然就处于上层模块，逻辑层和数据层自然就归类为底层。 优点通过抽象来搭建框架，建立类和类的关联，以减少类间的耦合性。而且以抽象搭建的系统要比以具体实现搭建的系统更加稳定，扩展性更高，同时也便于维护。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>设计原则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot入门到进阶（含源码）]]></title>
    <url>%2Fspringb-start2advanced%2F</url>
    <content type="text"><![CDATA[Spring Boot 入门1、Spring Boot 简介 简化Spring应用开发的一个框架； 整个Spring技术栈的一个大整合； J2EE开发的一站式解决方案； 2、微服务2014，martin fowler 微服务：架构风格（服务微化） 一个应用应该是一组小型服务；可以通过HTTP的方式进行互通； 单体应用：ALL IN ONE 微服务：每一个功能元素最终都是一个可独立替换和独立升级的软件单元； 详细参照微服务文档 3、环境准备http://www.gulixueyuan.com/ 谷粒学院 环境约束 –jdk1.8：Spring Boot 推荐jdk1.7及以上；java version “1.8.0_112” –maven3.x：maven 3.3以上版本；Apache Maven 3.3.9 –IntelliJIDEA2017：IntelliJ IDEA 2017.2.2 x64、STS –SpringBoot 1.5.9.RELEASE：1.5.9； 统一环境； 1、MAVEN设置；给maven 的settings.xml配置文件的profiles标签添加 123456789101112&lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt;&lt;/profile&gt; 2、IDEA设置整合maven进来； 4、Spring Boot HelloWorld一个功能： 浏览器发送hello请求，服务器接受请求并处理，响应Hello World字符串； 1、创建一个maven工程；（jar）2、导入spring boot相关的依赖1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3、编写一个主程序；启动Spring Boot应用12345678910111213/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123; public static void main(String[] args) &#123; // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); &#125;&#125; 4、编写相关的Controller、Service123456789@Controllerpublic class HelloController &#123; @ResponseBody @RequestMapping("/hello") public String hello()&#123; return "Hello World!"; &#125;&#125; 5、运行主程序测试6、简化部署123456789&lt;!-- 这个插件，可以将应用打包成一个可执行的jar包；--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 将这个应用打成jar包，直接使用java -jar的命令进行执行； 5、Hello World探究1、POM文件1、父项目1234567891011121314&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;他的父项目是&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;&lt;/parent&gt;他来真正管理Spring Boot应用里面的所有依赖版本； Spring Boot的版本仲裁中心； 以后我们导入依赖默认是不需要写版本；（没有在dependencies里面管理的依赖自然需要声明版本号） 2、启动器1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter-==web==： ​ spring-boot-starter：spring-boot场景启动器；帮我们导入了web模块正常运行所依赖的组件； Spring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter相关场景的所有依赖都会导入进来。要用什么功能就导入什么场景的启动器 2、主程序类，主入口类123456789101112/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123; public static void main(String[] args) &#123; // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); &#125;&#125; @SpringBootApplication: Spring Boot应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用； 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; @SpringBootConfiguration:Spring Boot的配置类； ​ 标注在某个类上，表示这是一个Spring Boot的配置类； ​ @Configuration:配置类上来标注这个注解； ​ 配置类 —– 配置文件；配置类也是容器中的一个组件；@Component @EnableAutoConfiguration：开启自动配置功能； ​ 以前我们需要配置的东西，Spring Boot帮我们自动配置；@EnableAutoConfiguration告诉SpringBoot开启自动配置功能；这样自动配置才能生效； 123@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; ​ @AutoConfigurationPackage：自动配置包 ​ @Import(AutoConfigurationPackages.Registrar.class)： ​ Spring的底层注解@Import，给容器中导入一个组件；导入的组件由AutoConfigurationPackages.Registrar.class； ==将主配置类（@SpringBootApplication标注的类）的所在包及下面所有子包里面的所有组件扫描到Spring容器；== ​ @Import(EnableAutoConfigurationImportSelector.class)； ​ 给容器中导入组件？ ​ EnableAutoConfigurationImportSelector：导入哪些组件的选择器； ​ 将所有需要导入的组件以全类名的方式返回；这些组件就会被添加到容器中； ​ 会给容器中导入非常多的自动配置类（xxxAutoConfiguration）；就是给容器中导入这个场景需要的所有组件，并配置好这些组件； 有了自动配置类，免去了我们手动编写配置注入功能组件等的工作； ​ SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class,classLoader)； ==Spring Boot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值，将这些值作为自动配置类导入到容器中，自动配置类就生效，帮我们进行自动配置工作；==以前我们需要自己配置的东西，自动配置类都帮我们； J2EE的整体整合解决方案和自动配置都在spring-boot-autoconfigure-1.5.9.RELEASE.jar； ​ ==Spring注解版（谷粒学院）== 6、使用Spring Initializer快速创建Spring Boot项目1、IDEA：使用 Spring Initializer快速创建项目IDE都支持使用Spring的项目创建向导快速创建一个Spring Boot项目； 选择我们需要的模块；向导会联网创建Spring Boot项目； 默认生成的Spring Boot项目； 主程序已经生成好了，我们只需要我们自己的逻辑 resources文件夹中目录结构 static：保存所有的静态资源； js css images； templates：保存所有的模板页面；（Spring Boot默认jar包使用嵌入式的Tomcat，默认不支持JSP页面）；可以使用模板引擎（freemarker、thymeleaf）； application.properties：Spring Boot应用的配置文件；可以修改一些默认设置； 2、STS使用 Spring Starter Project快速创建项目 二、配置文件1、配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的； •application.properties •application.yml 配置文件的作用：修改SpringBoot自动配置的默认值；SpringBoot在底层都给我们自动配置好； YAML（YAML Ain’t Markup Language） ​ YAML A Markup Language：是一个标记语言 ​ YAML isn’t Markup Language：不是一个标记语言； 标记语言： ​ 以前的配置文件；大多都使用的是 xxxx.xml文件； ​ YAML：以数据为中心，比json、xml等更适合做配置文件； ​ YAML：配置例子 12server: port: 8081 ​ XML： 123&lt;server&gt; &lt;port&gt;8081&lt;/port&gt;&lt;/server&gt; 2、YAML语法：1、基本语法k:(空格)v：表示一对键值对（空格必须有）； 以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的 123server: port: 8081 path: /hello 属性和值也是大小写敏感； 2、值的写法字面量：普通的值（数字，字符串，布尔）​ k: v：字面直接来写； ​ 字符串默认不用加上单引号或者双引号； ​ “”：双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思 ​ name: “zhangsan \n lisi”：输出；zhangsan 换行 lisi ​ ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据 ​ name: ‘zhangsan \n lisi’：输出；zhangsan \n lisi 对象、Map（属性和值）（键值对）：​ k: v：在下一行来写对象的属性和值的关系；注意缩进 ​ 对象还是k: v的方式 123friends: lastName: zhangsan age: 20 行内写法： 1friends: &#123;lastName: zhangsan,age: 18&#125; 数组（List、Set）：用- 值表示数组中的一个元素 1234pets: - cat - dog - pig 行内写法 1pets: [cat,dog,pig] 3、配置文件值注入配置文件 123456789101112person: lastName: hello age: 18 boss: false birth: 2017/12/12 maps: &#123;k1: v1,k2: 12&#125; lists: - lisi - zhaoliu dog: name: 小狗 age: 12 javaBean： 1234567891011121314151617181920/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = "person"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * */@Component@ConfigurationProperties(prefix = "person")public class Person &#123; private String lastName; private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 我们可以导入配置文件处理器，以后编写配置就有提示了 123456&lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 1、properties配置文件在idea中默认utf-8可能会乱码调整 2、@Value获取值和@ConfigurationProperties获取值比较 @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 配置文件yml还是properties他们都能获取到值； 如果说，我们只是在某个业务逻辑中需要获取一下配置文件中的某项值，使用@Value； 如果说，我们专门编写了一个javaBean来和配置文件进行映射，我们就直接使用@ConfigurationProperties； 3、配置文件注入值数据校验123456789101112131415161718192021222324@Component@ConfigurationProperties(prefix = "person")@Validatedpublic class Person &#123; /** * &lt;bean class="Person"&gt; * &lt;property name="lastName" value="字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;"&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 @Email //@Value("$&#123;person.last-name&#125;") private String lastName; //@Value("#&#123;11*2&#125;") private Integer age; //@Value("true") private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 4、@PropertySource&amp;@ImportResource&amp;@Bean@PropertySource：加载指定的配置文件； 1234567891011121314151617181920212223242526272829/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = "person"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * @ConfigurationProperties(prefix = "person")默认从全局配置文件中获取值； * */@PropertySource(value = &#123;"classpath:person.properties"&#125;)@Component@ConfigurationProperties(prefix = "person")//@Validatedpublic class Person &#123; /** * &lt;bean class="Person"&gt; * &lt;property name="lastName" value="字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;"&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 // @Email //@Value("$&#123;person.last-name&#125;") private String lastName; //@Value("#&#123;11*2&#125;") private Integer age; //@Value("true") private Boolean boss; @ImportResource：导入Spring的配置文件，让配置文件里面的内容生效； Spring Boot里面没有Spring的配置文件，我们自己编写的配置文件，也不能自动识别； 想让Spring的配置文件生效，加载进来；@ImportResource标注在一个配置类上 12@ImportResource(locations = &#123;"classpath:beans.xml"&#125;)导入Spring的配置文件让其生效 不来编写Spring的配置文件 12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="helloService" class="com.atguigu.springboot.service.HelloService"&gt;&lt;/bean&gt;&lt;/beans&gt; SpringBoot推荐给容器中添加组件的方式；推荐使用全注解的方式 1、配置类@Configuration——&gt;Spring配置文件 2、使用@Bean给容器中添加组件 12345678910111213141516/** * @Configuration：指明当前类是一个配置类；就是来替代之前的Spring配置文件 * * 在配置文件中用&lt;bean&gt;&lt;bean/&gt;标签添加组件 * */@Configurationpublic class MyAppConfig &#123; //将方法的返回值添加到容器中；容器中这个组件默认的id就是方法名 @Bean public HelloService helloService02()&#123; System.out.println("配置类@Bean给容器中添加组件了..."); return new HelloService(); &#125;&#125; ##4、配置文件占位符 1、随机数12$&#123;random.value&#125;、$&#123;random.int&#125;、$&#123;random.long&#125;$&#123;random.int(10)&#125;、$&#123;random.int[1024,65536]&#125; 2、占位符获取之前配置的值，如果没有可以是用:指定默认值123456789person.last-name=张三$&#123;random.uuid&#125;person.age=$&#123;random.int&#125;person.birth=2017/12/15person.boss=falseperson.maps.k1=v1person.maps.k2=14person.lists=a,b,cperson.dog.name=$&#123;person.hello:hello&#125;_dogperson.dog.age=15 5、Profile1、多Profile文件我们在主配置文件编写的时候，文件名可以是 application-{profile}.properties/yml 默认使用application.properties的配置； 2、yml支持多文档块方式1234567891011121314151617181920server: port: 8081spring: profiles: active: prod---server: port: 8083spring: profiles: dev---server: port: 8084spring: profiles: prod #指定属于哪个环境 3、激活指定profile​ 1、在配置文件中指定 spring.profiles.active=dev ​ 2、命令行： ​ java -jar spring-boot-02-config-0.0.1-SNAPSHOT.jar –spring.profiles.active=dev； ​ 可以直接在测试的时候，配置传入命令行参数 ​ 3、虚拟机参数； ​ -Dspring.profiles.active=dev 6、配置文件加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件 –file:./config/ –file:./ –classpath:/config/ –classpath:/ 优先级由高到底，高优先级的配置会覆盖低优先级的配置； SpringBoot会从这四个位置全部加载主配置文件；互补配置； ==我们还可以通过spring.config.location来改变默认的配置文件位置== 项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置； java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –spring.config.location=G:/application.properties 7、外部配置加载顺序==SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置== 1.命令行参数 所有的配置都可以在命令行上进行指定 java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –server.port=8087 –server.context-path=/abc 多个配置用空格分开； –配置项=值 2.来自java:comp/env的JNDI属性 3.Java系统属性（System.getProperties()） 4.操作系统环境变量 5.RandomValuePropertySource配置的random.*属性值 ==由jar包外向jar包内进行寻找；== ==优先加载带profile== 6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 ==再来加载不带profile== 8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件 9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件 10.@Configuration注解类上的@PropertySource 11.通过SpringApplication.setDefaultProperties指定的默认属性 所有支持的配置加载来源； 参考官方文档 8、自动配置原理配置文件到底能写什么？怎么写？自动配置原理； 配置文件能配置的属性参照 1、自动配置原理：1）、SpringBoot启动的时候加载主配置类，开启了自动配置功能 ==@EnableAutoConfiguration== 2）、@EnableAutoConfiguration 作用： 利用EnableAutoConfigurationImportSelector给容器中导入一些组件？ 可以查看selectImports()方法的内容； List configurations = getCandidateConfigurations(annotationMetadata, attributes);获取候选的配置 1234SpringFactoriesLoader.loadFactoryNames()扫描所有jar包类路径下 META-INF/spring.factories把扫描到的这些文件的内容包装成properties对象从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中 ​ ==将 类路径下 META-INF/spring.factories 里面配置的所有EnableAutoConfiguration的值加入到了容器中；== 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置； 3）、每一个自动配置类进行自动配置功能； 4）、以HttpEncodingAutoConfiguration（Http编码自动配置） 为例解释自动配置原理； 12345678910111213141516171819202122232425262728@Configuration //表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@EnableConfigurationProperties(HttpEncodingProperties.class) //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中@ConditionalOnWebApplication //Spring底层@Conditional注解（Spring注解版），根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效； 判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnClass(CharacterEncodingFilter.class) //判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤器；@ConditionalOnProperty(prefix = "spring.http.encoding", value = "enabled", matchIfMissing = true) //判断配置文件中是否存在某个配置 spring.http.encoding.enabled；如果不存在，判断也是成立的//即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；public class HttpEncodingAutoConfiguration &#123; //他已经和SpringBoot的配置文件映射了 private final HttpEncodingProperties properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123; this.properties = properties; &#125; @Bean //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？ public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; 根据当前不同的条件判断，决定这个配置类是否生效？ 一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的； 5）、所有在配置文件中能配置的属性都是在xxxxProperties类中封装者‘；配置文件能配置什么就可以参照某个功能对应的这个属性类 1234@ConfigurationProperties(prefix = "spring.http.encoding") //从配置文件中获取指定的值和bean的属性进行绑定public class HttpEncodingProperties &#123; public static final Charset DEFAULT_CHARSET = Charset.forName("UTF-8"); 精髓： ​ 1）、SpringBoot启动会加载大量的自动配置类 ​ 2）、我们看我们需要的功能有没有SpringBoot默认写好的自动配置类； ​ 3）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了） ​ 4）、给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值； xxxxAutoConfigurartion：自动配置类； 给容器中添加组件 xxxxProperties:封装配置文件中相关属性； 2、细节1、@Conditional派生注解（Spring注解版原生的@Conditional作用）作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 自动配置类必须在一定的条件下才能生效； 我们怎么知道哪些自动配置类生效； ==我们可以通过启用 debug=true属性；来让控制台打印自动配置报告==，这样我们就可以很方便的知道哪些自动配置类生效； 1234567891011121314151617181920212223=========================AUTO-CONFIGURATION REPORT=========================Positive matches:（自动配置类启用的）----------------- DispatcherServletAutoConfiguration matched: - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet'; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) - @ConditionalOnWebApplication (required) found StandardServletEnvironment (OnWebApplicationCondition) Negative matches:（没有启动，没有匹配成功的自动配置类）----------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'javax.jms.ConnectionFactory', 'org.apache.activemq.ActiveMQConnectionFactory' (OnClassCondition) AopAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'org.aspectj.lang.annotation.Aspect', 'org.aspectj.lang.reflect.Advice' (OnClassCondition) 三、日志1、日志框架 小张；开发一个大型系统； ​ 1、System.out.println(“”)；将关键数据打印在控制台；去掉？写在一个文件？ ​ 2、框架来记录系统的一些运行时信息；日志框架 ； zhanglogging.jar； ​ 3、高大上的几个功能？异步模式？自动归档？xxxx？ zhanglogging-good.jar？ ​ 4、将以前框架卸下来？换上新的框架，重新修改之前相关的API；zhanglogging-prefect.jar； ​ 5、JDBC—数据库驱动； ​ 写了一个统一的接口层；日志门面（日志的一个抽象层）；logging-abstract.jar； ​ 给项目中导入具体的日志实现就行了；我们之前的日志框架都是实现的抽象层； 市面上的日志框架； JUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j…. 日志门面 （日志的抽象层） 日志实现 JCL（Jakarta Commons Logging） SLF4j（Simple Logging Facade for Java） jboss-logging Log4j JUL（java.util.logging） Log4j2 Logback 左边选一个门面（抽象层）、右边来选一个实现； 日志门面： SLF4J； 日志实现：Logback； SpringBoot：底层是Spring框架，Spring框架默认是用JCL；‘ ​ ==SpringBoot选用 SLF4j和logback；== 2、SLF4j使用1、如何在系统中使用SLF4j https://www.slf4j.org以后开发的时候，日志记录方法的调用，不应该来直接调用日志的实现类，而是调用日志抽象层里面的方法； 给系统里面导入slf4j的jar和 logback的实现jar 123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld &#123; public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info("Hello World"); &#125;&#125; 图示； 每一个日志的实现框架都有自己的配置文件。使用slf4j以后，配置文件还是做成日志实现框架自己本身的配置文件； 2、遗留问题a（slf4j+logback）: Spring（commons-logging）、Hibernate（jboss-logging）、MyBatis、xxxx 统一日志记录，即使是别的框架和我一起统一使用slf4j进行输出？ 如何让系统中所有的日志都统一到slf4j； ==1、将系统中其他日志框架先排除出去；== ==2、用中间包来替换原有的日志框架；== ==3、我们导入slf4j其他的实现== 3、SpringBoot日志关系1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot使用它来做日志功能； 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; 底层依赖关系 总结： ​ 1）、SpringBoot底层也是使用slf4j+logback的方式进行日志记录 ​ 2）、SpringBoot也把其他的日志都替换成了slf4j； ​ 3）、中间替换包？ 123456@SuppressWarnings("rawtypes")public abstract class LogFactory &#123; static String UNSUPPORTED_OPERATION_IN_JCL_OVER_SLF4J = "http://www.slf4j.org/codes.html#unsupported_operation_in_jcl_over_slf4j"; static LogFactory logFactory = new SLF4JLogFactory(); ​ 4）、如果我们要引入其他框架？一定要把这个框架的默认日志依赖移除掉？ ​ Spring框架用的是commons-logging； 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; ==SpringBoot能自动适配所有的日志，而且底层使用slf4j+logback的方式记录日志，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉即可；== 4、日志使用；1、默认配置SpringBoot默认帮我们配置好了日志； 123456789101112131415161718//记录器Logger logger = LoggerFactory.getLogger(getClass());@Testpublic void contextLoads() &#123; //System.out.println(); //日志的级别； //由低到高 trace&lt;debug&lt;info&lt;warn&lt;error //可以调整输出的日志级别；日志就只会在这个级别以以后的高级别生效 logger.trace("这是trace日志..."); logger.debug("这是debug日志..."); //SpringBoot默认给我们使用的是info级别的，没有指定级别的就用SpringBoot默认规定的级别；root级别 logger.info("这是info日志..."); logger.warn("这是warn日志..."); logger.error("这是error日志...");&#125; 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger{50} 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%nSpringBoot修改日志的默认配置 123456789101112131415logging.level.com.atguigu=trace#logging.path=# 不指定路径在当前项目下生成springboot.log日志# 可以指定完整的路径；#logging.file=G:/springboot.log# 在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件logging.path=/spring/log# 在控制台输出的日志的格式logging.pattern.console=%d&#123;yyyy-MM-dd&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n# 指定文件中日志输出的格式logging.pattern.file=%d&#123;yyyy-MM-dd&#125; === [%thread] === %-5level === %logger&#123;50&#125; ==== %msg%n logging.file logging.path Example Description (none) (none) 只在控制台输出 指定文件名 (none) my.log 输出日志到my.log文件 (none) 指定目录 /var/log 输出到指定目录的 spring.log 文件中 2、指定配置给类路径下放上每个日志框架自己的配置文件即可；SpringBoot就不使用他默认配置的了 Logging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties logback.xml：直接就被日志框架识别了； logback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，可以使用SpringBoot的高级Profile功能 1234&lt;springProfile name="staging"&gt; &lt;!-- configuration to be enabled when the "staging" profile is active --&gt; 可以指定某段配置只在某个环境下生效&lt;/springProfile&gt; 如： 12345678910111213141516171819&lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt; &lt;springProfile name="dev"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ----&gt; [%thread] ---&gt; %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name="!dev"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ==== [%thread] ==== %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt; &lt;/appender&gt; 如果使用logback.xml作为日志配置文件，还要使用profile功能，会有以下错误 no applicable action for [springProfile] 5、切换日志框架可以按照slf4j的日志适配图，进行相关的切换； slf4j+log4j的方式； 12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;/dependency&gt; 切换为log4j2 123456789101112131415 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt; 四、Web开发1、简介使用SpringBoot； 1）、创建SpringBoot应用，选中我们需要的模块； 2）、SpringBoot已经默认将这些场景配置好了，只需要在配置文件中指定少量配置就可以运行起来 3）、自己编写业务代码； 自动配置原理？ 这个场景SpringBoot帮我们配置了什么？能不能修改？能修改哪些配置？能不能扩展？xxx 12xxxxAutoConfiguration：帮我们给容器中自动配置组件；xxxxProperties:配置类来封装配置文件的内容； 2、SpringBoot对静态资源的映射规则；123@ConfigurationProperties(prefix = "spring.resources", ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware &#123; //可以设置和静态资源有关的参数，缓存时间等 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364WebMvcAuotConfiguration： @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if (!this.resourceProperties.isAddMappings()) &#123; logger.debug("Default resource handling disabled"); return; &#125; Integer cachePeriod = this.resourceProperties.getCachePeriod(); if (!registry.hasMappingForPattern("/webjars/**")) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler("/webjars/**") .addResourceLocations( "classpath:/META-INF/resources/webjars/") .setCachePeriod(cachePeriod)); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); //静态资源文件夹映射 if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations( this.resourceProperties.getStaticLocations()) .setCachePeriod(cachePeriod)); &#125; &#125; //配置欢迎页映射 @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping( ResourceProperties resourceProperties) &#123; return new WelcomePageHandlerMapping(resourceProperties.getWelcomePage(), this.mvcProperties.getStaticPathPattern()); &#125; //配置喜欢的图标 @Configuration @ConditionalOnProperty(value = "spring.mvc.favicon.enabled", matchIfMissing = true) public static class FaviconConfiguration &#123; private final ResourceProperties resourceProperties; public FaviconConfiguration(ResourceProperties resourceProperties) &#123; this.resourceProperties = resourceProperties; &#125; @Bean public SimpleUrlHandlerMapping faviconHandlerMapping() &#123; SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE + 1); //所有 **/favicon.ico mapping.setUrlMap(Collections.singletonMap("**/favicon.ico", faviconRequestHandler())); return mapping; &#125; @Bean public ResourceHttpRequestHandler faviconRequestHandler() &#123; ResourceHttpRequestHandler requestHandler = new ResourceHttpRequestHandler(); requestHandler .setLocations(this.resourceProperties.getFaviconLocations()); return requestHandler; &#125; &#125; ==1）、所有 /webjars/** ，都去 classpath:/META-INF/resources/webjars/ 找资源；== ​ webjars：以jar包的方式引入静态资源； http://www.webjars.org/ localhost:8080/webjars/jquery/3.3.1/jquery.js 123456&lt;!--引入jquery-webjar--&gt;在访问的时候只需要写webjars下面资源的名称即可 &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; ==2）、”/**” 访问当前项目的任何资源，都去（静态资源的文件夹）找映射== 12345&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,&quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &quot;/&quot;：当前项目的根路径 localhost:8080/abc === 去静态资源文件夹里面找abc ==3）、欢迎页； 静态资源文件夹下的所有index.html页面；被”/**”映射；== ​ localhost:8080/ 找index页面 ==4）、所有的 **/favicon.ico 都是在静态资源文件下找；== 3、模板引擎JSP、Velocity、Freemarker、Thymeleaf SpringBoot推荐的Thymeleaf； 语法更简单，功能更强大； 1、引入thymeleaf；123456789101112 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; 2.1.6 &lt;/dependency&gt;切换thymeleaf版本&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt; &lt;!-- 布局功能的支持程序 thymeleaf3主程序 layout2以上版本 --&gt; &lt;!-- thymeleaf2 layout1--&gt; &lt;thymeleaf-layout-dialect.version&gt;2.2.2&lt;/thymeleaf-layout-dialect.version&gt; &lt;/properties&gt; 2、Thymeleaf使用1234567891011@ConfigurationProperties(prefix = "spring.thymeleaf")public class ThymeleafProperties &#123; private static final Charset DEFAULT_ENCODING = Charset.forName("UTF-8"); private static final MimeType DEFAULT_CONTENT_TYPE = MimeType.valueOf("text/html"); public static final String DEFAULT_PREFIX = "classpath:/templates/"; public static final String DEFAULT_SUFFIX = ".html"; // 只要我们把HTML页面放在classpath:/templates/，thymeleaf就能自动渲染； 使用： 1、导入thymeleaf的名称空间 1&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt; 2、使用thymeleaf语法； 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;成功！&lt;/h1&gt; &lt;!--th:text 将div里面的文本内容设置为 --&gt; &lt;div th:text="$&#123;hello&#125;"&gt;这是显示欢迎信息&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3、语法规则1）、th:text；改变当前元素里面的文本内容； ​ th：任意html属性；来替换原生属性的值 2）、表达式？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869Simple expressions:（表达式语法） Variable Expressions: $&#123;...&#125;：获取变量值；OGNL； 1）、获取对象的属性、调用方法 2）、使用内置的基本对象： #ctx : the context object. #vars: the context variables. #locale : the context locale. #request : (only in Web Contexts) the HttpServletRequest object. #response : (only in Web Contexts) the HttpServletResponse object. #session : (only in Web Contexts) the HttpSession object. #servletContext : (only in Web Contexts) the ServletContext object. $&#123;session.foo&#125; 3）、内置的一些工具对象：#execInfo : information about the template being processed.#messages : methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #&#123;…&#125; syntax.#uris : methods for escaping parts of URLs/URIs#conversions : methods for executing the configured conversion service (if any).#dates : methods for java.util.Date objects: formatting, component extraction, etc.#calendars : analogous to #dates , but for java.util.Calendar objects.#numbers : methods for formatting numeric objects.#strings : methods for String objects: contains, startsWith, prepending/appending, etc.#objects : methods for objects in general.#bools : methods for boolean evaluation.#arrays : methods for arrays.#lists : methods for lists.#sets : methods for sets.#maps : methods for maps.#aggregates : methods for creating aggregates on arrays or collections.#ids : methods for dealing with id attributes that might be repeated (for example, as a result of an iteration). Selection Variable Expressions: *&#123;...&#125;：选择表达式：和$&#123;&#125;在功能上是一样； 补充：配合 th:object=&quot;$&#123;session.user&#125;： &lt;div th:object=&quot;$&#123;session.user&#125;&quot;&gt; &lt;p&gt;Name: &lt;span th:text=&quot;*&#123;firstName&#125;&quot;&gt;Sebastian&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Surname: &lt;span th:text=&quot;*&#123;lastName&#125;&quot;&gt;Pepper&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Nationality: &lt;span th:text=&quot;*&#123;nationality&#125;&quot;&gt;Saturn&lt;/span&gt;.&lt;/p&gt; &lt;/div&gt; Message Expressions: #&#123;...&#125;：获取国际化内容 Link URL Expressions: @&#123;...&#125;：定义URL； @&#123;/order/process(execId=$&#123;execId&#125;,execType=&apos;FAST&apos;)&#125; Fragment Expressions: ~&#123;...&#125;：片段引用表达式 &lt;div th:insert=&quot;~&#123;commons :: main&#125;&quot;&gt;...&lt;/div&gt; Literals（字面量） Text literals: &apos;one text&apos; , &apos;Another one!&apos; ,… Number literals: 0 , 34 , 3.0 , 12.3 ,… Boolean literals: true , false Null literal: null Literal tokens: one , sometext , main ,…Text operations:（文本操作） String concatenation: + Literal substitutions: |The name is $&#123;name&#125;|Arithmetic operations:（数学运算） Binary operators: + , - , * , / , % Minus sign (unary operator): -Boolean operations:（布尔运算） Binary operators: and , or Boolean negation (unary operator): ! , notComparisons and equality:（比较运算） Comparators: &gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le ) Equality operators: == , != ( eq , ne )Conditional operators:条件运算（三元运算符） If-then: (if) ? (then) If-then-else: (if) ? (then) : (else) Default: (value) ?: (defaultvalue)Special tokens: No-Operation: _ 4、SpringMVC自动配置https://docs.spring.io/spring-boot/docs/1.5.10.RELEASE/reference/htmlsingle/#boot-features-developing-web-applications 1. Spring MVC auto-configurationSpring Boot 自动配置好了SpringMVC 以下是SpringBoot对SpringMVC的默认配置:==（WebMvcAutoConfiguration）== Inclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans. 自动配置了ViewResolver（视图解析器：根据方法的返回值得到视图对象（View），视图对象决定如何渲染（转发？重定向？）） ContentNegotiatingViewResolver：组合所有的视图解析器的； ==如何定制：我们可以自己给容器中添加一个视图解析器；自动的将其组合进来；== Support for serving static resources, including support for WebJars (see below).静态资源文件夹路径,webjars Static index.html support. 静态首页访问 Custom Favicon support (see below). favicon.ico ​ 自动注册了 of Converter, GenericConverter, Formatter beans. Converter：转换器； public String hello(User user)：类型转换使用Converter Formatter 格式化器； 2017.12.17===Date； 12345@Bean@ConditionalOnProperty(prefix = "spring.mvc", name = "date-format")//在文件中配置日期格式化的规则public Formatter&lt;Date&gt; dateFormatter() &#123; return new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件&#125; ​ ==自己添加的格式化器转换器，我们只需要放在容器中即可== Support for HttpMessageConverters (see below). HttpMessageConverter：SpringMVC用来转换Http请求和响应的；User—Json； HttpMessageConverters 是从容器中确定；获取所有的HttpMessageConverter； ==自己给容器中添加HttpMessageConverter，只需要将自己的组件注册容器中（@Bean,@Component）== ​ Automatic registration of MessageCodesResolver (see below).定义错误代码生成规则 Automatic use of a ConfigurableWebBindingInitializer bean (see below). ==我们可以配置一个ConfigurableWebBindingInitializer来替换默认的；（添加到容器）== 12初始化WebDataBinder；请求数据=====JavaBean； org.springframework.boot.autoconfigure.web：web的所有自动场景； If you want to keep Spring Boot MVC features, and you just want to add additional MVC configuration (interceptors, formatters, view controllers etc.) you can add your own @Configuration class of type WebMvcConfigurerAdapter, but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter or ExceptionHandlerExceptionResolver you can declare a WebMvcRegistrationsAdapter instance providing such components. If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc. 2、扩展SpringMVC1234567&lt;mvc:view-controller path="/hello" view-name="success"/&gt;&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/hello"/&gt; &lt;bean&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; ==编写一个配置类（@Configuration），是WebMvcConfigurerAdapter类型；不能标注@EnableWebMvc==; 既保留了所有的自动配置，也能用我们扩展的配置； 1234567891011//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController("/atguigu").setViewName("success"); &#125;&#125; 原理： ​ 1）、WebMvcAutoConfiguration是SpringMVC的自动配置类 ​ 2）、在做其他自动配置时会导入；@Import(EnableWebMvcConfiguration.class) 123456789101112131415161718 @Configurationpublic static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration &#123; private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); //从容器中获取所有的WebMvcConfigurer @Autowired(required = false) public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123; if (!CollectionUtils.isEmpty(configurers)) &#123; this.configurers.addWebMvcConfigurers(configurers); //一个参考实现；将所有的WebMvcConfigurer相关配置都来一起调用； @Override // public void addViewControllers(ViewControllerRegistry registry) &#123; // for (WebMvcConfigurer delegate : this.delegates) &#123; // delegate.addViewControllers(registry); // &#125; &#125; &#125;&#125; ​ 3）、容器中所有的WebMvcConfigurer都会一起起作用； ​ 4）、我们的配置类也会被调用； ​ 效果：SpringMVC的自动配置和我们的扩展配置都会起作用； 3、全面接管SpringMVC；SpringBoot对SpringMVC的自动配置不需要了，所有都是我们自己配置；所有的SpringMVC的自动配置都失效了 我们需要在配置类中添加@EnableWebMvc即可； 123456789101112//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@EnableWebMvc@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController("/atguigu").setViewName("success"); &#125;&#125; 原理： 为什么@EnableWebMvc自动配置就失效了； 1）@EnableWebMvc的核心 12@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123; 2）、 12@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; 3）、 12345678910@Configuration@ConditionalOnWebApplication@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class &#125;)//容器中没有这个组件的时候，这个自动配置类才生效@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123; 4）、@EnableWebMvc将WebMvcConfigurationSupport组件导入进来； 5）、导入的WebMvcConfigurationSupport只是SpringMVC最基本的功能； 5、如何修改SpringBoot的默认配置模式： ​ 1）、SpringBoot在自动配置很多组件的时候，先看容器中有没有用户自己配置的（@Bean、@Component）如果有就用用户配置的，如果没有，才自动配置；如果有些组件可以有多个（ViewResolver）将用户配置的和自己默认的组合起来； ​ 2）、在SpringBoot中会有非常多的xxxConfigurer帮助我们进行扩展配置 ​ 3）、在SpringBoot中会有很多的xxxCustomizer帮助我们进行定制配置 6、RestfulCRUD1）、默认访问首页1234567891011121314151617181920212223242526//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能//@EnableWebMvc 不要接管SpringMVC@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController("/atguigu").setViewName("success"); &#125; //所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/").setViewName("login"); registry.addViewController("/index.html").setViewName("login"); &#125; &#125;; return adapter; &#125;&#125; 2）、国际化1）、编写国际化配置文件； 2）、使用ResourceBundleMessageSource管理国际化资源文件 3）、在页面使用fmt:message取出国际化内容 步骤： 1）、编写国际化配置文件，抽取页面需要显示的国际化消息 2）、SpringBoot自动配置好了管理国际化资源文件的组件； 12345678910111213141516171819202122232425262728@ConfigurationProperties(prefix = "spring.messages")public class MessageSourceAutoConfiguration &#123; /** * Comma-separated list of basenames (essentially a fully-qualified classpath * location), each following the ResourceBundle convention with relaxed support for * slash based locations. If it doesn't contain a package qualifier (such as * "org.mypackage"), it will be resolved from the classpath root. */ private String basename = "messages"; //我们的配置文件可以直接放在类路径下叫messages.properties； @Bean public MessageSource messageSource() &#123; ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); if (StringUtils.hasText(this.basename)) &#123; //设置国际化资源文件的基础名（去掉语言国家代码的） messageSource.setBasenames(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(this.basename))); &#125; if (this.encoding != null) &#123; messageSource.setDefaultEncoding(this.encoding.name()); &#125; messageSource.setFallbackToSystemLocale(this.fallbackToSystemLocale); messageSource.setCacheSeconds(this.cacheSeconds); messageSource.setAlwaysUseMessageFormat(this.alwaysUseMessageFormat); return messageSource; &#125; 3）、去页面获取国际化的值； 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"&gt; &lt;meta name="description" content=""&gt; &lt;meta name="author" content=""&gt; &lt;title&gt;Signin Template for Bootstrap&lt;/title&gt; &lt;!-- Bootstrap core CSS --&gt; &lt;link href="asserts/css/bootstrap.min.css" th:href="@&#123;/webjars/bootstrap/4.0.0/css/bootstrap.css&#125;" rel="stylesheet"&gt; &lt;!-- Custom styles for this template --&gt; &lt;link href="asserts/css/signin.css" th:href="@&#123;/asserts/css/signin.css&#125;" rel="stylesheet"&gt; &lt;/head&gt; &lt;body class="text-center"&gt; &lt;form class="form-signin" action="dashboard.html"&gt; &lt;img class="mb-4" th:src="@&#123;/asserts/img/bootstrap-solid.svg&#125;" src="asserts/img/bootstrap-solid.svg" alt="" width="72" height="72"&gt; &lt;h1 class="h3 mb-3 font-weight-normal" th:text="#&#123;login.tip&#125;"&gt;Please sign in&lt;/h1&gt; &lt;label class="sr-only" th:text="#&#123;login.username&#125;"&gt;Username&lt;/label&gt; &lt;input type="text" class="form-control" placeholder="Username" th:placeholder="#&#123;login.username&#125;" required="" autofocus=""&gt; &lt;label class="sr-only" th:text="#&#123;login.password&#125;"&gt;Password&lt;/label&gt; &lt;input type="password" class="form-control" placeholder="Password" th:placeholder="#&#123;login.password&#125;" required=""&gt; &lt;div class="checkbox mb-3"&gt; &lt;label&gt; &lt;input type="checkbox" value="remember-me"/&gt; [[#&#123;login.remember&#125;]] &lt;/label&gt; &lt;/div&gt; &lt;button class="btn btn-lg btn-primary btn-block" type="submit" th:text="#&#123;login.btn&#125;"&gt;Sign in&lt;/button&gt; &lt;p class="mt-5 mb-3 text-muted"&gt;© 2017-2018&lt;/p&gt; &lt;a class="btn btn-sm"&gt;中文&lt;/a&gt; &lt;a class="btn btn-sm"&gt;English&lt;/a&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 效果：根据浏览器语言设置的信息切换了国际化； 原理： ​ 国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）； 12345678910111213 @Bean @ConditionalOnMissingBean @ConditionalOnProperty(prefix = "spring.mvc", name = "locale") public LocaleResolver localeResolver() &#123; if (this.mvcProperties .getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) &#123; return new FixedLocaleResolver(this.mvcProperties.getLocale()); &#125; AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver(); localeResolver.setDefaultLocale(this.mvcProperties.getLocale()); return localeResolver; &#125;默认的就是根据请求头带来的区域信息获取Locale进行国际化 4）、点击链接切换国际化 12345678910111213141516171819202122232425262728/** * 可以在连接上携带区域信息 */public class MyLocaleResolver implements LocaleResolver &#123; @Override public Locale resolveLocale(HttpServletRequest request) &#123; String l = request.getParameter("l"); Locale locale = Locale.getDefault(); if(!StringUtils.isEmpty(l))&#123; String[] split = l.split("_"); locale = new Locale(split[0],split[1]); &#125; return locale; &#125; @Override public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123; &#125;&#125; @Bean public LocaleResolver localeResolver()&#123; return new MyLocaleResolver(); &#125;&#125; 3）、登陆开发期间模板引擎页面修改以后，要实时生效 1）、禁用模板引擎的缓存 12# 禁用缓存spring.thymeleaf.cache=false 2）、页面修改完成以后ctrl+f9：重新编译； 登陆错误消息的显示 1&lt;p style="color: red" th:text="$&#123;msg&#125;" th:if="$&#123;not #strings.isEmpty(msg)&#125;"&gt;&lt;/p&gt; 4）、拦截器进行登陆检查拦截器 12345678910111213141516171819202122232425262728293031/** * 登陆检查， */public class LoginHandlerInterceptor implements HandlerInterceptor &#123; //目标方法执行之前 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; Object user = request.getSession().getAttribute("loginUser"); if(user == null)&#123; //未登陆，返回登陆页面 request.setAttribute("msg","没有权限请先登陆"); request.getRequestDispatcher("/index.html").forward(request,response); return false; &#125;else&#123; //已登陆，放行请求 return true; &#125; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 注册拦截器 1234567891011121314151617181920212223//所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/").setViewName("login"); registry.addViewController("/index.html").setViewName("login"); registry.addViewController("/main.html").setViewName("dashboard"); &#125; //注册拦截器 @Override public void addInterceptors(InterceptorRegistry registry) &#123; //super.addInterceptors(registry); //静态资源； *.css , *.js //SpringBoot已经做好了静态资源映射 registry.addInterceptor(new LoginHandlerInterceptor()).addPathPatterns("/**") .excludePathPatterns("/index.html","/","/user/login"); &#125; &#125;; return adapter; &#125; 5）、CRUD-员工列表实验要求： 1）、RestfulCRUD：CRUD满足Rest风格； URI： /资源名称/资源标识 HTTP请求方式区分对资源CRUD操作 普通CRUD（uri来区分操作） RestfulCRUD 查询 getEmp emp—GET 添加 addEmp?xxx emp—POST 修改 updateEmp?id=xxx&amp;xxx=xx emp/{id}—PUT 删除 deleteEmp?id=1 emp/{id}—DELETE 2）、实验的请求架构; 实验功能 请求URI 请求方式 查询所有员工 emps GET 查询某个员工(来到修改页面) emp/1 GET 来到添加页面 emp GET 添加员工 emp POST 来到修改页面（查出员工进行信息回显） emp/1 GET 修改员工 emp PUT 删除员工 emp/1 DELETE 3）、员工列表： thymeleaf公共页面元素抽取12345678910111213141、抽取公共片段&lt;div th:fragment="copy"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt;2、引入公共片段&lt;div th:insert="~&#123;footer :: copy&#125;"&gt;&lt;/div&gt;~&#123;templatename::selector&#125;：模板名::选择器~&#123;templatename::fragmentname&#125;:模板名::片段名3、默认效果：insert的公共片段在div标签中如果使用th:insert等属性进行引入，可以不用写~&#123;&#125;：行内写法可以加上：[[~&#123;&#125;]];[(~&#123;&#125;)]； 三种引入公共片段的th属性： th:insert：将公共片段整个插入到声明引入的元素中 th:replace：将声明引入的元素替换为公共片段 th:include：将被引入的片段的内容包含进这个标签中 1234567891011121314151617181920212223&lt;footer th:fragment="copy"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;引入方式&lt;div th:insert="footer :: copy"&gt;&lt;/div&gt;&lt;div th:replace="footer :: copy"&gt;&lt;/div&gt;&lt;div th:include="footer :: copy"&gt;&lt;/div&gt;效果&lt;div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt;&lt;/div&gt;&lt;footer&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;&lt;div&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt; 引入片段的时候传入参数： 123456789101112131415161718&lt;nav class="col-md-2 d-none d-md-block bg-light sidebar" id="sidebar"&gt; &lt;div class="sidebar-sticky"&gt; &lt;ul class="nav flex-column"&gt; &lt;li class="nav-item"&gt; &lt;a class="nav-link active" th:class="$&#123;activeUri=='main.html'?'nav-link active':'nav-link'&#125;" href="#" th:href="@&#123;/main.html&#125;"&gt; &lt;svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-home"&gt; &lt;path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"&gt;&lt;/path&gt; &lt;polyline points="9 22 9 12 15 12 15 22"&gt;&lt;/polyline&gt; &lt;/svg&gt; Dashboard &lt;span class="sr-only"&gt;(current)&lt;/span&gt; &lt;/a&gt; &lt;/li&gt;&lt;!--引入侧边栏;传入参数--&gt;&lt;div th:replace="commons/bar::#sidebar(activeUri='emps')"&gt;&lt;/div&gt; 6）、CRUD-员工添加添加页面 123456789101112131415161718192021222324252627282930313233343536&lt;form&gt; &lt;div class="form-group"&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input type="text" class="form-control" placeholder="zhangsan"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input type="email" class="form-control" placeholder="zhangsan@atguigu.com"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="1"&gt; &lt;label class="form-check-label"&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="0"&gt; &lt;label class="form-check-label"&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;department&lt;/label&gt; &lt;select class="form-control"&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input type="text" class="form-control" placeholder="zhangsan"&gt; &lt;/div&gt; &lt;button type="submit" class="btn btn-primary"&gt;添加&lt;/button&gt;&lt;/form&gt; 提交的数据格式不对：生日：日期； 2017-12-12；2017/12/12；2017.12.12； 日期的格式化；SpringMVC将页面提交的值需要转换为指定的类型; 2017-12-12—Date； 类型转换，格式化; 默认日期是按照/的方式； 7）、CRUD-员工修改修改添加二合一表单 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!--需要区分是员工修改还是添加；--&gt;&lt;form th:action="@&#123;/emp&#125;" method="post"&gt; &lt;!--发送put请求修改员工数据--&gt; &lt;!--1、SpringMVC中配置HiddenHttpMethodFilter;（SpringBoot自动配置好的）2、页面创建一个post表单3、创建一个input项，name="_method";值就是我们指定的请求方式--&gt; &lt;input type="hidden" name="_method" value="put" th:if="$&#123;emp!=null&#125;"/&gt; &lt;input type="hidden" name="id" th:if="$&#123;emp!=null&#125;" th:value="$&#123;emp.id&#125;"&gt; &lt;div class="form-group"&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input name="lastName" type="text" class="form-control" placeholder="zhangsan" th:value="$&#123;emp!=null&#125;?$&#123;emp.lastName&#125;"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input name="email" type="email" class="form-control" placeholder="zhangsan@atguigu.com" th:value="$&#123;emp!=null&#125;?$&#123;emp.email&#125;"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="1" th:checked="$&#123;emp!=null&#125;?$&#123;emp.gender==1&#125;"&gt; &lt;label class="form-check-label"&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="0" th:checked="$&#123;emp!=null&#125;?$&#123;emp.gender==0&#125;"&gt; &lt;label class="form-check-label"&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;department&lt;/label&gt; &lt;!--提交的是部门的id--&gt; &lt;select class="form-control" name="department.id"&gt; &lt;option th:selected="$&#123;emp!=null&#125;?$&#123;dept.id == emp.department.id&#125;" th:value="$&#123;dept.id&#125;" th:each="dept:$&#123;depts&#125;" th:text="$&#123;dept.departmentName&#125;"&gt;1&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input name="birth" type="text" class="form-control" placeholder="zhangsan" th:value="$&#123;emp!=null&#125;?$&#123;#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')&#125;"&gt; &lt;/div&gt; &lt;button type="submit" class="btn btn-primary" th:text="$&#123;emp!=null&#125;?'修改':'添加'"&gt;添加&lt;/button&gt;&lt;/form&gt; 8）、CRUD-员工删除123456789101112131415161718192021&lt;tr th:each="emp:$&#123;emps&#125;"&gt; &lt;td th:text="$&#123;emp.id&#125;"&gt;&lt;/td&gt; &lt;td&gt;[[$&#123;emp.lastName&#125;]]&lt;/td&gt; &lt;td th:text="$&#123;emp.email&#125;"&gt;&lt;/td&gt; &lt;td th:text="$&#123;emp.gender&#125;==0?'女':'男'"&gt;&lt;/td&gt; &lt;td th:text="$&#123;emp.department.departmentName&#125;"&gt;&lt;/td&gt; &lt;td th:text="$&#123;#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')&#125;"&gt;&lt;/td&gt; &lt;td&gt; &lt;a class="btn btn-sm btn-primary" th:href="@&#123;/emp/&#125;+$&#123;emp.id&#125;"&gt;编辑&lt;/a&gt; &lt;button th:attr="del_uri=@&#123;/emp/&#125;+$&#123;emp.id&#125;" class="btn btn-sm btn-danger deleteBtn"&gt;删除&lt;/button&gt; &lt;/td&gt;&lt;/tr&gt;&lt;script&gt; $(".deleteBtn").click(function()&#123; //删除当前员工的 $("#deleteEmpForm").attr("action",$(this).attr("del_uri")).submit(); return false; &#125;);&lt;/script&gt; 7、错误处理机制1）、SpringBoot默认的错误处理机制默认效果： ​ 1）、浏览器，返回一个默认的错误页面 浏览器发送请求的请求头： ​ 2）、如果是其他客户端，默认响应一个json数据 ​ 原理： ​ 可以参照ErrorMvcAutoConfiguration；错误处理的自动配置； 给容器中添加了以下组件​ 1、DefaultErrorAttributes： 1234567891011帮我们在页面共享信息；@Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;(); errorAttributes.put("timestamp", new Date()); addStatus(errorAttributes, requestAttributes); addErrorDetails(errorAttributes, requestAttributes, includeStackTrace); addPath(errorAttributes, requestAttributes); return errorAttributes; &#125; ​ 2、BasicErrorController：处理默认/error请求 12345678910111213141516171819202122232425@Controller@RequestMapping("$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;")public class BasicErrorController extends AbstractErrorController &#123; @RequestMapping(produces = "text/html")//产生html类型的数据；浏览器发送的请求来到这个方法处理 public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) &#123; HttpStatus status = getStatus(request); Map&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); //去哪个页面作为错误页面；包含页面地址和页面内容 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView == null ? new ModelAndView("error", model) : modelAndView); &#125; @RequestMapping @ResponseBody //产生json数据，其他客户端来到这个方法处理； public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) &#123; Map&lt;String, Object&gt; body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); return new ResponseEntity&lt;Map&lt;String, Object&gt;&gt;(body, status); &#125; ​ 3、ErrorPageCustomizer： 12@Value("$&#123;error.path:/error&#125;")private String path = "/error"; 系统出现错误以后来到error请求进行处理；（web.xml注册的错误页面规则） ​ 4、DefaultErrorViewResolver： 123456789101112131415161718192021222324@Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) &#123; ModelAndView modelAndView = resolve(String.valueOf(status), model); if (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) &#123; modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); &#125; return modelAndView; &#125; private ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) &#123; //默认SpringBoot可以去找到一个页面？ error/404 String errorViewName = "error/" + viewName; //模板引擎可以解析这个页面地址就用模板引擎解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders .getProvider(errorViewName, this.applicationContext); if (provider != null) &#123; //模板引擎可用的情况下返回到errorViewName指定的视图地址 return new ModelAndView(errorViewName, model); &#125; //模板引擎不可用，就在静态资源文件夹下找errorViewName对应的页面 error/404.html return resolveResource(errorViewName, model); &#125; ​ 步骤： ​ 一但系统出现4xx或者5xx之类的错误；ErrorPageCustomizer就会生效（定制错误的响应规则）；就会来到/error请求；就会被BasicErrorController处理； ​ 1）响应页面；去哪个页面是由DefaultErrorViewResolver解析得到的； 1234567891011protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status, Map&lt;String, Object&gt; model) &#123; //所有的ErrorViewResolver得到ModelAndView for (ErrorViewResolver resolver : this.errorViewResolvers) &#123; ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) &#123; return modelAndView; &#125; &#125; return null;&#125; 2）、如果定制错误响应：1）、如何定制错误的页面；​ 1）、有模板引擎的情况下；error/状态码; 【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的 error文件夹下】，发生此状态码的错误就会来到 对应的页面； ​ 我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）； ​ 页面能获取的信息； ​ timestamp：时间戳 ​ status：状态码 ​ error：错误提示 ​ exception：异常对象 ​ message：异常消息 ​ errors：JSR303数据校验的错误都在这里 ​ 2）、没有模板引擎（模板引擎找不到这个错误页面），静态资源文件夹下找； ​ 3）、以上都没有错误页面，就是默认来到SpringBoot默认的错误提示页面； 2）、如何定制错误的json数据；​ 1）、自定义异常处理&amp;返回定制json数据； 12345678910111213@ControllerAdvicepublic class MyExceptionHandler &#123; @ResponseBody @ExceptionHandler(UserNotExistException.class) public Map&lt;String,Object&gt; handleException(Exception e)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put("code","user.notexist"); map.put("message",e.getMessage()); return map; &#125;&#125;//没有自适应效果... ​ 2）、转发到/error进行自适应响应效果处理 1234567891011121314@ExceptionHandler(UserNotExistException.class) public String handleException(Exception e, HttpServletRequest request)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //传入我们自己的错误状态码 4xx 5xx，否则就不会进入定制错误页面的解析流程 /** * Integer statusCode = (Integer) request .getAttribute("javax.servlet.error.status_code"); */ request.setAttribute("javax.servlet.error.status_code",500); map.put("code","user.notexist"); map.put("message",e.getMessage()); //转发到/error return "forward:/error"; &#125; 3）、将我们的定制数据携带出去；出现错误以后，会来到/error请求，会被BasicErrorController处理，响应出去可以获取的数据是由getErrorAttributes得到的（是AbstractErrorController（ErrorController）规定的方法）； ​ 1、完全来编写一个ErrorController的实现类【或者是编写AbstractErrorController的子类】，放在容器中； ​ 2、页面上能用的数据，或者是json返回能用的数据都是通过errorAttributes.getErrorAttributes得到； ​ 容器中DefaultErrorAttributes.getErrorAttributes()；默认进行数据处理的； 自定义ErrorAttributes 1234567891011//给容器中加入我们自己定义的ErrorAttributes@Componentpublic class MyErrorAttributes extends DefaultErrorAttributes &#123; @Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; map = super.getErrorAttributes(requestAttributes, includeStackTrace); map.put("company","atguigu"); return map; &#125;&#125; 最终的效果：响应是自适应的，可以通过定制ErrorAttributes改变需要返回的内容， 8、配置嵌入式Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器； 问题？ 1）、如何定制和修改Servlet容器的相关配置；1、修改和server有关的配置（ServerProperties【也是EmbeddedServletContainerCustomizer】）； 123456789server.port=8081server.context-path=/crudserver.tomcat.uri-encoding=UTF-8//通用的Servlet容器设置server.xxx//Tomcat的设置server.tomcat.xxx 2、编写一个EmbeddedServletContainerCustomizer：嵌入式的Servlet容器的定制器；来修改Servlet容器的配置 1234567891011@Bean //一定要将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer()&#123; return new EmbeddedServletContainerCustomizer() &#123; //定制嵌入式的Servlet容器相关的规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.setPort(8083); &#125; &#125;;&#125; 2）、注册Servlet三大组件【Servlet、Filter、Listener】由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动SpringBoot的web应用，没有web.xml文件。 注册三大组件用以下方式 ServletRegistrationBean 123456//注册三大组件@Beanpublic ServletRegistrationBean myServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),"/myServlet"); return registrationBean;&#125; FilterRegistrationBean 1234567@Beanpublic FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new MyFilter()); registrationBean.setUrlPatterns(Arrays.asList("/hello","/myServlet")); return registrationBean;&#125; ServletListenerRegistrationBean 12345@Beanpublic ServletListenerRegistrationBean myListener()&#123; ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener()); return registrationBean;&#125; SpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器；DIspatcherServlet； DispatcherServletAutoConfiguration中： 1234567891011121314151617@Bean(name = DEFAULT_DISPATCHER_SERVLET_REGISTRATION_BEAN_NAME)@ConditionalOnBean(value = DispatcherServlet.class, name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)public ServletRegistrationBean dispatcherServletRegistration( DispatcherServlet dispatcherServlet) &#123; ServletRegistrationBean registration = new ServletRegistrationBean( dispatcherServlet, this.serverProperties.getServletMapping()); //默认拦截： / 所有请求；包静态资源，但是不拦截jsp请求； /*会拦截jsp //可以通过server.servletPath来修改SpringMVC前端控制器默认拦截的请求路径 registration.setName(DEFAULT_DISPATCHER_SERVLET_BEAN_NAME); registration.setLoadOnStartup( this.webMvcProperties.getServlet().getLoadOnStartup()); if (this.multipartConfig != null) &#123; registration.setMultipartConfig(this.multipartConfig); &#125; return registration;&#125; 2）、SpringBoot能不能支持其他的Servlet容器； 3）、替换为其他嵌入式Servlet容器 默认支持： Tomcat（默认使用） 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; 引入web模块默认就是使用嵌入式的Tomcat作为Servlet容器；&lt;/dependency&gt; Jetty 1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; Undertow 1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 4）、嵌入式Servlet容器自动配置原理；EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)//导入BeanPostProcessorsRegistrar：Spring注解版；给容器中导入一些组件//导入了EmbeddedServletContainerCustomizerBeanPostProcessor：//后置处理器：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作public class EmbeddedServletContainerAutoConfiguration &#123; @Configuration @ConditionalOnClass(&#123; Servlet.class, Tomcat.class &#125;)//判断当前是否引入了Tomcat依赖； @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)//判断当前容器没有用户自己定义EmbeddedServletContainerFactory：嵌入式的Servlet容器工厂；作用：创建嵌入式的Servlet容器 public static class EmbeddedTomcat &#123; @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123; return new TomcatEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class, WebAppContext.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty &#123; @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() &#123; return new JettyEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow &#123; @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() &#123; return new UndertowEmbeddedServletContainerFactory(); &#125; &#125; 1）、EmbeddedServletContainerFactory（嵌入式Servlet容器工厂） 1234567public interface EmbeddedServletContainerFactory &#123; //获取嵌入式的Servlet容器 EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers);&#125; 2）、EmbeddedServletContainer：（嵌入式的Servlet容器） 3）、以TomcatEmbeddedServletContainerFactory为例 123456789101112131415161718192021222324@Overridepublic EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; //创建一个Tomcat Tomcat tomcat = new Tomcat(); //配置Tomcat的基本环节 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir("tomcat")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); //将配置好的Tomcat传入进去，返回一个EmbeddedServletContainer；并且启动Tomcat服务器 return getTomcatEmbeddedServletContainer(tomcat);&#125; 4）、我们对嵌入式容器的配置修改是怎么生效？ 1ServerProperties、EmbeddedServletContainerCustomizer EmbeddedServletContainerCustomizer：定制器帮我们修改了Servlet容器的配置？ 怎么修改的原理？ 5）、容器中导入了EmbeddedServletContainerCustomizerBeanPostProcessor 12345678910111213141516171819202122232425262728293031323334353637//初始化之前@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; //如果当前初始化的是一个ConfigurableEmbeddedServletContainer类型的组件 if (bean instanceof ConfigurableEmbeddedServletContainer) &#123; // postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean); &#125; return bean;&#125;private void postProcessBeforeInitialization( ConfigurableEmbeddedServletContainer bean) &#123; //获取所有的定制器，调用每一个定制器的customize方法来给Servlet容器进行属性赋值； for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) &#123; customizer.customize(bean); &#125;&#125;private Collection&lt;EmbeddedServletContainerCustomizer&gt; getCustomizers() &#123; if (this.customizers == null) &#123; // Look up does not include the parent context this.customizers = new ArrayList&lt;EmbeddedServletContainerCustomizer&gt;( this.beanFactory //从容器中获取所有这葛类型的组件：EmbeddedServletContainerCustomizer //定制Servlet容器，给容器中可以添加一个EmbeddedServletContainerCustomizer类型的组件 .getBeansOfType(EmbeddedServletContainerCustomizer.class, false, false) .values()); Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); &#125; return this.customizers;&#125;ServerProperties也是定制器 步骤： 1）、SpringBoot根据导入的依赖情况，给容器中添加相应的EmbeddedServletContainerFactory【TomcatEmbeddedServletContainerFactory】 2）、容器中某个组件要创建对象就会惊动后置处理器；EmbeddedServletContainerCustomizerBeanPostProcessor； 只要是嵌入式的Servlet容器工厂，后置处理器就工作； 3）、后置处理器，从容器中获取所有的EmbeddedServletContainerCustomizer，调用定制器的定制方法 ###5）、嵌入式Servlet容器启动原理； 什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat； 获取嵌入式的Servlet容器工厂： 1）、SpringBoot应用启动运行run方法 2）、refreshContext(context);SpringBoot刷新IOC容器【创建IOC容器对象，并初始化容器，创建容器中的每一个组件】；如果是web应用创建AnnotationConfigEmbeddedWebApplicationContext，否则：AnnotationConfigApplicationContext 3）、refresh(context);刷新刚才创建好的ioc容器； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 4）、 onRefresh(); web的ioc容器重写了onRefresh方法 5）、webioc容器会创建嵌入式的Servlet容器；createEmbeddedServletContainer(); 6）、获取嵌入式的Servlet容器工厂： EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); ​ 从ioc容器中获取EmbeddedServletContainerFactory 组件；TomcatEmbeddedServletContainerFactory创建对象，后置处理器一看是这个对象，就获取所有的定制器来先定制Servlet容器的相关配置； 7）、使用容器工厂获取嵌入式的Servlet容器：this.embeddedServletContainer = containerFactory .getEmbeddedServletContainer(getSelfInitializer()); 8）、嵌入式的Servlet容器创建对象并启动Servlet容器； 先启动嵌入式的Servlet容器，再将ioc容器中剩下没有创建出的对象获取出来； ==IOC容器启动创建嵌入式的Servlet容器== 9、使用外置的Servlet容器嵌入式Servlet容器：应用打成可执行的jar ​ 优点：简单、便携； ​ 缺点：默认不支持JSP、优化定制比较复杂（使用定制器【ServerProperties、自定义EmbeddedServletContainerCustomizer】，自己编写嵌入式Servlet容器的创建工厂【EmbeddedServletContainerFactory】）； 外置的Servlet容器：外面安装Tomcat—应用war包的方式打包； 步骤1）、必须创建一个war项目；（利用idea创建好目录结构） 2）、将嵌入式的Tomcat指定为provided； 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3）、必须编写一个SpringBootServletInitializer的子类，并调用configure方法 123456789public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; //传入SpringBoot应用的主程序 return application.sources(SpringBoot04WebJspApplication.class); &#125;&#125; 4）、启动服务器就可以使用； 原理jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器； war包：启动服务器，服务器启动SpringBoot应用【SpringBootServletInitializer】，启动ioc容器； servlet3.0（Spring注解版）： 8.2.4 Shared libraries / runtimes pluggability： 规则： ​ 1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面ServletContainerInitializer实例： ​ 2）、ServletContainerInitializer的实现放在jar包的META-INF/services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名 ​ 3）、还可以使用@HandlesTypes，在应用启动的时候加载我们感兴趣的类； 流程： 1）、启动Tomcat 2）、org\springframework\spring-web\4.3.14.RELEASE\spring-web-4.3.14.RELEASE.jar!\META-INF\services\javax.servlet.ServletContainerInitializer： Spring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer 3）、SpringServletContainerInitializer将@HandlesTypes(WebApplicationInitializer.class)标注的所有这个类型的类都传入到onStartup方法的Set&lt;Class&lt;?&gt;&gt;；为这些WebApplicationInitializer类型的类创建实例； 4）、每一个WebApplicationInitializer都调用自己的onStartup； 5）、相当于我们的SpringBootServletInitializer的类会被创建对象，并执行onStartup方法 6）、SpringBootServletInitializer实例执行onStartup的时候会createRootApplicationContext；创建容器 1234567891011121314151617181920212223242526272829303132333435363738protected WebApplicationContext createRootApplicationContext( ServletContext servletContext) &#123; //1、创建SpringApplicationBuilder SpringApplicationBuilder builder = createSpringApplicationBuilder(); StandardServletEnvironment environment = new StandardServletEnvironment(); environment.initPropertySources(servletContext, null); builder.environment(environment); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; this.logger.info("Root context already created (using as parent)."); servletContext.setAttribute( WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers( new ServletContextApplicationContextInitializer(servletContext)); builder.contextClass(AnnotationConfigEmbeddedWebApplicationContext.class); //调用configure方法，子类重写了这个方法，将SpringBoot的主程序类传入了进来 builder = configure(builder); //使用builder创建一个Spring应用 SpringApplication application = builder.build(); if (application.getSources().isEmpty() &amp;&amp; AnnotationUtils .findAnnotation(getClass(), Configuration.class) != null) &#123; application.getSources().add(getClass()); &#125; Assert.state(!application.getSources().isEmpty(), "No SpringApplication sources have been defined. Either override the " + "configure method or add an @Configuration annotation"); // Ensure error pages are registered if (this.registerErrorPageFilter) &#123; application.getSources().add(ErrorPageFilterConfiguration.class); &#125; //启动Spring应用 return run(application);&#125; 7）、Spring的应用就启动并且创建IOC容器 1234567891011121314151617181920212223242526272829303132333435public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新IOC容器 refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; ==启动Servlet容器，再启动SpringBoot应用== 五、Docker1、简介Docker是一个开源的应用容器引擎；是一个轻量级容器技术； Docker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像； 运行中的这个镜像称为容器，容器启动是非常快速的。 2、核心概念docker主机(Host)：安装了Docker程序的机器（Docker直接安装在操作系统之上）； docker客户端(Client)：连接docker主机进行操作； docker仓库(Registry)：用来保存各种打包好的软件镜像； docker镜像(Images)：软件打包好的镜像；放在docker仓库中； docker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用 使用Docker的步骤： 1）、安装Docker 2）、去Docker仓库找到这个软件对应的镜像； 3）、使用Docker运行这个镜像，这个镜像就会生成一个Docker容器； 4）、对容器的启动停止就是对软件的启动停止； 3、安装Docker1）、安装linux虚拟机​ 1）、VMWare、VirtualBox（安装）； ​ 2）、导入虚拟机文件centos7-atguigu.ova； ​ 3）、双击启动linux虚拟机;使用 root/ 123456登陆 ​ 4）、使用客户端连接linux服务器进行命令操作； ​ 5）、设置虚拟机网络； ​ 桥接网络===选好网卡====接入网线； ​ 6）、设置好网络以后使用命令重启虚拟机的网络 1service network restart ​ 7）、查看linux的ip地址 1ip addr ​ 8）、使用客户端连接linux； 2）、在linux虚拟机上安装docker步骤： 12345678910111213141、检查内核版本，必须是3.10及以上uname -r2、安装dockeryum install docker3、输入y确认安装4、启动docker[root@localhost ~]# systemctl start docker[root@localhost ~]# docker -vDocker version 1.12.6, build 3e8e77d/1.12.65、开机启动docker[root@localhost ~]# systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.6、停止dockersystemctl stop docker 4、Docker常用命令&amp;操作1）、镜像操作 操作 命令 说明 检索 docker search 关键字 eg：docker search redis 我们经常去docker hub上检索镜像的详细信息，如镜像的TAG。 拉取 docker pull 镜像名:tag :tag是可选的，tag表示标签，多为软件的版本，默认是latest 列表 docker images 查看所有本地镜像 删除 docker rmi image-id 删除指定的本地镜像 https://hub.docker.com/ 2）、容器操作软件镜像（QQ安装程序）—-运行镜像—-产生一个容器（正在运行的软件，运行的QQ）； 步骤： 1234567891011121314151617181920212223242526272829301、搜索镜像[root@localhost ~]# docker search tomcat2、拉取镜像[root@localhost ~]# docker pull tomcat3、根据镜像启动容器docker run --name mytomcat -d tomcat:latest4、docker ps 查看运行中的容器5、 停止运行中的容器docker stop 容器的id6、查看所有的容器docker ps -a7、启动容器docker start 容器id8、删除一个容器 docker rm 容器id9、启动一个做了端口映射的tomcat[root@localhost ~]# docker run -d -p 8888:8080 tomcat-d：后台运行-p: 将主机的端口映射到容器的一个端口 主机端口:容器内部的端口10、为了演示简单关闭了linux的防火墙service firewalld status ；查看防火墙状态service firewalld stop：关闭防火墙11、查看容器的日志docker logs container-name/container-id更多命令参看https://docs.docker.com/engine/reference/commandline/docker/可以参考每一个镜像的文档 3）、安装MySQL示例1docker pull mysql 错误的启动 1234567891011121314151617[root@localhost ~]# docker run --name mysql01 -d mysql42f09819908bb72dd99ae19e792e0a5d03c48638421fa64cce5f8ba0f40f5846mysql退出了[root@localhost ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES42f09819908b mysql "docker-entrypoint.sh" 34 seconds ago Exited (1) 33 seconds ago mysql01538bde63e500 tomcat "catalina.sh run" About an hour ago Exited (143) About an hour ago compassionate_goldstinec4f1ac60b3fc tomcat "catalina.sh run" About an hour ago Exited (143) About an hour ago lonely_fermi81ec743a5271 tomcat "catalina.sh run" About an hour ago Exited (143) About an hour ago sick_ramanujan//错误日志[root@localhost ~]# docker logs 42f09819908berror: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD；这个三个参数必须指定一个 正确的启动 12345[root@localhost ~]# docker run --name mysql01 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlb874c56bec49fb43024b3805ab51e9097da779f2f572c22c695305dedd684c5f[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb874c56bec49 mysql "docker-entrypoint.sh" 4 seconds ago Up 3 seconds 3306/tcp mysql01 做了端口映射 12345[root@localhost ~]# docker run -p 3306:3306 --name mysql02 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlad10e4bc5c6a0f61cbad43898de71d366117d120e39db651844c0e73863b9434[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESad10e4bc5c6a mysql "docker-entrypoint.sh" 4 seconds ago Up 2 seconds 0.0.0.0:3306-&gt;3306/tcp mysql02 几个其他的高级操作 123456docker run --name mysql03 -v /conf/mysql:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag把主机的/conf/mysql文件夹挂载到 mysqldocker容器的/etc/mysql/conf.d文件夹里面改mysql的配置文件就只需要把mysql配置文件放在自定义的文件夹下（/conf/mysql）docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci指定mysql的一些配置参数 六、SpringBoot与数据访问1、JDBC123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; 123456spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.15.22:3306/jdbc driver-class-name: com.mysql.jdbc.Driver 效果： ​ 默认是用org.apache.tomcat.jdbc.pool.DataSource作为数据源； ​ 数据源的相关配置都在DataSourceProperties里面； 自动配置原理： org.springframework.boot.autoconfigure.jdbc： 1、参考DataSourceConfiguration，根据配置创建数据源，默认使用Tomcat连接池；可以使用spring.datasource.type指定自定义的数据源类型； 2、SpringBoot默认可以支持； 1org.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource、 3、自定义数据源类型 1234567891011121314/** * Generic DataSource configuration. */@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(name = "spring.datasource.type")static class Generic &#123; @Bean public DataSource dataSource(DataSourceProperties properties) &#123; //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); &#125;&#125; 4、DataSourceInitializer：ApplicationListener； ​ 作用： ​ 1）、runSchemaScripts();运行建表语句； ​ 2）、runDataScripts();运行插入数据的sql语句； 默认只需要将文件命名为： 123456schema-*.sql、data-*.sql默认规则：schema.sql，schema-all.sql；可以使用 schema: - classpath:department.sql 指定位置 5、操作数据库：自动配置了JdbcTemplate操作数据库 2、整合Druid数据源12345678910111213141516171819202122232425262728293031323334353637383940414243导入druid数据源@Configurationpublic class DruidConfig &#123; @ConfigurationProperties(prefix = "spring.datasource") @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), "/druid/*"); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put("loginUsername","admin"); initParams.put("loginPassword","123456"); initParams.put("allow","");//默认就是允许所有访问 initParams.put("deny","192.168.15.21"); bean.setInitParameters(initParams); return bean; &#125; //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put("exclusions","*.js,*.css,/druid/*"); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList("/*")); return bean; &#125;&#125; 3、整合MyBatis12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt; 步骤： ​ 1）、配置数据源相关属性（见上一节Druid） ​ 2）、给数据库建表 ​ 3）、创建JavaBean 4）、注解版1234567891011121314151617//指定这是一个操作数据库的mapper@Mapperpublic interface DepartmentMapper &#123; @Select("select * from department where id=#&#123;id&#125;") public Department getDeptById(Integer id); @Delete("delete from department where id=#&#123;id&#125;") public int deleteDeptById(Integer id); @Options(useGeneratedKeys = true,keyProperty = "id") @Insert("insert into department(departmentName) values(#&#123;departmentName&#125;)") public int insertDept(Department department); @Update("update department set departmentName=#&#123;departmentName&#125; where id=#&#123;id&#125;") public int updateDept(Department department);&#125; 问题： 自定义MyBatis的配置规则；给容器中添加一个ConfigurationCustomizer； 1234567891011121314@org.springframework.context.annotation.Configurationpublic class MyBatisConfig &#123; @Bean public ConfigurationCustomizer configurationCustomizer()&#123; return new ConfigurationCustomizer()&#123; @Override public void customize(Configuration configuration) &#123; configuration.setMapUnderscoreToCamelCase(true); &#125; &#125;; &#125;&#125; 123456789使用MapperScan批量扫描所有的Mapper接口；@MapperScan(value = "com.atguigu.springboot.mapper")@SpringBootApplicationpublic class SpringBoot06DataMybatisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBoot06DataMybatisApplication.class, args); &#125;&#125; 5）、配置文件版123mybatis: config-location: classpath:mybatis/mybatis-config.xml 指定全局配置文件的位置 mapper-locations: classpath:mybatis/mapper/*.xml 指定sql映射文件的位置 更多使用参照 http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/ 4、整合SpringData JPA1）、SpringData简介 2）、整合SpringData JPAJPA:ORM（Object Relational Mapping）； 1）、编写一个实体类（bean）和数据表进行映射，并且配置好映射关系； 12345678910111213//使用JPA注解配置映射关系@Entity //告诉JPA这是一个实体类（和数据表映射的类）@Table(name = "tbl_user") //@Table来指定和哪个数据表对应;如果省略默认表名就是user；public class User &#123; @Id //这是一个主键 @GeneratedValue(strategy = GenerationType.IDENTITY)//自增主键 private Integer id; @Column(name = "last_name",length = 50) //这是和数据表对应的一个列 private String lastName; @Column //省略默认列名就是属性名 private String email; 2）、编写一个Dao接口来操作实体类对应的数据表（Repository） 123//继承JpaRepository来完成对数据库的操作public interface UserRepository extends JpaRepository&lt;User,Integer&gt; &#123;&#125; 3）、基本的配置JpaProperties 1234567spring: jpa: hibernate:# 更新或者创建数据表结构 ddl-auto: update# 控制台显示SQL show-sql: true 七、启动配置原理几个重要的事件回调机制 配置在META-INF/spring.factories ApplicationContextInitializer SpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner CommandLineRunner 启动流程： 1、创建SpringApplication对象12345678910111213141516initialize(sources);private void initialize(Object[] sources) &#123; //保存主配置类 if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判断当前是否一个web应用 this.webEnvironment = deduceWebEnvironment(); //从类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //从类路径下找到ETA-INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 2、运行run方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //获取SpringApplicationRunListeners；从类路径下META-INF/spring.factories SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的获取SpringApplicationRunListener.starting()方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成 Banner printedBanner = printBanner(environment); //创建ApplicationContext；决定创建web的ioc还是普通的ioc context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //准备上下文环境;将environment保存到ioc中；而且applyInitializers()； //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 //回调所有的SpringApplicationRunListener的contextPrepared()； // prepareContext(context, environment, listeners, applicationArguments, printedBanner); //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； //s刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat）；Spring注解版 //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置） refreshContext(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调 //ApplicationRunner先回调，CommandLineRunner再回调 afterRefresh(context, applicationArguments); //所有的SpringApplicationRunListener回调finished方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; //整个SpringBoot应用启动完成以后返回启动的ioc容器； return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 3、事件监听机制配置在META-INF/spring.factories ApplicationContextInitializer 123456public class HelloApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println("ApplicationContextInitializer...initialize..."+applicationContext); &#125;&#125; SpringApplicationRunListener 123456789101112131415161718192021222324252627282930313233public class HelloSpringApplicationRunListener implements SpringApplicationRunListener &#123; //必须有的构造器 public HelloSpringApplicationRunListener(SpringApplication application, String[] args)&#123; &#125; @Override public void starting() &#123; System.out.println("SpringApplicationRunListener...starting..."); &#125; @Override public void environmentPrepared(ConfigurableEnvironment environment) &#123; Object o = environment.getSystemProperties().get("os.name"); System.out.println("SpringApplicationRunListener...environmentPrepared.."+o); &#125; @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; System.out.println("SpringApplicationRunListener...contextPrepared..."); &#125; @Override public void contextLoaded(ConfigurableApplicationContext context) &#123; System.out.println("SpringApplicationRunListener...contextLoaded..."); &#125; @Override public void finished(ConfigurableApplicationContext context, Throwable exception) &#123; System.out.println("SpringApplicationRunListener...finished..."); &#125;&#125; 配置（META-INF/spring.factories） 12345org.springframework.context.ApplicationContextInitializer=\com.atguigu.springboot.listener.HelloApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=\com.atguigu.springboot.listener.HelloSpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner 1234567@Componentpublic class HelloApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println("ApplicationRunner...run...."); &#125;&#125; CommandLineRunner 1234567@Componentpublic class HelloCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println("CommandLineRunner...run..."+ Arrays.asList(args)); &#125;&#125; 八、自定义starterstarter： ​ 1、这个场景需要使用到的依赖是什么？ ​ 2、如何编写自动配置 12345678910111213@Configuration //指定这个类是一个配置类@ConditionalOnXXX //在指定条件成立的情况下自动配置类生效@AutoConfigureAfter //指定自动配置类的顺序@Bean //给容器中添加组件@ConfigurationPropertie结合相关xxxProperties类来绑定相关的配置@EnableConfigurationProperties //让xxxProperties生效加入到容器中自动配置类要能加载将需要启动就加载的自动配置类，配置在META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\ ​ 3、模式： 启动器只用来做依赖导入； 专门来写一个自动配置模块； 启动器依赖自动配置；别人只需要引入启动器（starter） mybatis-spring-boot-starter；自定义启动器名-spring-boot-starter 步骤： 1）、启动器模块 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--启动器--&gt; &lt;dependencies&gt; &lt;!--引入自动配置模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2）、自动配置模块 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.10.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--引入spring-boot-starter；所有starter的基本配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 1234567891011121314151617181920212223242526package com.atguigu.starter;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = "atguigu.hello")public class HelloProperties &#123; private String prefix; private String suffix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public String getSuffix() &#123; return suffix; &#125; public void setSuffix(String suffix) &#123; this.suffix = suffix; &#125;&#125; 123456789101112131415161718package com.atguigu.starter;public class HelloService &#123; HelloProperties helloProperties; public HelloProperties getHelloProperties() &#123; return helloProperties; &#125; public void setHelloProperties(HelloProperties helloProperties) &#123; this.helloProperties = helloProperties; &#125; public String sayHellAtguigu(String name)&#123; return helloProperties.getPrefix()+"-" +name + helloProperties.getSuffix(); &#125;&#125; 12345678910111213141516171819202122package com.atguigu.starter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration@ConditionalOnWebApplication //web应用才生效@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration &#123; @Autowired HelloProperties helloProperties; @Bean public HelloService helloService()&#123; HelloService service = new HelloService(); service.setHelloProperties(helloProperties); return service; &#125;&#125; 更多SpringBoot整合示例https://github.com/spring-projects/spring-boot/tree/master/spring-boot-samples]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>原理</tag>
        <tag>框架</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro浅析：原理篇]]></title>
    <url>%2Fshiro-principle%2F</url>
    <content type="text"><![CDATA[什么是Shiro Apache Shiro™是一个功能强大且易于使用的Java安全框架，它执行身份验证，授权，加密和会话管理。使用Shiro易于理解的API，您可以快速轻松地保护任何应用程序-从最小的移动应用程序到最大的Web和企业应用程序。 Shiro能做什么 4大核心部分 Authentication：身份验证，简称“登录”。 Authorization：授权，给用户分配角色或者权限资源，判断用户是否有权限做某事。 Session Management：用户session管理器，可以让CS程序也使用session来控制权限。 Cryptography：把JDK中复杂的密码加密方式进行封装。 提供很多扩展 Web Support：主要针对web应用提供一些常用功能。 Caching：缓存可以使应用程序运行更有效率。 Concurrency：多线程相关功能。 Testing：帮助我们进行测试相关功能 Run As：一个允许用户假设为另一个用户身份（如果允许）的功能，有时候在管理脚本很有用。 Remember Me：记住用户身份，提供类似购物车功能。 Logout：退出。 对JDK中复杂的密码加密方式进行封装。 Shiro流程 Application Code：应用程序代码，由开发人员负责开发的。 Subject：框架提供的接口，是与程序进行交互的对象，可以是人也可以是服务或者其他第三方应用等， 通常就理解为用户。所有Subject实例都必须绑定到一个SecurityManager上。我们与一个 Subject交互，运行时shiro会自动转化为与 SecurityManager交互的特定subject的交互。 SecurityManager：框架提供的接口，是 Shiro的核心， 代表安全管理器对象。初始化时协调各个模块运行。然而，一旦 SecurityManager协调完毕，SecurityManager 会被单独留下，我们只需要去操作Subject即可，无需操作SecurityManager。 但是我们得知道，当我们正与一个 Subject 进行交互时，实质上是 SecurityManager 在处理 Subject 安全操作。 Realm：可以由开发人员编写，框架也提供一些。Realms在 Shiro中作为应用程序和安全数据之间的“桥梁”或“连接器”。 他获取安全数据来判断subject是否能够登录，subject拥有什么权限。他有点类似DAO。在配置realms时，需要至少一个realm。 而且Shiro提供了一些常用的 Realms来连接数据源，如LDAP数据源的JndiLdapRealm，JDBC数据源的JdbcRealm，ini文件数据源的IniRealm，properties文件数据源的PropertiesRealm，等等。我们也可以插入自己的 Realm实现来代表自定义的数据源。 像其他组件一样，Realms也是由SecurityManager控制。 Shiro架构 图中的subject就是请求主体。subject请求都交给Security Manager进行处理。Security Manager是暴露给主体请求的唯一一个接口。在Security Manager 中又有Authenticator、Authorized、SessionManager、Realm、SessionDAO和Cache Manager模块。 Subject(org.apache.shiro.subject.Subject) 主体 Subject即主体，外部应用与 subject进行交互，subject记录了当前操作用户，将用户的理解为当前操作的主体。Subject在shiro中是一个接口，接口中定义了很多认证授权的方法，外部程序通过subject进行认证授权，而subject通过Security Manager安全管理器进行认证授权。 SecurityManager(org.apache.shiro.mgt.SecurityManager)Shiro的核心 Sercurity Manager即安全管理器，对所有的subject进行管理，它是shiro的核心，负责对所有的subject进行安全管理。通过Security Manager可以完成对shiro的认证、授权等，但是实质上Security Manager是通过Authenticator进行认证、通过Authorizer进行授权、通过sessionManager进行会话管理等。SecurityManager是一个接口，继承了Authenticator、Authorizer、SessionManager这三个接口。 Authenticator(org.apache.shiro.authc.Authenticator)主体认证 Authenticator即认证器，对subject身份进行认证，Authenticator是一个抽象类，该类的对象知道如何为网络连接获取身份验证。应用程序可以重写子类中的一些方法进行认证实现。 Authorizer(org.apache.shiro.authz.Authorizer)授权器 是一种最终判定用户是否被允许做某事的机制。与 Authenticator相似，Authorizer也知道如何协调多个后台数据源来访问角色权限信息。 Realms(org.apache.shiro.realm.Realm)安全实体的数据源Realm即域，上边介绍了很多了。它相当于DataSource数据源，securityManager进行安全认证需要通过realm获取用户权限数据，比如：如果用户身份信息存储在数据库那么realm就需要从数据库获取用户身份信息。 注意： 不要把realm理解成只是从数据源取数据，在realm中还有认证授权校验相关的代码。 SessionManager(org.apache.shiro.session.SessionManager)Session会话管理器Shiro框架提供了一套会话管理，它不依赖web容器的session，所以Shiro可以使用在非web环境中，也可以将分布式应用的会话集中在一点管理，此特性可使它实现单点登录。 SessionDAO(org.apache.shiro.session.mgt.eis.SessionDAO)用于会话的curd代表SessionManager执行Session持久化（CRUD）操作。比如要将session存储到数据库(Redis)，可以使用jdbc(RedisManager)将会话存储到数据库(Redis)。 CacheManager(org.apahce.shiro.cache.CacheManager)缓存管理器 创建并管理其他Shiro组件使用的Cache实例生命周期。因为Shiro能够访问许多后台数据源，由于身份验证，授权和会话管理，缓存在框架中一直是一流的架构功能，用来在同时使用这些数据源时提高性能。 Cryptography(org.apache.shiro.crypto.x)密码模块Shiro提供了一套加密/解密的组件，方便开发。提供了常用的散列、加/解密算法。 Authentication Strategy(org.apache.shiro.authc.pam.AuthenticationStrategy) 如果不止一个Realm被配置，则AuthenticationStrategy将会协调这些Realm来决定身份认证尝试成功或失败下的条件（例如，如果一个Realm成功，而其他的均失败，是否该尝试成功？是否所有的Realm必须成功？或只有第一个成功即可？）。 下一篇将会Coding一下，进行Shiro代码入门。]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>原理</tag>
        <tag>框架</tag>
        <tag>shiro</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringSecurity浅析：原理篇]]></title>
    <url>%2Fsprings-principle%2F</url>
    <content type="text"><![CDATA[简介 SpringSecurity 是一个灵活和强大的身份验证和访问控制的安全框架，它确保基于Spring的应用程序提供身份验证和授权支持。它与Spring MVC有很好地集成，并配备了流行的安全算法实现捆绑在一起。 Spring Security 模块 核心模块 - spring-security-core.jar：包含核心验证和访问控制类和接口，远程支持的基本配置API，是基本模块。 远程调用 - spring-security-remoting.jar：提供与 Spring Remoting 集成。 网页 - spring-security-web.jar：包括网站安全的模块，提供网站认证服务和基于URL访问控制。 配置 - spring-security-config.jar：包含安全命令空间解析代码，若使用XML进行配置则需要。 LDAP - spring-security-ldap.jar：LDAP 验证和配置，若需要LDAP验证和管理LDAP用户实体。 ACL访问控制表 - spring-security-acl.jar：ACL专门领域对象的实现。 CAS - spring-security-cas.jar：CAS客户端继承，若想用CAS的SSO服务器网页验证。 OpenID - spring-security-openid.jar：OpenID网页验证支持。 Test - spring-security-test.jar：支持Spring Security的测试。 认证流程 用户使用用户名和密码登录。 用户名密码被过滤器（默认为UsernamePasswordAuthenticationFilter）获取到，封装成 Authentication。 token（Authentication实现类）传递给 AuthenticationManager 进行认证。 AuthenticationManager 认证成功后返回一个封装了用户权限信息的 Authentication 对象。 通过调用 SecurityContextHolder.getContext().setAuthentication(…) 将 Authentication 对象赋给当前的 SecurityContext。 启动原理启动demo引入相关依赖后，根据Spring Security官方文档给出的例子创建类。 12345678910@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser(&quot;user&quot;).password(&quot;password&quot;).roles(&quot;USER&quot;); &#125;&#125; 以上我们便将spring security应用到我们的项目中了，上面的例子，在内存中配置了一个用户名为user,密码为password，并且拥有USER角色的用户。想要知道它是怎么运行的，请往下看。 WebSecurityConfigurer的子类可以扩展spring security的应用, 而WebSecurityConfigurerAdapter是WebSecurityConfigurer 的一个适配器，必然也是做了很多默认的工作。 入手 @EnableWebSecurity注解跟进@EnableWebSecurity看下源码： 123456789@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)@Documented@Import(&#123;WebSecurityConfiguration.class, SpringWebMvcImportSelector.class, OAuth2ImportSelector.class&#125;)@EnableGlobalAuthentication@Configurationpublic @interface EnableWebSecurity &#123; boolean debug() default false;&#125; Tips： @EnableWebSecurity 配置到拥有注解 @Configuration 的类上，就可以获取到spring security的支持. 跟进 SpringWebMvcImportSelectorSpringWebMvcImportSelector 的作用是判断当前的环境是否包含springmvc，因为spring security可以在非spring环境下使用，为了避免DispatcherServlet的重复配置，所以使用了这个注解来区分。 跟进 @EnableGlobalAuthentication注解的源码如下： 1234@Import(AuthenticationConfiguration.class)@Configurationpublic @interface EnableGlobalAuthentication &#123;&#125; 可以看出，这个注解引入了AuthenticationConfiguration配置。而这个类用来配置认证相关，主要任务就是生成全局的身份认证管理者。AuthenticationManager： 1234567891011121314151617@Configuration@Import(ObjectPostProcessorConfiguration.class)public class AuthenticationConfiguration &#123; private AuthenticationManager authenticationManager; @Bean public AuthenticationManagerBuilder authenticationManagerBuilder( ObjectPostProcessor&lt;Object&gt; objectPostProcessor) &#123; return new AuthenticationManagerBuilder(objectPostProcessor); &#125; public AuthenticationManager getAuthenticationManager() throws Exception &#123; ... &#125;&#125; 跟进 WebSecurityConfiguration setFilterChainProxySecurityConfigurer（）方法12345678910111213141516171819202122232425262728293031323334353637@Autowired(required = false)public void setFilterChainProxySecurityConfigurer( ObjectPostProcessor&lt;Object&gt; objectPostProcessor, //T1 使用@Value获取到配置信息 @Value(&quot;#&#123;@autowiredWebSecurityConfigurersIgnoreParents.getebSecurityConfigurers()&#125;&quot;) List&lt;SecurityConfigurer&lt;Filter,WebSecurity&gt;&gt; webSecurityConfigurers) throws Exception &#123; //T2 创建一个webSecurity 对象 webSecurity = objectPostProcessor .postProcess(new WebSecurity(objectPostProcessor)); if (debugEnabled != null) &#123; webSecurity.debug(debugEnabled); &#125; //T3对configures进行排序 Collections.sort(webSecurityConfigurers,AnnotationAwareOrderComparator.INSTANCE); //T4对Order进行比较是否有相同的，由于前面进行了排序，只要比较后有相同的就可以 Integer previousOrder = null; Object previousConfig = null; for (SecurityConfigurer&lt;Filter, WebSecurity&gt; config :webSecurityConfigurers) &#123; Integer order =AnnotationAwareOrderComparator.lookupOrder(config); if (previousOrder != null &amp;&amp; previousOrder.equals(order)) &#123; throw new IllegalStateException( &quot;@Order on WebSecurityConfigurers must beunique. Order of &quot; + order + &quot; was already used on &quot; +previousConfig + &quot;, so it cannot be usedon &quot; + config + &quot; too.&quot;); &#125; previousOrder = order; previousConfig = config; &#125; for (SecurityConfigurer&lt;Filter, WebSecurity&gt;webSecurityConfigurer : webSecurityConfigurers) &#123; //T5将配置信息配置到webSecurity中 webSecurity.apply(webSecurityConfigurer); &#125; this.webSecurityConfigurers = webSecurityConfigurers;&#125; 上述代码中T1标记处，我们看一下autowiredWebSecurityConfigurersIgnoreParents.getWebSecurityConfigurers()的源代码 1234567891011private final ConfigurableListableBeanFactory beanFactory;public List&lt;SecurityConfigurer&lt;Filter, WebSecurity&gt;&gt; getWebSecurityConfigurers() &#123; List&lt;SecurityConfigurer&lt;Filter, WebSecurity&gt;&gt; webSecurityConfigurers = new ArrayList&lt;SecurityConfigurer&lt;Filter, WebSecurity&gt;&gt;(); Map&lt;String, WebSecurityConfigurer&gt; beansOfType = beanFactory .getBeansOfType(WebSecurityConfigurer.class); for (Entry&lt;String, WebSecurityConfigurer&gt; entry : beansOfType.entrySet()) &#123; webSecurityConfigurers.add(entry.getValue()); &#125; return webSecurityConfigurers; &#125; 这个beansOfType 就是我们定义的继承自WebSecurityConfigurerAdapter的类， 通过查看父类的定义，我们知道调用build()方法最后返回的必须是一个Filter对象，可以自行参考顶级父类(或接口)WebSecurityConfigurer和SecurityBuilder springSecurityFilterChain（）为我们创建了一个名字叫做springSecurityFilterChain的Filter源代码: 123456789101112131415161718192021222324/** * Creates the Spring Security Filter Chain * @return the &#123;@link Filter&#125; that represents the security filterchain * @throws Exception */@Bean(name = AbstractSecurityWebApplicationInitializer.DEFAULT_FILTR_NAME)public Filter springSecurityFilterChain() throws Exception &#123; //T1 查看是否有WebSecurityConfigurer的相关配置 boolean hasConfigurers = webSecurityConfigurers != null &amp;&amp; !webSecurityConfigurers.isEmpty(); //T2 如果没有，说明我们没有注入继承WebSecurityConfigurerAdapter的对象（没有创建其子类） if (!hasConfigurers) &#123; //T3 创建默认的配置信息WebSecurityConfigurerAdapter,保证SpringSecurity的 //最基础的功能，如果我们要有自定义的相关，一定要重配置 WebSecurityConfigurerAdapter adapter =objectObjectPostProcessor .postProcess(new WebSecurityConfigurerAdapter() &#123; &#125;); //T4 默认配置信息载入webSecurity webSecurity.apply(adapter); &#125; // T5这里build一个Filter return webSecurity.build();&#125; webSecurity对象在此时已经加载完所有的配置。 webSecurity对象为我们创建一个Filter通过的是build()方法。 注意： 建立了一个Filter对象，而这个Filter将会拦截掉我们的请求，对请求进行过滤拦截，从而起到对资源进行认证保护的作用。然后这个Filter并非我们自己平时定义的Filter这么简单,这个过滤器也只是一个代理的过滤器而已，里面还会有过滤器链。 WebSecurity的build()方法WebSecurity继承了AbstractConfiguredSecurityBuilder类，实现了SecurityBuilder接口。 事实上AbstractConfiguredSecurityBuilder类的父类AbstractSecurityBuilder也是实现了SecurityBuilder接口。子类和父类实现同一个接口。事实上是为了子类在反射调用方法getInterfaces()中可以获取到接口，根据这里的情况就是WebSecurity反射调用getInterfaces()可以获取到SecurityBuilder接口。 WebSecurity 类图 SecurityBuilder定义了构建的接口标准 AbstractSecurityBuilder实现build方法,用AtomicBoolean的变量building保证多线程情况下，操作的原子性。此处采用的是模板模式。定义了doBuild()抽象方法,用来给子类实现。 AbstractConfiguredSecurityBuilder 继承AbstractSecurityBuilder实现doBuild()方法,也采用模板模式，定义了实现的具体的步骤，如UNBUILT，INITIALIZING,CONFIGURING,BUILDING，以及BUILT。 我们看一下WebSecurity的定义 123456public final class WebSecurity extends AbstractConfiguredSecurityBuilder&lt;Filter, WebSecurity&gt; implements SecurityBuilder&lt;Filter&gt;, ApplicationContextAware &#123; ... ...&#125; 从上面的代码可以看出WebSecurity指定泛型的类型为Filter，结合上面接口build()方法我们可以知道，WebSecurity的build()方法返回的是一个Filter,Spring Securiy 通过这个来创建一个过滤器。 build()过程 AbstractSecurityBuilder保证了线程的安全。 AbstractConfiguredSecurityBuilder保证了构建过程以及构建状态。 WebSecurity通过performBuild()来实现自身的构建 AbstractConfiguredSecurityBuilder的构建过程，我们看一下doBuild()方法的定义 123456789101112131415161718192021222324252627@Overrideprotected final O doBuild() throws Exception &#123; synchronized (configurers) &#123; buildState = BuildState.INITIALIZING; //默认什么都没做，WebSecurity也没有重写 beforeInit(); //T1默认此处调用WebSecurityConfigurerAdapter的init(finalWebSecurity web)方法 init(); buildState = BuildState.CONFIGURING; //默认什么都不做,WebSecurity没有重写 beforeConfigure(); //调用WebSecurityConfigurerAdapter的configure(WbSecurity web)，但是什么都没做 configure(); buildState = BuildState.BUILDING; //T2这里调用WebSecurity的performBuild()方法 O result = performBuild(); buildState = BuildState.BUILT; //从WebSecurity的实现，这里返回了一个Filter，完成构建过程 return result; &#125;&#125; T1 处调用WebSecurityConfigurerAdapter的init(final WebSecurity web)方法，看一下源代码的定义 1234567891011121314151617/** * @param web * @throws Exception */public void init(final WebSecurity web) throws Exception &#123; //构建HttpSecurity对象 final HttpSecurity http = getHttp(); //Ta web.addSecurityFilterChainBuilder(http).postBuildAction(new Runnable() &#123; public void run() &#123; FilterSecurityInterceptor securityInterceptor = http .getSharedObject(FilterSecurityInterceptor.class); web.securityInterceptor(securityInterceptor); &#125; &#125;);&#125; 这里构建了HttpSecurity对象，以及有一个共享对象FilterSecurityInterceptor。 Ta 处调用了WebSecurity的addSecurityFilterChainBuilder()方法，我们看一下这个方法的源代码123456public WebSecurity addSecurityFilterChainBuilder( SecurityBuilder&lt;? extends SecurityFilterChain&gt; securityFilterChainBuilder) &#123; //这个就是securityFilterChainBuilders变量 this.securityFilterChainBuilders.add(securityFilterChainBuilder); return this;&#125; 在构建Filter过程的初始化的时候，我们对securityFilterChainBuilders这个变量进行了赋值，默认情况下securityFilterChainBuilders里面只有一个对象，那就是HttpSecurity。 T2 根据WebSecurity的属性构建Filter的performBuild()方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Overrideprotected Filter performBuild() throws Exception &#123; Assert.state( //T1 securityFilterChainBuilders哪里来的? !securityFilterChainBuilders.isEmpty(), () -&gt; &quot;At least one SecurityBuilder&lt;? extends SecurityFilterChain&gt; needs to be specified. &quot; + &quot;Typically this done by adding a @Configuration that extends WebSecurityConfigurerAdapter. &quot; + &quot;More advanced users can invoke &quot; + WebSecurity.class.getSimpleName() + &quot;.addSecurityFilterChainBuilder directly&quot;); //T2 ignoredRequests.size()到底是什么？ int chainSize = ignoredRequests.size() + securityFilterChainBuilders.size(); //这个securityFilterChains 的集合里面存放的就是我们所有的过滤器链，根据长度的定义， //我们也可以知道分为两种一个是通过 ignoredRequests 来的过滤器链, //一个是通过 securityFilterChainBuilders 这个过滤器链构建链来的。 List&lt;SecurityFilterChain&gt; securityFilterChains = new ArrayList&lt;&gt;( chainSize); //如果是 ignoredRequest类型的，那么就添加默认过滤器链(DefaultSecurityFilterChain) for (RequestMatcher ignoredRequest : ignoredRequests) &#123; securityFilterChains.add(new DefaultSecurityFilterChain(ignoredRequest)); &#125; //如果是securityFilterChainBuilder类型的，那么通过securityFilterChainBuilder的build()方法来构建过滤器链 for (SecurityBuilder&lt;? extends SecurityFilterChain&gt; securityFilterChainBuilder : securityFilterChainBuilders) &#123; securityFilterChains.add(securityFilterChainBuilder.build()); &#125; //将过滤器链交给一个过滤器链代理对象,而这个代理对象就是返回回去的 //过滤器。到这里为止，过滤器的过程已经结束 //T3 什么是FilterChainProxy? FilterChainProxy filterChainProxy = new FilterChainProxy(securityFilterChains); if (httpFirewall != null) &#123; filterChainProxy.setFirewall(httpFirewall); &#125; filterChainProxy.afterPropertiesSet(); Filter result = filterChainProxy; if (debugEnabled) &#123; logger.warn(&quot;\n\n&quot; + &quot;********************************************************************\n&quot; + &quot;********** Security debugging is enabled. *************\n&quot; + &quot;********** This may include sensitive information. *************\n&quot; + &quot;********** Do not use in a production system! *************\n&quot; + &quot;********************************************************************\n\n&quot;); result = new DebugFilter(filterChainProxy); &#125; postBuildAction.run(); return result;&#125; WebSecurity的securityFilterChainBuilders属性哪里来的？见上边解释 ignoredRequest是什么？ignoredRequests只是WebSecurity的一个属性 ignoredRequests的list中的值从哪里来的呢？我们可以看到里面有一个ignore()方法，通过这个来进行设置的怎么设置呢，那我们得看看WebSecurityConfigurerAdapter这个类了，里面有一个configure方法供我们重写 12345678910public void configure(WebSecurity web) throws Exception &#123;&#125;#具体的例子如下@Overridepublic void configure(WebSecurity web) throws Exception &#123; super.configure(web); web.ignoring() .mvcMatchers(&quot;/favicon.ico&quot;, &quot;/webjars/**&quot;, &quot;/css/**&quot;);&#125; 然后值得一提的是这里有多少个mvcMatchers就会创建多少个ignoredRequests的对象，也就会有多少个过滤器链，也是在WebSecurity里面定义的内部类IgnoredRequestConfigurer这个类里面。 FilterChainProxy到底是什么上面的描述中我们知道， FilterChainProxy是真正返回的Filter，上面代码中 FilterChainProxy的对象创建的源码为：1FilterChainProxy filterChainProxy = new FilterChainProxy(securityFilterChains); Filter实现的流程 小结SpringSecurityFilterChain 是Spring Security认证的入口。集成Spring Boot集成之后，xml配置被java注解配置取代，也就是 在WebSecurityConfiguration中完成了声明springSecurityFilterChain的作用。 并且最终交给DelegatingFilterProxy这个代理类，负责拦截请求。 也就是说：@EnableWebSecurity完成的工作便是加载了WebSecurityConfiguration，AuthenticationConfiguration这两个核心配置类，也就此将spring security的职责划分为了配置安全信息，配置认证信息两部分。 入手 WebSecurityConfigurerAdapter 适配器类。 HttpSecurity 通过getHttp()获取，后面会详细说到这个类 UserDetailsService 用户信息获取 AuthenticationManager 认证管理类 SecurityContextHolderSecurityContextHolder 用于存储安全上下文信息（如操作用户是谁、用户是否被认证、用户权限有哪些），它用 ThreadLocal 来保存 SecurityContext，者意味着 Spring Security 在用户登录时自动绑定到当前现场，用户退出时，自动清除当前线程认证信息，SecurityContext 中含有正在访问系统用户的详细信息]]></content>
      <categories>
        <category>SpringSecurity</category>
      </categories>
      <tags>
        <tag>原理</tag>
        <tag>框架</tag>
        <tag>安全</tag>
        <tag>springsecurity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringSecurity简单入门]]></title>
    <url>%2Fsprings-start%2F</url>
    <content type="text"><![CDATA[SpringSecurity简单入门环境：SpringBoot 2.1 + Mybatis + SpringSecurity 5.0 导入依赖导入 spring-boot-starter-security 依赖，在 SpringBoot 2.1 环境下默认使用的是 5.0 版本。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/grupId&gt; &lt;artifactId&gt;spring-boot-starter-paren&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parentfrom repository --&gt;&lt;/parent&gt;&lt;groupId&gt;com.jelly&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-security&lt;/artifacId&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;name&gt;spring-boot-security&lt;/name&gt;&lt;description&gt;Demo project for SpringBoot&lt;/description&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot/groupId&gt; &lt;artifactId&gt;spring-boot-starter-scurity&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot/groupId&gt; &lt;artifactId&gt;spring-boot-starter-wb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-sarter&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--https://mvnrepository.com/artifact/or.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupd&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.6&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tst&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.secuity&lt;/groupId&gt; &lt;artifactId&gt;spring-security-test&lt;artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.oot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-mavenplugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 创建数据库一般权限控制有三层，即：用户&lt;–&gt;角色&lt;–&gt;权限，用户与角色是多对多，角色和权限也是多对多。这里我们先暂时不考虑权限，只考虑用户&lt;–&gt;角色。 创建用户表sys_user： 123456CREATE TABLE `sys_user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) NOT NULL, `password` varchar(255) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 创建权限表sys_role： 12345CREATE TABLE `sys_role` ( `id` int(11) NOT NULL, `name` varchar(255) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 创建用户-角色表sys_user_role： 12345678CREATE TABLE `sys_user_role` ( `user_id` int(11) NOT NULL, `role_id` int(11) NOT NULL, PRIMARY KEY (`user_id`,`role_id`), KEY `fk_role_id` (`role_id`), CONSTRAINT `fk_role_id` FOREIGN KEY (`role_id`) REFERENCES `sys_role` (`id`) ON DELETE CASCADE ON UPDATE CASCADE, CONSTRAINT `fk_user_id` FOREIGN KEY (`user_id`) REFERENCES `sys_user` (`id`) ON DELETE CASCADE ON UPDATE CASCADE) ENGINE=InnoDB DEFAULT CHARSET=utf8; 初始化一下数据： 12345678INSERT INTO `sys_role` VALUES (&apos;1&apos;, &apos;ROLE_ADMIN&apos;);INSERT INTO `sys_role` VALUES (&apos;2&apos;, &apos;ROLE_USER&apos;);INSERT INTO `sys_user` VALUES (&apos;1&apos;, &apos;admin&apos;, &apos;123&apos;);INSERT INTO `sys_user` VALUES (&apos;2&apos;, &apos;jitwxs&apos;, &apos;123&apos;);INSERT INTO `sys_user_role` VALUES (&apos;1&apos;, &apos;1&apos;);INSERT INTO `sys_user_role` VALUES (&apos;2&apos;, &apos;2&apos;); 注意： 这里的权限格式为 ROLE_XXX ，是Spring Security规定的，不要乱起名字哦。 准备页面因为是示例程序，页面越简单越好，只用于登陆的login.html以及用于登陆成功后的home.html，将其放置在 resources/static 目录下： login.html：123456789101112131415161718192021&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;登陆&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;登陆&lt;/h1&gt;&lt;form method=&quot;post&quot; action=&quot;/login&quot;&gt; &lt;div&gt; 用户名：&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt; &lt;/div&gt; &lt;div&gt; 密码：&lt;input type=&quot;password&quot; name=&quot;password&quot;&gt; &lt;/div&gt; &lt;div&gt; &lt;button type=&quot;submit&quot;&gt;立即登陆&lt;/button&gt; &lt;/div&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 注意： 用户的登陆认证是由Spring Security进行处理的，请求路径默认为/login，用户名字段默认为username，密码字段默认为password home.html12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;登陆成功&lt;/h1&gt; &lt;a href=&quot;/admin&quot;&gt;检测ROLE_ADMIN角色&lt;/a&gt; &lt;a href=&quot;/user&quot;&gt;检测ROLE_USER角色&lt;/a&gt; &lt;button onclick=&quot;window.location.href=&apos;/logout&apos;&quot;&gt;退出登录&lt;/button&gt;&lt;/body&gt;&lt;/html&gt; 配置application.properties在配置文件中配置下数据库连接： 数据源1234567spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/study?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=GMT%2B8&amp;useSSL=truespring.datasource.username=rootspring.datasource.password=123456#开启Mybatis下划线命名转驼峰命名mybatis.configuration.map-underscore-to-camel-case=true 创建实体、Dao、Service和Controller实体SysUser1234567891011121314151617181920212223package com.jelly.security.bean;import lombok.Data;import java.io.Serializable;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 18:53 **/@Datapublic class SysUser &#123; private Integer id; private String name; private String password;&#125; SysRole123456789101112131415161718192021package com.jelly.security.bean;import lombok.Data;import java.io.Serializable;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 18:54 **/@Datapublic class SysRole &#123; private Integer id; private String name;&#125; SysUserRole123456789101112131415161718192021package com.jelly.security.bean;import lombok.Data;import java.io.Serializable;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 18:55 **/@Datapublic class SysUserRole &#123; private Integer userId; private Integer roleId;&#125; DaoSysUserMapper12345678910111213141516171819package com.jelly.security.dao;import com.jelly.security.bean.SysUser;import org.apache.ibatis.annotations.Select;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 19:03 **/public interface SysUserMapper &#123; @Select(&quot;SELECT * FROM sys_user WHERE id = #&#123;id&#125;&quot;) SysUser selectById(Integer id); @Select(&quot;SELECT * FROM sys_user WHERE name = #&#123;name&#125;&quot;) SysUser selectByName(String name);&#125; SysRoleMapper12345678910111213141516package com.jelly.security.dao;import com.jelly.security.bean.SysRole;import org.apache.ibatis.annotations.Select;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 19:07 **/public interface SysRoleMapper &#123; @Select(&quot;SELECT * FROM sys_role WHERE id = #&#123;id&#125;&quot;) SysRole selectById(Integer id);&#125; SysUserRoleMapper123456789101112131415161718package com.jelly.security.dao;import com.jelly.security.bean.SysUserRole;import org.apache.ibatis.annotations.Select;import java.util.List;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 19:08 **/public interface SysUserRoleMapper &#123; @Select(&quot;SELECT * FROM sys_user_role WHERE user_id = #&#123;userId&#125;&quot;) List&lt;SysUserRole&gt; listByUserId(Integer userId);&#125; ServiceSysUserService123456789101112131415161718192021222324252627package com.jelly.security.service;import com.jelly.security.bean.SysUser;import com.jelly.security.dao.SysUserMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 19:09 **/@Servicepublic class SysUserService &#123; @Autowired private SysUserMapper userMapper; public SysUser selectById(Integer id) &#123; return userMapper.selectById(id); &#125; public SysUser selectByName(String name) &#123; return userMapper.selectByName(name); &#125;&#125; SysRoleService123456789101112131415161718192021222324package com.jelly.security.service;import com.jelly.security.bean.SysRole;import com.jelly.security.dao.SysRoleMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 19:10 **/@Servicepublic class SysRoleService &#123; @Autowired private SysRoleMapper roleMapper; public SysRole selectById(Integer id)&#123; return roleMapper.selectById(id); &#125;&#125; SysUserRoleService12345678910111213141516171819202122232425package com.jelly.security.service;import com.jelly.security.bean.SysUserRole;import com.jelly.security.dao.SysUserRoleMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 19:11 **/@Servicepublic class SysUserRoleService &#123; @Autowired private SysUserRoleMapper userRoleMapper; public List&lt;SysUserRole&gt; listByUserId(Integer userId) &#123; return userRoleMapper.listByUserId(userId); &#125;&#125; Controller12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.jelly.security.web;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.security.access.prepost.PreAuthorize;import org.springframework.security.core.context.SecurityContextHolder;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;/** * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 19:12 **/@Controllerpublic class LoginController &#123; private Logger logger = LoggerFactory.getLogger(LoginController.class); @RequestMapping(&quot;/&quot;) public String showHome() &#123; String name = SecurityContextHolder.getContext().getAuthentication().getName(); logger.info(&quot;当前登陆用户：&quot; + name); return &quot;home.html&quot;; &#125; @RequestMapping(&quot;/login&quot;) public String showLogin() &#123; return &quot;login.html&quot;; &#125; @RequestMapping(&quot;/admin&quot;) @ResponseBody @PreAuthorize(&quot;hasRole(&apos;ROLE_ADMIN&apos;)&quot;) public String printAdmin() &#123; return &quot;如果你看见这句话，说明你有ROLE_ADMIN角色&quot;; &#125; @RequestMapping(&quot;/user&quot;) @ResponseBody @PreAuthorize(&quot;hasRole(&apos;ROLE_USER&apos;)&quot;) public String printUser() &#123; return &quot;如果你看见这句话，说明你有ROLE_USER角色&quot;; &#125;&#125; 如代码所示，获取当前登录用户： SecurityContextHolder.getContext().getAuthentication()@PreAuthorize 用于判断用户是否有指定权限，没有就不能访问 配置SpringSecurityUserDetailsService首先我们需要自定义 UserDetailsService ，将用户信息和权限注入进来。 我们需要重写 loadUserByUsername 方法，参数是用户输入的用户名。返回值是UserDetails，这是一个接口，一般使用它的子类org.springframework.security.core.userdetails.User，它有三个参数，分别是用户名、密码和权限集。 实际情况下，大多将 DAO 中的 User 类继承 org.springframework.security.core.userdetails.User 返回 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.jelly.security.security;import com.jelly.security.bean.SysRole;import com.jelly.security.bean.SysUser;import com.jelly.security.bean.SysUserRole;import com.jelly.security.service.SysRoleService;import com.jelly.security.service.SysUserRoleService;import com.jelly.security.service.SysUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.security.core.GrantedAuthority;import org.springframework.security.core.authority.SimpleGrantedAuthority;import org.springframework.security.core.userdetails.User;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.core.userdetails.UsernameNotFoundException;import org.springframework.stereotype.Service;import java.util.ArrayList;import java.util.Collection;import java.util.List;/** * 我们需要自定义 UserDetailsService ，将用户信息和权限注入进来。 * * 我们需要重写 loadUserByUsername 方法，参数是用户输入的用户名。 * * 返回值是UserDetails，这是一个接口，一般使用它的子类o * * rg.springframework.security.core.userdetails.User， * * 它有三个参数，分别是用户名、密码和权限集。 * @version V1.0 * @author: Jelly * @program: spring-boot-security * @description: * @date: 2019-03-10 19:25 **/@Service(&quot;userDetailsService&quot;)public class CustomUserDetailsService implements UserDetailsService &#123; @Autowired private SysUserService userService; @Autowired private SysRoleService roleService; @Autowired private SysUserRoleService userRoleService; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; Collection&lt;GrantedAuthority&gt; authorities = new ArrayList&lt;&gt;(); // 从数据库中取出用户信息 SysUser user = userService.selectByName(username); // 判断用户是否存在 if(user == null) &#123; throw new UsernameNotFoundException(&quot;用户名不存在&quot;); &#125; // 添加权限 List&lt;SysUserRole&gt; userRoles = userRoleService.listByUserId(user.getId()); for (SysUserRole userRole : userRoles) &#123; SysRole role = roleService.selectById(userRole.getRoleId()); authorities.add(new SimpleGrantedAuthority(role.getName())); &#125; // 返回UserDetails实现类 return new User(user.getName(), user.getPassword(), authorities); &#125;&#125; WebSecurityConfig该类是 Spring Security 的配置类，该类的三个注解分别是标识该类是配置类、开启 Security 服务、开启全局 Securtiy 注解。 首先将我们自定义的 userDetailsService 注入进来，在 configure() 方法中使用 auth.userDetailsService() 方法替换掉默认的 userDetailsService。 这里我们还指定了密码的加密方式（5.0 版本强制要求设置），因为我们数据库是明文存储的，所以明文返回即可，如下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.jelly.security.security;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.builders.WebSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.crypto.password.PasswordEncoder;/** * @version V1.0 * @author: Jelly * @program: * @description: * @date: 2019-03-10 17:27 **/@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired private CustomUserDetailsService userDetailsService; /** * 想要密码加密 * * auth.userDetailsService(userDetailsService) * .passwordEncoder(new BCryptPasswordEncoder()); * @param auth * @throws Exception */ @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.userDetailsService(userDetailsService).passwordEncoder(new PasswordEncoder() &#123; @Override public String encode(CharSequence charSequence) &#123; return charSequence.toString(); &#125; @Override public boolean matches(CharSequence charSequence, String s) &#123; return s.equals(charSequence.toString()); &#125; &#125;); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() // 如果有允许匿名的url，填在下面// .antMatchers().permitAll() .anyRequest().authenticated() .and() // 设置登陆页 .formLogin().loginPage(&quot;/login&quot;) // 设置登陆成功页 .defaultSuccessUrl(&quot;/&quot;).permitAll() // 自定义登陆用户名和密码参数，默认为username和password// .usernameParameter(&quot;username&quot;)// .passwordParameter(&quot;password&quot;) .and() .logout().permitAll(); // 关闭CSRF跨域 http.csrf().disable(); &#125; @Override public void configure(WebSecurity web) throws Exception &#123; // 设置拦截忽略文件夹，可以对静态资源放行 web.ignoring().antMatchers(&quot;/css/**&quot;, &quot;/js/**&quot;); &#125;&#125; 运行程序在启动类添加注解 1@MapperScan(&quot;com.jelly.security.dao&quot;) 启动项目，浏览器输入：localhost:8080。有以下两个角色。 12ROLE_ADMIN 账户：用户名 admin，密码 123ROLE_USER 账户：用户名 jitwxs，密码 123 配置跨域在configure中添加 1.and().cors(). 下边添加： 1234567891011@Beanpublic CorsFilter corsFilter() &#123; final UrlBasedCorsConfigurationSource urlBasedCorsConfigurationSource = new UrlBasedCorsConfigurationSource(); final CorsConfiguration cors = new CorsConfiguration(); cors.setAllowCredentials(true); cors.addAllowedOrigin(&quot;*&quot;); cors.addAllowedHeader(&quot;*&quot;); cors.addAllowedMethod(&quot;*&quot;); urlBasedCorsConfigurationSource.registerCorsConfiguration(&quot;/**&quot;, cors); return new CorsFilter(urlBasedCorsConfigurationSource);&#125;]]></content>
      <categories>
        <category>SpringSecurity</category>
      </categories>
      <tags>
        <tag>框架</tag>
        <tag>安全</tag>
        <tag>springsecurity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ceph浅析：结构、工作原理及流程]]></title>
    <url>%2Fceph-principle%2F</url>
    <content type="text"><![CDATA[Ceph浅析：结构、工作原理及流程 其命名和UCSC（Ceph诞生地）的吉祥物有关，这个吉祥物是“Sammy”，一个香蕉色的蛞蝓，就是头足类中无壳的软体动物。这些有多触角的头足类动物，是对一个分布式文件系统高度并行的形象比喻。 Ceph的结构Ceph系统的层次结构Ceph存储系统的逻辑层次结构如下图所示： 自下向上，可以将Ceph系统分为四个层次： （1）基础存储系统RADOS（Reliable, Autonomic, Distributed Object Store，即可靠的、自动化的、分布式的对象存储） 顾名思义，这一层本身就是一个完整的对象存储系统，所有存储在Ceph系统中的用户数据事实上最终都是由这一层来存储的。而Ceph的高可靠、高可扩展、高性能、高自动化等等特性本质上也是由这一层所提供的。因此，理解RADOS是理解Ceph的基础与关键。 物理上，RADOS由大量的存储设备节点组层，每个节点拥有自己的硬件资源（CPU、内存、硬盘、网络），并运行着操作系统和文件系统。4.2、4.3节将对RADOS进行展开介绍。 （2）基础库librados这一层的功能是对RADOS进行抽象和封装，并向上层提供API，以便直接基于RADOS（而不是整个Ceph）进行应用开发。特别要注意的是，RADOS是一个对象存储系统，因此，librados实现的API也只是针对对象存储功能的。 RADOS采用C++开发，所提供的原生librados API包括C和C++两种，其文档参见[2]。物理上，librados和基于其上开发的应用位于同一台机器，因而也被称为本地API。应用调用本机上的librados API，再由后者通过socket与RADOS集群中的节点通信并完成各种操作。 （3）高层应用接口这一层包括了三个部分：RADOS GW（RADOS Gateway）、 RBD（Reliable Block Device）和Ceph FS（Ceph File System），其作用是在librados库的基础上提供抽象层次更高、更便于应用或客户端使用的上层接口。 其中，RADOS GW是一个提供与Amazon S3和Swift兼容的RESTful API的gateway，以供相应的对象存储应用开发使用。RADOS GW提供的API抽象层次更高，但功能则不如librados强大。因此，开发者应针对自己的需求选择使用。 RBD则提供了一个标准的块设备接口，常用于在虚拟化的场景下为虚拟机创建volume。目前，Red Hat已经将RBD驱动集成在KVM/QEMU中，以提高虚拟机访问性能。 Ceph FS是一个POSIX兼容的分布式文件系统。由于还处在开发状态，因而Ceph官网并不推荐将其用于生产环境中。 （4）应用层这一层就是不同场景下对于Ceph各个应用接口的各种应用方式，例如基于librados直接开发的对象存储应用，基于RADOS GW开发的对象存储应用，基于RBD实现的云硬盘等等。 在上文的介绍中，有一个地方可能容易引起困惑：RADOS自身既然已经是一个对象存储系统，并且也可以提供librados API，为何还要再单独开发一个RADOS GW？ 理解这个问题，事实上有助于理解RADOS的本质，因此有必要在此加以分析。粗看起来，librados和RADOS GW的区别在于，librados提供的是本地API，而RADOS GW提供的则是RESTful API，二者的编程模型和实际性能不同。而更进一步说，则和这两个不同抽象层次的目标应用场景差异有关。换言之，虽然RADOS和S3、Swift同属分布式对象存储系统，但RADOS提供的功能更为基础、也更为丰富。这一点可以通过对比看出。 由于Swift和S3支持的API功能近似，这里以S3举例说明。S3提供的API功能主要包括： 用户管理操作： 用户认证、获取账户信息、列出容器列表等； 容器管理操作： 创建/删除容器、读取容器信息、列出容器内对象列表等； 对象管理操作： 对象的写入、读取、复制、更新、删除、访问许可设置、元数据读取或更新等。 由此可见，S3（以及Swift）提供的API所操作的“对象”只有三个：用户账户、用户存储数据对象的容器、数据对象。并且，所有的操作均不涉及存储系统 的底层硬件或系统信息。不难看出，这样的API设计完全是针对对象存储应用开发者和对象存储应用用户的，并且假定其开发者和用户关心的内容更偏重于账户和数据的管理，而对底层存储系统细节不感兴趣，更不关心效率、性能等方面的深入优化。? 而librados API的设计思想则与此完全不同。一方面，librados中没有账户、容器这样的高层概念；另一方面，librados API向开发者开放了大量的RADOS状态信息与配置参数，允许开发者对RADOS系统以及其中存储的对象的状态进行观察，并强有力地对系统存储策略进行控制。换言之，通过调用librados API，应用不仅能够实现对数据对象的操作，还能够实现对RADOS系统的管理和配置。这对于S3和Swift的RESTful API设计是不可想像的，也是没有必要的。 基于上述分析对比，不难看出，librados事实上更适合对于系统有着深刻理解，同时对于功能定制扩展和性能深度优化有着强烈需求的高级用户。基于librados的开发可能更适合于在私有Ceph系统上开发专用应用，或者为基于Ceph的公有存储系统开发后台数据管理、处理应用。而RADOS GW则更适合于常见的基于web的对象存储应用开发，例如公有云上的对象存储服务。? RADOS的逻辑结构RADOS的系统逻辑结构如下图所示 在使用RADOS系统时，大量的客户端程序通过与OSD或者monitor的交互获取cluster map，然后直接在本地进行计算，得出对象的存储位置后，便直接与对应的OSD通信，完成数据的各种操作。 可见，在此过程中，只要保证cluster map不频繁更新，则客户端显然可以不依赖于任何元数据服务器，不进行任何查表操作，便完成数据访问流程。在RADOS的运行过程中，cluster map的更新完全取决于系统的状态变化，而导致这一变化的常见事件只有两种：OSD出现故障，或者RADOS规模扩大。 而正常应用场景下，这两种事件发生 的频率显然远远低于客户端对数据进行访问的频率。 OSD的逻辑结构根据定义，OSD可以被抽象为两个组成部分，即系统部分和守护进程（OSD deamon）部分。 OSD的系统部分本质上就是一台安装了操作系统和文件系统的计算机，其硬件部分至少包括一个单核的处理器、一定数量的内存、一块硬盘以及一张网卡。 由于这么小规模的x86架构服务器并不实用（事实上也见不到），因而实际应用中通常将多个OSD集中部署在一台更大规模的服务器上。在选择系统配置时，应当 能够保证每个OSD占用一定的计算能力、一定量的内存和一块硬盘。同时，应当保证该服务器具备足够的网络带宽。具体的硬件配置选择可以参考。 在 上述系统平台上，每个OSD拥有一个自己的OSD deamon。这个deamon负责完成OSD的所有逻辑功能，包括与monitor和其他OSD（事实上是其他OSD的deamon）通信以维护更新系 统状态，与其他OSD共同完成数据的存储和维护，与client通信完成各种数据对象操作等等。 Ceph系统的逻辑结构就介绍到这里。下篇文章将着重说明Ceph（主要是RADOS）的工作原理和操作流程。 如图所示，RADOS集群主要由两种节点组成。一种是为数众多的、负责完成数据存储和维护功能的OSD（Object Storage Device），另一种则是若干个负责完成系统状态检测和维护的monitor。OSD和monitor之间相互传输节点状态信息，共同得出系统的总体工 作状态，并形成一个全局系统状态记录数据结构，即所谓的cluster map。这个数据结构与RADOS提供的特定算法相配合，便实现了Ceph“无需查表，算算就好”的核心机制以及若干优秀特性。 Ceph的工作原理及流程本节将对Ceph的工作原理和若干关键工作流程进行扼要介绍。如前所述，由于Ceph的功能实现本质上依托于RADOS，因而，此处的介绍事实上也是针对RADOS进行。对于上层的部分，特别是RADOS GW和RBD，由于现有的文档中（包括Sage的论文中）并未详细介绍，还请读者多多包涵。 首先介绍RADOS中最为核心的、基于计算的对象寻址机制，然后说明对象存取的工作流程，之后介绍RADOS集群维护的工作过程，最后结合Ceph的结构和原理对其技术优势加以回顾和剖析。 寻址流程Ceph系统中的寻址流程如下图所示： 上图左侧的几个概念说明如下： File – 此处的file就是用户需要存储或者访问的文件。对于一个基于Ceph开发的对象存储应用而言，这个file也就对应于应用中的“对象”，也就是用户直接操作的“对象”。 Ojbect—— 此处的object是RADOS所看到的“对象”。Object与上面提到的file的区别是，object的最大size由RADOS限定（通常为2MB或4MB），以便实现底层存储的组织管理。因此，当上层应用向RADOS存入size很大的file时，需要将file切分成统一大小的一系列object（最后一个的大小可以不同）进行存储。为避免混淆，在本文中将尽量避免使用中文的“对象”这一名词，而直接使用file或object进行说明。 PG（Placement Group）—— 顾名思义，PG的用途是对object的存储进行组织和位置映射。具体而言，一个PG负责组织若干个object（可以为数千个甚至更多），但一个object只能被映射到一个PG中，即，PG和object之间是“一对多”映射关系。同时，一个PG会被映射到n个OSD上，而每个OSD上都会承载大量的PG，即，PG和OSD之间是“多对多”映射关系。在实践当中，n至少为2，如果用于生产环境，则至少为3。一个OSD上的PG则可达到数百个。事实上，PG数量的设置牵扯到数据分布的均匀性问题。关于这一点，下文还将有所展开。 OSD—— 即object storage device，前文已经详细介绍，此处不再展开。唯一需要说明的是，OSD的数量事实上也关系到系统的数据分布均匀性，因此其数量不应太少。在实践当中，至少也应该是数十上百个的量级才有助于Ceph系统的设计发挥其应有的优势。 Failure domain—— 这个概念在论文中并没有进行定义，好在对分布式存储系统有一定概念的读者应该能够了解其大意。 基于上述定义，便可以对寻址流程进行解释了。具体而言， Ceph中的寻址至少要经历以下三次映射。 三次映射：1. File -&gt; object映射这次映射的目的是，将用户要操作的file，映射为RADOS能够处理的object。其映射十分简单，本质上就是按照object的最大size对file进行切分，相当于RAID中的条带化过程。这种切分的好处有二：一是让大小不限的file变成最大size一致、可以被RADOS高效管理的object；二是让对单一file实施的串行处理变为对多个object实施的并行化处理。 每一个切分后产生的object将获得唯一的oid，即object id。其产生方式也是线性映射，极其简单。图中，ino是待操作file的元数据，可以简单理解为该file的唯一id。ono则是由该file切分产生的某个object的序号。而oid就是将这个序号简单连缀在该file id之后得到的。举例而言，如果一个id为filename的file被切分成了三个object，则其object序号依次为0、1和2，而最终得到的oid就依次为filename0、filename1和filename2。 这里隐含的问题是，ino的唯一性必须得到保证，否则后续映射无法正确进行。 2. Object -&gt; PG映射在file被映射为一个或多个object之后，就需要将每个object独立地映射到一个PG中去。这个映射过程也很简单，如图中所示，其计算公式是： 1hash(oid) &amp; mask -&gt; pgid 由此可见，其计算由两步组成。首先是使用Ceph系统指定的一个静态哈希函数计算oid的哈希值，将oid映射成为一个近似均匀分布的伪随机值。然后，将这个伪随机值和mask按位相与，得到最终的PG序号（pgid）。根据RADOS的设计，给定PG的总数为m（m应该为2的整数幂），则mask的值为m-1。因此，哈希值计算和按位与操作的整体结果事实上是从所有m个PG中近似均匀地随机选择一个。基于这一机制，当有大量object和大量PG时，RADOS能够保证object和PG之间的近似均匀映射。又因为object是由file切分而来，大部分object的size相同，因而，这一映射最终保证了，各个PG中存储的object的总数据量近似均匀。 从介绍不难看出，这里反复强调了 “大量”。只有当object和PG的数量较多时，这种伪随机关系的近似均匀性才能成立，Ceph的数据存储均匀性才有保证。为保证“大量”的成立，一方面，object的最大size应该被合理配置，以使得同样数量的file能够被切分成更多的object；另一方面，Ceph也推荐PG总数应该为OSD总数的数百倍，以保证有足够数量的PG可供映射。 3. PG -&gt; OSD映射第三次映射就是将作为object的逻辑组织单元的PG映射到数据的实际存储单元OSD。如图所示，RADOS采用一个名为 CRUSH 的算法，将pgid代入其中，然后得到一组共n个OSD。这n个OSD即共同负责存储和维护一个PG中的所有object。前已述及，n的数值可以根据实际应用中对于可靠性的需求而配置，在生产环境下通常为3。具体到每个OSD，则由其上运行的OSD deamon负责执行映射到本地的object在本地文件系统中的存储、访问、元数据维护等操作。 和“object -&gt; PG”映射中采用的哈希算法不同，这个 CRUSH算法的结果不是绝对不变的 ，而是受到其他因素的影响。 其影响因素主要有二： 一是 当前系统状态，也就是上文逻辑结构中曾经提及的cluster map。当系统中的OSD状态、数量发生变化时，cluster map可能发生变化，而这种变化将会影响到PG与OSD之间的映射。 二是 存储策略配置。这里的策略主要与安全相关。利用策略配置，系统管理员可以指定承载同一个PG的3个OSD分别位于数据中心的不同服务器乃至机架上，从而进一步改善存储的可靠性。 因此，只有在系统状态（cluster map）和存储策略都不发生变化的时候，PG和OSD之间的映射关系才是固定不变的。 在实际使用当中，策略一经配置通常不会改变。而系统状态的改变或者是由于设备损坏，或者是因为存储集群规模扩大。好在Ceph本身提供了对于这种变化的自动化支持，因而，即便PG与OSD之间的映射关系发生了变化，也并不会对应用造成困扰。 事实上，Ceph正是需要有目的的利用这种动态映射关系。正是利用了CRUSH的动态特性，Ceph可以将一个PG根据需要动态迁移到不同的OSD组合上，从而自动化地实现高可靠性、数据分布re-blancing等特性。 之所以在此次映射中使用CRUSH算法，而不是其他哈希算法，原因之一正是CRUSH具有上述可配置特性，可以根据管理员的配置参数决定OSD的物理位置映射策略；另一方面是因为CRUSH具有特殊的“稳定性”，也即，当系统中加入新的OSD，导致系统规模增大时，大部分PG与OSD之间的映射关系不会发生改变，只有少部分PG的映射关系会发生变化并引发数据迁移。这种可配置性和稳定性都不是普通哈希算法所能提供的。因此，CRUSH算法的设计也是Ceph的核心内容之一，具体介绍可以参考另一篇文章。 至此为止，Ceph通过三次映射，完成了从file到object、PG和OSD整个映射过程。通观整个过程，可以看到，这里没有任何的全局性查表操作需求。 至于唯一的全局性数据结构cluster map，在后文中将加以介绍。可以在这里指明的是，cluster map的维护和操作都是轻量级的，不会对系统的可扩展性、性能等因素造成不良影响。 一个可能出现的困惑是：为什么需要同时设计第二次和第三次映射？难道不重复么？关于这一点，Sage在其论文中解说不多，而笔者个人的分析如下： 我们可以反过来想像一下，如果没有PG这一层映射，又会怎么样呢？在这种情况下，一定需要采用某种算法，将object直接映射到一组OSD上。如果这种算法是某种固定映射的哈希算法，则意味着一个object将被固定映射在一组OSD上，当其中一个或多个OSD损坏时，object无法被自动迁移至其他OSD上（因为映射函数不允许），当系统为了扩容新增了OSD时，object也无法被re-balance到新的OSD上（同样因为映射函数不允许）。 这些限制都违背了Ceph系统高可靠性、高自动化的设计初衷。 如果采用一个动态算法（例如仍然采用CRUSH算法）来完成这一映射，似乎是可以避免静态映射导致的问题。但是，其结果将是各个OSD所处理的本地元数据量爆增，由此带来的计算复杂度和维护工作量也是难以承受的。 例如，在Ceph的现有机制中，一个OSD平时需要和与其共同承载同一个PG的其他OSD交换信息，以确定各自是否工作正常，是否需要进行维护操作。由于一个OSD上大约承载数百个PG，每个PG内通常有3个OSD，因此，一段时间内，一个OSD大约需要进行数百至数千次OSD信息交换。 然而，如果没有PG的存在，则一个OSD需要和与其共同承载同一个object的其他OSD交换信息。 由于每个OSD上承载的object很可能高达数百万个，因此，同样长度的一段时间内，一个OSD大约需要进行的OSD间 信息交换将暴涨至数百万乃至数千万次。 而这种状态维护成本显然过高。 综上所述，笔者认为，引入PG的好处至少有二：一方面实现了object和OSD之间的动态映射，从而为Ceph的可靠性、自动化等特性的实现留下了空间；另一方面也有效简化了数据的存储组织，大大降低了系统的维护管理开销。理解这一点，对于彻底理解Ceph的对象寻址机制，是十分重要的。 数据操作流程此处将首先以file写入过程为例，对数据操作流程进行说明。 为简化说明，便于理解，此处进行若干假定。首先，假定待写入的file较小，无需切分，仅被映射为一个object。其次，假定系统中一个PG被映射到3个OSD上。 基于上述假定，则file写入流程可以被下图表示： 如图所示，当某个client需要向Ceph集群写入一个file时，首先需要在本地完成前边所叙述的寻址流程， 将file变为一个object，然后 找出存储该object的一组三个OSD。 这三个OSD具有各自不同的序号，序号最靠前的那个OSD就是这一组中的Primary OSD，而后两个则依次是Secondary OSD和Tertiary OSD。 找出三个OSD后，client将直接和Primary OSD通信，发起写入操作（步骤1）。Primary OSD收到请求后，分别向Secondary OSD和Tertiary OSD发起写入操作（步骤2、3）。当Secondary OSD和Tertiary OSD各自完成写入操作后，将分别向Primary OSD发送确认信息（步骤4、5）。 当Primary OSD确信其他两个OSD的写入完成后，则自己也完成数据写入，并向client确认object写入操作完成（步骤6）。 之所以采用这样的写入流程，本质上是为了保证写入过程中的可靠性，尽可能避免造成数据丢失。同时，由于client只需要向Primary OSD发送数据，因此，在Internet使用场景下的外网带宽和整体访问延迟又得到了一定程度的优化。 当然，这种可靠性机制必然导致较长的延迟，特别是，如果等到所有的OSD都将数据写入磁盘后再向client发送确认信号，则整体延迟可能难以忍受。因此，Ceph可以分两次向client进行确认。 当各个OSD都将数据写入内存缓冲区后，就先向client发送一次确认，此时client即可以向下执行。待各个OSD都将数据写入磁盘后，会向client发送一个最终确认信号，此时client可以根据需要删除本地数据。 分析上述流程可以看出，在正常情况下，client可以独立完成OSD寻址操作，而不必依赖于其他系统模块。因此，大量的client可以同时和大量的OSD进行并行操作。同时，如果一个file被切分成多个object，这多个object也可被并行发送至多个OSD。 从OSD的角度来看，由于同一个OSD在不同的PG中的角色不同，因此，其工作压力也可以被尽可能均匀地分担，从而避免单个OSD变成性能瓶颈。 如果需要读取数据，client只需完成同样的寻址过程，并直接和Primary OSD联系。目前的Ceph设计中，被读取的数据仅由Primary OSD提供。但目前也有分散读取压力以提高性能的讨论。 集群维护前面的介绍中已经提到，由若干个monitor共同负责整个Ceph集群中所有OSD状态的发现与记录，并且共同形成cluster map的master版本，然后扩散至全体OSD以及client。OSD使用cluster map进行数据的维护，而client使用cluster map进行数据的寻址。 在集群中，各个monitor的功能总体上是一样的，其相互间的关系可以被简单理解为主从备份关系。因此，在下面的讨论中不对各个monitor加以区分。 略显出乎意料的是，monitor并不主动轮询各个OSD的当前状态。正相反，OSD需要向monitor上报状态信息。 常见的上报有两种情况：一是新的OSD被加入集群，二是某个OSD发现自身或者其他OSD发生异常。在收到这些上报信息后，monitor将更新cluster map信息并加以扩散。其细节将在下文中加以介绍。 Cluster map的实际内容包括（1） Epoch，即版本号Cluster map的epoch是一个单调递增序列。Epoch越大，则cluster map版本越新。因此，持有不同版本cluster map的OSD或client可以简单地通过比较epoch决定应该遵从谁手中的版本。而monitor手中必定有epoch最大、版本最新的cluster map。当任意两方在通信时发现彼此epoch值不同时，将默认先将cluster map同步至高版本一方的状态，再进行后续操作。 （2）各个OSD的网络地址（3）各个OSD的状态OSD状态的描述分为两个维度：up或者down（表明OSD是否正常工作），in或者out（表明OSD是否在至少一个PG中）。因此，对于任意一个OSD，共有四种可能的状态： Up且in：说明该OSD正常运行，且已经承载至少一个PG的数据。这是一个OSD的标准工作状态； Up且out：说明该OSD正常运行，但并未承载任何PG，其中也没有数据。一个新的OSD刚刚被加入Ceph集群后，便会处于这一状态。而一个出现故障的OSD被修复后，重新加入Ceph集群时，也是处于这一状态； Down且in：说明该OSD发生异常，但仍然承载着至少一个PG，其中仍然存储着数据。这种状态下的OSD刚刚被发现存在异常，可能仍能恢复正常，也可能会彻底无法工作； Down且out：说明该OSD已经彻底发生故障，且已经不再承载任何PG。 （4）CRUSH算法配置参数CRUSH算法根据种每个设备的权重尽可能概率平均地分配数据。参数有两个，一 表明了Ceph集群的物理层级关系（cluster hierarchy），二 位置映射规则（placement rules）。 情景复现根据cluster map的定义可以看出，其版本变化通常只会由（3）和（4）两项信息的变化触发。而这两者相比，（3）发生变化的概率更高一些。这可以通过下面对OSD工作状态变化过程的介绍加以反映。 新OSD上线一个新的OSD上线后，首先根据配置信息与monitor通信。Monitor将其加入cluster map，并设置为up且out状态，再将最新版本的cluster map发给这个新OSD。 收到monitor发来的cluster map之后，这个新OSD计算出自己所承载的PG（为简化讨论，此处我们假定这个新的OSD开始只承载一个PG），以及和自己承载同一个PG的其他OSD。然后，新OSD将与这些OSD取得联系。如果这个PG目前处于降级状态 （即承载该PG的OSD个数少于正常值，如正常应该是3个，此时只有2个或1个。这种情况通常是OSD故障所致），则其他OSD将把这个PG内的所有对象和元数据复制给新OSD。 数据复制完成后，新OSD被置为up且in状态。而cluster map内容也将据此更新。这事实上是一个自动化的failure recovery过程。当然，即便没有新的OSD加入，降级的PG也将计算出其他OSD实现failure recovery。 如果该PG目前一切正常，则这个新OSD将替换掉现有OSD中的一个（PG内将重新选出Primary OSD），并承担其数据。 在数据复制完成后，新OSD被置为up且in状态，而被替换的OSD将退出该PG（但状态通常仍然为up且in，因为还要承载其他PG）。而cluster map内容也将据此更新。这事实上是一个自动化的数据re-balancing过程。 OSD异常如果一个OSD发现和自己共同承载一个PG的另一个OSD无法联通，则会将这一情况 上报 monitor。此外，如果一个OSD deamon发现自身工作状态异常，也将把异常情况主动 上报 报给monitor。 在上述情况下，monitor将把出现问题的OSD的状态设为down且in。如果超过某一预订时间期限，该OSD仍然无法恢复正常，则其状态将被设置为down且out。反之，如果该OSD能够恢复正常，则其状态会恢复为up且in。在上述这些状态变化发生之后，monitor都将更新cluster map并进行扩散。这事实上是自动化的failure detection过程。 cluster map 小结由之前介绍可以看出，对于一个Ceph集群而言，即便由数千个甚至更多OSD组成，cluster map的数据结构大小也并不惊人。同时，cluster map的状态更新并不会频繁发生。即便如此，Ceph依然对cluster map信息的扩散机制进行了优化，以便减轻相关计算和通信压力。 首先，cluster map信息是以增量形式扩散的。如果任意一次通信的双方发现其epoch不一致，则版本更新的一方将把二者所拥有的cluster map的差异发送给另外一方。 其次，cluster map信息是以异步且lazy的形式扩散的。也即，monitor并不会在每一次cluster map版本更新后都将新版本广播至全体OSD，而是在有OSD向自己上报信息时，将更新回复给对方。类似的，各个OSD也是在和其他OSD通信时，将更新发送给版本低于自己的对方。 基于上述机制，Ceph避免了由于cluster map版本更新而引起的广播风暴。这虽然是一种异步且lazy的机制，但根据Sage论文中的结论，对于一个由n个OSD组成的Ceph集群，任何一次版本更新能够在O(log(n))时间复杂度内扩散到集群中的任何一个OSD上。 一个可能被问到的问题是： 既然这是一种异步和lazy的扩散机制，则在版本扩散过程中，系统必定出现各个OSD看到的cluster map不一致的情况，这是否会导致问题？ 答案是：不会。 事实上，如果一个client和它要访问的PG内部的各个OSD看到的cluster map状态一致，则访问操作就可以正确进行。而如果这个client或者PG中的某个OSD和其他几方的cluster map不一致，则根据Ceph的机制设计，这几方将首先同步cluster map至最新状态，并进行必要的数据re-balancing操作，然后即可继续正常访问。 小结通过上述介绍，我们可以简要了解Ceph究竟是如果基于cluster map机制，并由monitor、OSD和client共同配合完成集群状态的维护与数据访问的。特别的，基于这个机制，事实上可以自然而然的完成自动化的数据备份、数据re-balancing、故障探测和故障恢复，并不需要复杂的特殊设计。这一点确实让人印象深刻。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>分布式</tag>
        <tag>原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ceph跨域问题]]></title>
    <url>%2Fceph-cros%2F</url>
    <content type="text"><![CDATA[解决Ceph跨域问题 https://help.dreamhost.com/hc/en-us/articles/216201557-How-to-setup-Cross-Origin-Resource-Sharing-CORS-on-DreamObjects 现象：edu.valsun.cn 里js访问ceph对象存储 http://ceph.valsun.cn/EDU/p/course/20180313/1-0f1e2da9cbf438d03c2dba050220ff77.m3u8 报如下错误 1Failed to load http://ceph.valsun.cn/EDU/p/course/20180313/1-0f1e2da9cbf438d03c2dba050220ff77.m3u8: No &apos;Access-Control-Allow-Origin&apos; header is present on the requested resource. Origin &apos; http://edu.valsun.cn&apos; is therefore not allowed access. 修改ceph.conf配置文件123cd my-cluster/vim ceph.confrgw_dns_name = ceph.valsun.cn 覆盖各个节点配置1ceph-deploy --overwrite-conf config push openstack-nova29 openstack-nova30 在各自节点重启rgw服务123systemctl restart ceph-radosgw@rgw.openstack-nova28.servicesystemctl restart ceph-radosgw@rgw.openstack-nova29.servicesystemctl restart ceph-radosgw@rgw.openstack-nova30.service 给s3存储桶设置CORS规则写 CORS 规则123456789101112131415[root@openstack-nova28 ~]# cat rules.xml &lt;CORSConfiguration&gt;&lt;CORSRule&gt; &lt;ID&gt;Allow everything&lt;/ID&gt; &lt;AllowedOrigin&gt;http://edu.valsun.cn&lt;/AllowedOrigin&gt; &lt;AllowedMethod&gt;GET&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;HEAD&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;PUT&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;POST&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;DELETE&lt;/AllowedMethod&gt; &lt;AllowedHeader&gt;*&lt;/AllowedHeader&gt; &lt;MaxAgeSeconds&gt;30&lt;/MaxAgeSeconds&gt;&lt;/CORSRule&gt;&lt;/CORSConfiguration&gt; 给对应的存储桶设置cors规则12s3cmd setcors rules.xml s3://EDUs3cmd info s3://EDU #查看规则 我的nginx转发代理配置server_name 填写和rgw_dns_name 一致 再次访问，问题解决]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>跨域</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ceph踩坑指南]]></title>
    <url>%2Fceph-problems%2F</url>
    <content type="text"><![CDATA[Ceph踩坑指南环境：机器：centos 7.5 ceph Luminous版本 源：阿里云 ceph-deploy new node问题： 123456Traceback (most recent call last): File &quot;/usr/bin/ceph-deploy&quot;, line 18, in &lt;module&gt; from ceph_deploy.cli import main File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/cli.py&quot;, line 1, in &lt;module&gt; import pkg_resourcesImportError: No module named pkg_resources 解决办法： python 版本问题 ，注意检查系统的python版本，此处ceph-deploy实则为通过执行python脚本来实现安装， 更改/usr/bin/ceph-deploy文件中 更改python2.6的部分为2.7（此处应当与系统python版本相同） 更改第一行文件为 #！/usr/bin/python2.7 重新执行ceph-deploy new即可 ceph-deploy disk zap node12:sdb问题： 1[ceph_deploy][ERROR ] RuntimeError: zap command needs both HOSTNAME and DISK but got &quot;None node12:sdb&quot; 解决办法： 12# 注意中间是空格，一个是名称，一个是设备ceph-deploy disk zap node12 /dev/sdb ceph-deploy disk list node12问题： 123456789101112[ceph_deploy][ERROR ] Traceback (most recent call last):[ceph_deploy][ERROR ] File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/util/decorators.py&quot;, line 69, in newfunc[ceph_deploy][ERROR ] return f(*a, **kw)[ceph_deploy][ERROR ] File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/cli.py&quot;, line 164, in _main[ceph_deploy][ERROR ] return args.func(args)[ceph_deploy][ERROR ] File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/osd.py&quot;, line 434, in disk[ceph_deploy][ERROR ] disk_list(args, cfg)[ceph_deploy][ERROR ] File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/osd.py&quot;, line 376, in disk_list[ceph_deploy][ERROR ] distro.conn.logger(line)[ceph_deploy][ERROR ] TypeError: &apos;Logger&apos; object is not callable[ceph_deploy][ERROR ] 解决办法： 待解决 这个是为了查看当前所有空闲盘用的，当拟清楚所有盘的情况时可以不执行。 [root@node12 my-cluster]# ceph-deploy disk zap node12 /dev/sdb问题： 1234567891011[ceph_deploy][ERROR ] Traceback (most recent call last):[ceph_deploy][ERROR ] File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/util/decorators.py&quot;, line 69, in newfunc[ceph_deploy][ERROR ] return f(*a, **kw)[ceph_deploy][ERROR ] File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/cli.py&quot;, line 164, in _main[ceph_deploy][ERROR ] return args.func(args)[ceph_deploy][ERROR ] File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/osd.py&quot;, line 438, in disk[ceph_deploy][ERROR ] disk_zap(args)[ceph_deploy][ERROR ] File &quot;/usr/lib/python2.7/site-packages/ceph_deploy/osd.py&quot;, line 336, in disk_zap[ceph_deploy][ERROR ] if args.debug:[ceph_deploy][ERROR ] AttributeError: &apos;Namespace&apos; object has no attribute &apos;debug&apos;[ceph_deploy][ERROR ] 解决： 123456vim /usr/lib/python2.7/site-packages/ceph_deploy/osd.py # 修改第336行为 #if args.debug: if False: ceph-deploy –overwrite-conf osd create node231:vdb问题： 1[ceph_deploy][ERROR ] NeedDiskError: Must supply disk/path argument: node12:sdb 解决： 在ceph luminous中创建bluestore的过程为指定data，block-db，block-wal 例如执行 12345# 数据日志存在不同的盘符ceph-deploy osd create node1 --data /dev/sde --block-db /dev/sdf1 --block-wal /dev/sdf2# 省略db 与wal的说明，只指定data则为 (创建于同一个盘)ceph-deploy osd create node1 --data /dev/sdb ceph -s问题： 12health: HEALTH_WARN no active mgr 解决： Ceph Manager Daemon，简称ceph-mgr。 该组件的主要作用是分担和扩展monitor的部分功能，减轻monitor的负担，让更好地管理ceph存储系统ceph ceph在 luminous中新加入了mgr功能模块，手动安装mgr即可 1ceph-deploy mgr create node01 node02 node03 crush rule 常用命令记录12345ceph osd getcrushmap -o /tmp/crush crushtool -d /tmp/crush -o /tmp/crush.txtcrushtool -c /tmp/crush.txt -o /tmp/crush.binceph osd setcrushmap -i /tmp/crush.bin]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>分布式</tag>
        <tag>踩坑指南</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式存储概览]]></title>
    <url>%2Fstorage-distributed%2F</url>
    <content type="text"><![CDATA[存储系统对比目前比较热门的分布式文件系统有如下几种:Ceph，GlusterFS,Sheepdog,Lustre,Swift,Cinder,TFS,HDFS,MooseFS,FastDFS,MogileFS等 –开源协议说明 GPL:不允许修改后和衍生的代码做为闭源的商业软件发布和销售，修改后该软件产品必须也采用GPL协议； GPL V2：修改文本的整体就必须按照GPL流通，不仅该修改文本的源码必须向社会公开，而且对于这种修改文本的流通不准许附加修改者自己作出的限制; GPL V3：要求用户公布修改的源代码，还要求公布相关硬件; LGPL：更宽松的GPL 存储系统 Ceph GlusterFS Sheepdog Lustre Swift Cinder TFS HDFS MooseFS FastDFS MogileFS 开发语言 C++ C C C Python Python C++ Java C C Perl 开源协议 LGPL GPL V3 GPLv2 GPL Apache Apache GPL V2 Apache GPL 数据存储方式 对象/文件/块 文件/块 块 对象 对象 块 文件 文件 块 文件/ 文件 集群节点通信协议 私有协议（TCP 私有协议（TCP）/ RDAM(远程直接访问内存) totem协议 私有协议（TCP）/ RDAM(远程直接访问内存) TCP 未知 TCP TCP TCP TCP HTTP 专用元数据存储点 占用MDS 无 无 双MDS 无 未知 占用NS 占用MDS 占用MFS 无 占用DB 在线扩容 支持 支持 支持 支持 支持 未知 支持 支持 支持 支持 支持 冗余备份 支持 支持 支持 无 支持 未知 支持 支持 支持 支 不支持 单点故障 存在 不存在 不存在 存在 不存在 未知 存在 存在 存在 不存在 存在 跨集群同步 不支持 支持 未知 未知 未知 未知 支持 不支持 不支持 部分支持 不支持 易用性 安装简单，官方文档专业化 安装简单，官方文档专业化 未知 复杂。而且Lustre严重依赖内核，需要重新编译内核 未知 目前来说框架不算成熟存在一些问题 安装复杂，官方文档少 安装简单，官方文档专业化 安装简单，官方文档 安装简单，社区相对活跃 未知 适用场景 单集群的大中小文件 跨集群云存储 弹性块存储虚拟机 大文件读写 openstack对象存储 openstack块存储 跨集群的小文件 Mapreduce使用的文件存储 单集群的大中文件 单集群的中小文件 未知 FUSE挂载 支持 支持 支持 支持 支持 未知 未知 支持 支持 不支持 不支持 访问接口 POSIX POSIX 未知 POSIX/MPI POSIX 未知 不支持POSIX 不支持POSIX POSIX 不支持POSIX 不支持POSIX]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS安装使用]]></title>
    <url>%2Fstorage-NFS%2F</url>
    <content type="text"><![CDATA[NFS安装使用NFS 是 Network File System 的缩写，即网络文件系统。他最大的功能就是可以透过网络，让不同的机器、不同的操作系统、可以彼此分享个别的档案(share file) ，所以，也可以简单的将他看做是一个file server呢！ 这个NFS Server可以让你的PC来将网络远程的NFS主机分享的目录，挂载到本地端的机器当中，所以，在本地端的机器看起来，那个远程主机的目录就好象是自己的partition一般！ NFS有属于自己的协议与使用的端口号，但是在资料传送或者其它相关讯息传递的时候，NFS使用的则是一个称为远程过程调用(Remote Procedure Call, RPC)的协议来协助NFS本身的运作！ RPC?因为NFS支持的功能很多，而不同的功能都会使用不同的程序来启动，每启动一个功能就会启用一些端口来传输数据，应此，NFS的功能所对应的端口是无法固定的，二是随机取用一些违背使用的端口来作为传输工具，其中Centos5X随机端口小于1024的，而Centos6X都是比较大的。 因为端口不固定，这样一来就会造成NFS客户端与NFS服务端的通讯障碍，运维NFS客户端必须要知道NFS服务器端的数据传输端口才能进行通讯交互数据。 要解决上面的通讯问题困扰，就需要远程调用RPC服务来帮忙了，NFS的RPC服务最主要的功能就是记录每个NFS功能所对应的端口号 ，并且在NFS客户端请求时将该端口和功能对应的信息传递给请求数据的NFS客户端，从而可以确保客户端可以连接到正确的NFS端口上去，达到实现数据传输交互数据目的，这个RPC服务很类似NFS服务端和NFS客户端之间的一个中介。 NFS的RPC服务在CentOS5.x下名称为portmap，在CentOS6.x下名称为rocbind（rpcbind监听端口111） 应用场景A,B,C三台机器上需要保证被访问到的文件是一样的，A共享数据出来，B和C分别去挂载A共享的数据目录，从而B和C访问到的数据和A上的一致 举例：假如有三台机器A, B, C，它们需要访问同一个目录，目录中都是图片，传统的做法是把这些图片分别放到A, B, C. 但是使用NFS只需要放到A上，然后A共享给B和C即可，B和C把A共享的目录放在本地，这个动作叫做挂载。访问的时候，B和C是通过网络的方式去访问A上的那个目录的。其主要特点就是允许一个系统和网络上的他人共享目录和文件。 – 安装使用NFS配置文件 NFS常用路径 说明 /etc/exports NFS服务主配置文件，配置NFS具体共享服务的地点，默认内容为空 /usr/sbin/exportfs NFS的管理命令，下边会介绍 /usr/sbin/showmount 常用来在客户端，查看NFS配置及共享目录的情况 /var/lib/nfs/etab NFS配置文件的完整参数设定的文件（有很多没有配置单默认就有的参数） showmount命令语法：showmount [-ae] hostname 参数： 参数 说明 -a 显示目前主机与client所连上来的使用目录的状态 -e 显示hostname的/etc/exports里面共享的目录 exportfs命令如果我们修改了/etc/exports后，并不需要重启nfs服务，只要用exportfs重新扫描一次/etc/exports，并且重新加载即可。 语法:exportfs [-aruv] 参数： 参数 说明 -a 全部挂载(或卸载) /etc/exports档案内的设定 -r 重新挂载/etc/exports里面的设定 -u 卸载某一目录 -v 在export的时候，将分享的目录显示到荧屏上 例子： 12# exportfs卸载所有的共享目录[root@ansheng ~]# exportfs -au nfs 配置选项123456789101112131415rw 读写 ro 只读 sync 同步模式，内存数据实时写入磁盘 async 非同步模式 ，把内存总数据定期写入磁盘no_root_squash 客户端挂载NFS共享目录后，root用户不受约束，权限很大 ，不安全，不建议使用root_squash 与上面选项相对，客户端上的root用户受到约束，被限定成某个普通用户 all_squash 客户端上所有用户在使用NFS共享目录时都被限定为一个普通用户 anonuid/anongid 和上面几个选项搭配使用，定义被限定用户的uid和gid 客户端IP地址 客户端地址 具体地址例子 说明 授权单一客户访问NFS 10.0.0.30 一般情况，生产环境中此配置不多 授权整个网段可访问NFS 10.0.0.0/24 其中的24等于255.255.255.0，制定瓦工段为生产环境中最常见的配置。配置简单，维护方便 授权整个网段可访问NFS 10.0.0.* 指定网段的另外写法（需要验证） 授权某个域名客户端访问NFS Nfs.oldboy.cc 此方法生产环境中一般情况不常用 授权某个域名客户端访问NFS *.oldboy.cc 此方法生产环境中一般情况不常用 配置NFS生产重要技巧 确保所有服务器对NFS共享目录具备相同的权限。 all_squash把所有客户端都压缩成匿名用户 就是anonuid,anongid制定的UID和GID的用户。 所有的客户端和服务端都需要有一个相同的UID和GID的用户，即nfsnodoby(UID必须相同)，如果客户端没有服务端指定的用户则创建文件时客户端会显示nfsnodoby这个用户，服务端则显示自己设置的用户； 服务端步骤 1: 服务端安装使用 yum 安装 NFS 安装包。 1$ sudo yum install nfs-utils 注意:只安装 nfs-utils 即可，rpcbind 属于它的依赖，也会安装上。 步骤 2: 服务端配置1234567891011121314151617# 设置 NFS 服务开机启动$ sudo systemctl enable rpcbind$ sudo systemctl enable nfs# 启动 NFS 服务$ sudo systemctl start rpcbind$ sudo systemctl start nfs# 防火墙需要打开 rpc-bind 和 nfs 的服务$ sudo firewall-cmd --zone=public --permanent --add-service=rpc-bindsuccess$ sudo firewall-cmd --zone=public --permanent --add-service=mountdsuccess$ sudo firewall-cmd --zone=public --permanent --add-service=nfssuccess$ sudo firewall-cmd --reloadsuccess 步骤 3: 配置共享目录服务启动之后，我们在服务端配置一个共享目录 12$ sudo mkdir /data$ sudo chmod 755 /data 根据这个目录，相应配置导出目录 1234$ sudo vi /etc/exports添加如下配置/data/ 192.168.0.0/24(rw,sync,no_root_squash,no_all_squash) /data: 共享目录位置。 192.168.0.0/24: 客户端 IP 范围，* 代表所有，即没有限制。 rw: 权限设置，可读可写。 sync: 同步共享目录。 no_root_squash: 可以使用 root 授权。 no_all_squash: 可以使用普通用户授权。 1234567# 重启以下服务$ sudo systemctl restart nfs# 可以检查一下本地的共享目录$ showmount -e localhostExport list for localhost:/data 192.168.0.0/24 这样，服务端就配置好了，接下来配置客户端，连接服务端，使用共享目录。 客户端步骤 1: 客户端安装12# 与服务端类似$ sudo yum install nfs-utils 步骤 2: 客户端配置12345# 设置 rpcbind 服务的开机启动$ sudo systemctl enable rpcbind# 启动 rpcbind 服务$ sudo systemctl start rpcbind 注意: 客户端不需要打开防火墙，因为客户端时发出请求方，网络能连接到服务端即可。 客户端也不需要开启 NFS 服务，因为不共享目录。 步骤 3: 客户端连接 NFS1234567891011121314151617181920#先查服务端的共享目录$ showmount -e 192.168.0.101Export list for 192.168.0.101:/data 192.168.0.0/24# 在客户端创建目录$ sudo mkdir /data# 挂载$ sudo mount -t nfs 192.168.0.101:/data /data# 挂载之后，可以使用 mount 命令查看一下$ mount......192.168.0.101:/data on /data type nfs4 (rw,relatime,sync,vers=4.1,rsize=131072,wsize=131072,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=192.168.0.100,local_lock=none,addr=192.168.0.101)# 这说明已经挂载成功了。或者使用 df -h 也可以查看挂载的目录 步骤 5: 测试 NFS测试一下，在客户端向共享目录创建一个文件 123456789$ cd /data$ sudo touch a#之后取 NFS 服务端 192.168.0.101 查看一下$ cd /data$ lltotal 0-rw-r--r--. 1 root root 0 Aug 8 18:46 a# 可以看到，共享目录已经写入了。 步骤 6: 客户端自动挂载自动挂载很常用，客户端设置一下即可。 123456789101112131415# 在结尾添加类似如下配置$ sudo vi /etc/fstab## /etc/fstab# Created by anaconda on Thu May 25 13:11:52 2017## Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/cl-root / xfs defaults 0 0UUID=414ee961-c1cb-4715-b321-241dbe2e9a32 /boot xfs defaults 0 0/dev/mapper/cl-home /home xfs defaults 0 0/dev/mapper/cl-swap swap swap defaults 0 0192.168.0.101:/data /data nfs defaults 0 0 由于修改了 /etc/fstab，需要重新加载 systemctl。 12345678# 重新加载$ sudo systemctl daemon-reload# 之后查看一下$ mount......192.168.0.101:/data on /data type nfs4 (rw,relatime,vers=4.1,rsize=131072,wsize=131072,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=192.168.0.100,local_lock=none,addr=192.168.0.101) 此时已经启动好了。如果实在不放心，可以重启一下客户端的操作系统，之后再查看一下。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R740服务器装Centos7.6步骤图]]></title>
    <url>%2Fserver-R740-Centos%2F</url>
    <content type="text"><![CDATA[Dell R740服务器安装 Centos 7.6 步骤其实服务器安装系统和虚拟机安装系统没什么太多的不同，注意我前边的文章《服务器装系统注意事项》中说的内容就好了。 开机后按 F11 进入BootManager，选择 One-shot UEFI Boot Menu 选择带有USB的选项，从U盘启动 进入安装界面，光标移到第一个Install Centos 7 然后有两种做法 4.1 按Tab键 按下TAB后，你会看到 1vmlinuz initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 rd.live.check quiet 把LABEL=CentOS\x207\x20x86_64修改一下改成你修改后的卷标。然后 按回车，稍等一会进入第 5 步。 4.2 第3步完成后 按e 将hd:LABEL=CentOS\x207\x20x86_64 quiet 删除一部分，改成hd:LABEL=CentOS quiet inst.gpt 按Ctrl+x启动。LABEL= 后为你的启动盘的名称。inst.gpt为你需要手动分区 GPT分割表。 选择语言，默认即可，点击Continue 下边可能存在一些感叹号，暂时不用管。选择DATE &amp; TIME 选择 亚洲 Asia，上海 Shanghai，修改一下下边的小时，然后点击Done 选择SOFTWARE SELECTION 选择安装的软件，勾选 Development Tools 点击Done 等一小段时间，SOFTWARE 中的两个图标中的感叹号将消失，然后选择INSTALLATION DESTINATION 选择安装设备，下边分区选择自动分区Automatically configure partitioning，需要特殊分区的待系统创建好后，手动更改，然后点击Done 过一小段时间，感叹号将消失。此时已经开始安装，点击ROOT PASSWORD 进行更改Root用户密码 修改Root用户密码，完成后点击两次Done 此时可以点击 USER CREATION 可以创建一个用户同时设置其密码和权限 将该用户设为管理员级别 勾选Make this user administrator 等待安装完毕，点击右下角Reboot。待重启完成后，输入root和第11步设置的root密码进行登陆。 完成安装，拔掉U盘。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UltraISO制作启动盘安装CentOS7]]></title>
    <url>%2Fserver-UltraISO%2F</url>
    <content type="text"><![CDATA[UltraISO制作启动盘安装CentOS7简单几个步骤即可完成启动盘的制作，非常便利 准备工具 准备8G优盘(启动盘制作完成后占用约4.02G，所以需要8G) 最新版UltraISO(软碟通)官方下载地址：https://cn.ultraiso.net/xiazai.html centos7镜像文件。从centos官网下载，也可以从国内一些镜像网站下载。官网下载：http://isoredirect.centos.org/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-1810.iso 注意： 启动盘制作完成后，不需要把镜像文件复制到U盘里，centos从6.5版本开始就已经不需要这么做了。 制作启动盘 用软碟通打开镜像文件：文件–&gt;打开 写入映像：启动–&gt;写入硬盘映像 点击写入，等待几分钟就ok了。 注意： 启动制作完成后，你的u盘卷标会被改掉，会尝试改成CentOS 7 x86_64，但是呢这个卷标超过了windows规定的长度，所以最终没有改成CentOS 7 x86_64，具体是什么我现在记不清楚了，总之，启动盘制作完成后，你要做一个很重要的工作，那就是改掉卷标，比如改成CENTOS，或者其他的也行，你自己要记住就行了。因为系统安装的时候用的到。下面我会说明怎么用。 系统安装 将机器设置为U盘启动，（DELL R740服务器在启动界面按F11，选择Boot Manager，选择 One-shot UEFI Boot Menu，选择你的启动盘） 由于不同款式的机器设置方式不尽相同，所以你的机器如何设置U盘启动请自行查找。 系统进入安装界面的时候，选中第一个选项，然后按下TAB键 按下TAB后，你会看到 1vmlinuz initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 rd.live.check quiet 这里的，LABEL=CentOS\x207\x20x86_64，意思是说安装源的卷标是CentOS 7 x86_64。但是，因为这个长度超过了windows系统允许的卷标长度，所以你的u盘卷标最终没有成为CentOS 7 x86_64，如果就这样安装下去你在后面的安装过程中会出错，因为系统找不到安装源。 这就是为什么上面改掉卷标的原因，所以把LABEL=CentOS\x207\x20x86_64 改成你修改后的卷标就可以了, 比如LABEL=CENTOS，注意大小写与你的保持一致。 修改完成后，按回车，就开始安装了。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>操作系统</tag>
        <tag>启动盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iso镜像国内下载源]]></title>
    <url>%2Fmirror-iso%2F</url>
    <content type="text"><![CDATA[Linux iso镜像国内下载地址 Centos 链接删除到 xx/7/xx 的位置，可以自行更换版本下载 http://mirrors.btte.net/centos/7/isos/x86_64/ http://mirrors.cn99.com/centos/7/isos/x86_64/ http://mirrors.sohu.com/centos/7/isos/x86_64/ http://mirrors.aliyun.com/centos/7/isos/x86_64/ http://centos.ustc.edu.cn/centos/7/isos/x86_64/ http://mirrors.neusoft.edu.cn/centos/7/isos/x86_64/ http://mirror.lzu.edu.cn/centos/7/isos/x86_64/ http://mirrors.163.com/centos/7/isos/x86_64/ http://ftp.sjtu.edu.cn/centos/7/isos/x86_64/ Ubuntu http://www.oschina.net/p/ubuntu http://releases.ubuntu.com/ http://mirrors.163.com/ubuntu-releases/14.04/]]></content>
      <categories>
        <category>代码工具</category>
      </categories>
      <tags>
        <tag>国内镜像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器装系统注意点]]></title>
    <url>%2Fserver-attention%2F</url>
    <content type="text"><![CDATA[服务器装系统注意点 硬件相关做RAID0配置磁盘阵列等（需两块以上硬盘） 建议服务器系统盘符小于2T使用小于2T盘符来装系统，装好系统后，其他磁盘卡槽可以随意挂载硬盘。 系统盘符大于4T服务器会有很多意外情况。 软件相关强制使用GPT 分割表系统盘容量小于2TB的话，系统预设会使用MBR模式来安装，系统盘大于2T，需要GPT分割表。 在installcentos7，之前，选择”tab”键，输入inst.gpt 在启动时。同时，可能出现找不到安装U盘的盘符，可以删除LABEL=后的名称 让其等于你的启动盘盘符。(注意，各个项目要有空格，最后一个是游标本身而非底线) 分区？ 大小？ 类型？ ext3、ext4?磁盘需要给系统50G~100G ，类型一般选ext4或xfs都行 若手动分区失败，采用自动分区。自动分区没有data目录，可以手动更改，卸载/home替换为/data。参考链接 DevelopMent Tools安装系统时记得选择安装软件 ‘DevelopMent Tools’ 123456# 当然错过的话可以使用如下命令yum groupinstall &quot;Development Libraries&quot;yum groupinstall &quot;Development Tools&quot;yum install ncurses-devel zlib-devel texinfo gtk+-devel gtk2-devel qt-devel tcl-devel tk-devel libX11-devel kernel-headers kernel-devel CentOS 7 使用yum安装MariaDB在线安装MariaDB参考链接 启动盘挂载/etc/yml.repo将上面的文件都备份，然后创建个repo文件，其中file:///mnt是挂载的启动盘]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>踩坑指南</tag>
        <tag>Linux</tag>
        <tag>操作系统</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP三次握手四次挥手简介]]></title>
    <url>%2Fnet-protocol-tcp%2F</url>
    <content type="text"><![CDATA[TCP三次握手四次挥手简介 图解三次握手、四次挥手建立连接：三次握手 关闭连接：四次挥手 上图传递过程中出现的几个字符（SYN,ACK,FIN,seq,ack）各代表什么意思 SYN，ACK，FIN存放在TCP的标志位(标志位一共有6个字符，这里就介绍这三个)： SYN： 代表请求创建连接，所以在三次握手中前两次要SYN=1，表示这两次用于建立连接，至于第三次什么用，在疑问三里解答。 FIN： 表示请求关闭连接，在四次分手时，我们发现FIN发了两遍。这是因为TCP的连接是双向的，所以一次FIN只能关闭一个方向。 ACK： 代表确认接受，从上面可以发现，不管是三次握手还是四次分手，在回应的时候都会加上ACK=1，表示消息接收到了，并且在建立连接以后的发送数据时，都需加上ACK=1,来表示数据接收成功。 seq: 序列号，什么意思呢？当发送一个数据时，数据是被拆成多个数据包来发送，序列号就是对每个数据包进行编号，这样接受方才能对数据包进行再次拼接。 ack: 这个代表下一个数据包的编号，这也就是为什么第二请求时，ack是seq+1， TCP协议和UDP协议的区别 TCP协议是有连接的，有连接的意思是开始传输实际数据之前TCP的客户端和服务器端必须通过三次握手建立连接，会话结束之后也要结束连接。而UDP是无连接的。 TCP协议保证数据按序发送，按序到达，提供超时重传来保证可靠性，但是UDP不保证按序到达，甚至不保证到达，只是努力交付，即便是按序发送的序列，也不保证按序送到。 TCP协议所需资源多，TCP首部需20个字节（不算可选项），UDP首部字段只需8个字节。TCP有流量控制和拥塞控制，UDP没有，网络拥堵不会影响发送端的发送速率 TCP是一对一的连接，而UDP则可以支持一对一，多对多，一对多的通信。TCP面向的是字节流的服务，UDP面向的是报文的服务。 TCP介绍和UDP介绍为什么需要三次握手如果发送两次就建立连接话，那么只要客户端发送一个连接请求，服务端接收到并发送了确认，就会建立一个连接。 可能出现的问题： 如果一个连接请求在网络中跑的慢，超时了，这时客户端会从发请求，但是这个跑的慢的请求最后还是跑到了，然后服务端就接收了两个连接请求，然后全部回应就会创建两个连接，浪费资源！ 如果加了第三次客户端确认，客户端在接受到一个服务端连接确认请求后，后面再接收到的连接确认请求就可以抛弃不管了。 为什么关闭连接却是四次握手关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可能未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了。 什么是TIME_WAIT状态（2MSL状态）有什么意义MSL 即 Maximum Segment Lifetime ，也就是报文最大生存时间，引用《TCP/IP详解》中的话：“它(MSL)是任何报文段被丢弃前在网络内的最长时间。”那么，2MSL也就是这个时间的2倍。需要明白的是，当TCP连接完成四个报文段的交换时，主动关闭的一方将继续等待一定时间(2-4分钟)，即使两端的应用程序结束。 意义： 为了保证A发送的最有一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN和ACK 报文段的确认。B会超时重传这个FIN和ACK报文段，而A就能在2MSL时间内收到这个重传的ACK+FIN报文段。接着A重传一次确认。 就是防止已失效的连接请求报文段出现在本连接中，A在发送完最有一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。 常见的应用中使用到的协议常见的应用中有哪些是应用TCP协议的，哪些又是应用UDP协议的，为什么它们被如此设计？以下应用一般或必须用udp实现？ 多播的信息一定要用udp实现，因为tcp只支持一对一通信。 如果一个应用场景中大多是简短的信息，适合用udp实现，因为udp是基于报文段的，它直接对上层应用的数据封装成报文段，然后丢在网络中，如果信息量太大，会在链路层中被分片，影响传输效率。 如果一个应用场景重性能甚于重完整性和安全性，那么适合于udp，比如多媒体应用，缺一两帧不影响用户体验，但是需要流媒体到达的速度快，因此比较适合用udp 如果要求快速响应，那么udp听起来比较合适如果又要利用udp的快速响应优点，又想可靠传输，那么只能考上层应用自己制定规则了。常见的使用udp的例子：ICQ,QQ的聊天模块。 以qq为例的一个说明（转载自知乎） 登陆采用TCP协议和HTTP协议，你和好友之间发送消息，主要采用UDP协议，内网传文件采用了P2P技术。总来的说： 登陆过程，客户端client 采用TCP协议向服务器server发送信息，HTTP协议下载信息。登陆之后，会有一个TCP连接来保持在线状态。 和好友发消息，客户端client采用UDP协议，但是需要通过服务器转发。腾讯为了确保传输消息的可靠，采用上层协议来保证可靠传输。如果消息发送失败，客户端会提示消息发送失败，并可重新发送。 如果是在内网里面的两个客户端传文件，QQ采用的是P2P技术，不需要服务器中转。 因特网应用中用到的协议]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
        <tag>UDP</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程间的通信、同步方式与进程间通信方式]]></title>
    <url>%2Fthread-communicate%2F</url>
    <content type="text"><![CDATA[线程间的通信、同步方式与进程间通信方式线程、进程两个名字虽然相似但是其确实层级关系，一个进程可以拥有多个线程，而一个线程只会归属于一个进程。 线程间的通信方式使用全局变量主要由于多个线程可能更改全局变量，因此全局变量最好声明为volatile 使用消息实现通信在Windows程序设计中，每一个线程都可以拥有自己的消息队列（UI线程默认自带消息队列和消息循环，工作线程需要手动实现消息循环），因此可以采用消息进行线程间通信sendMessage,postMessage。 定义消息#define WM_THREAD_SENDMSG=WM_USER+20; 添加消息函数声明afx_msg int OnTSendmsg(); 添加消息映射ON_MESSAGE(WM_THREAD_SENDMSG,OnTSM) 添加OnTSM()的实现函数； 在线程函数中添加PostMessage消息Post函数 使用事件CEvent类实现线程间通信Event对象有两种状态：有信号和无信号，线程可以监视处于有信号状态的事件，以便在适当的时候执行对事件的操作。 创建一个CEvent类的对象：CEvent threadStart;它默认处在未通信状态； threadStart.SetEvent();使其处于通信状态； 调用WaitForSingleObject()来监视CEvent对象 线程间的同步方式各个线程可以访问进程中的公共变量，资源，所以使用多线程的过程中需要注意的问题是如何防止两个或两个以上的线程同时访问同一个数据，以免破坏数据的完整性。数据之间的相互制约包括 直接制约关系，即一个线程的处理结果，为另一个线程的输入，因此线程之间直接制约着，这种关系可以称之为同步关系 间接制约关系，即两个线程需要访问同一资源，该资源在同一时刻只能被一个线程访问，这种关系称之为线程间对资源的互斥访问，某种意义上说互斥是一种制约关系更小的同步线程间的同步方式有四种 临界区临界区对应着一个CcriticalSection对象，当线程需要访问保护数据时，调用EnterCriticalSection函数；当对保护数据的操作完成之后，调用LeaveCriticalSection函数释放对临界区对象的拥有权，以使另一个线程可以夺取临界区对象并访问受保护的数据。 PS: 关键段对象会记录拥有该对象的线程句柄即其具有“线程所有权”概念，即进入代码段的线程在leave之前，可以重复进入关键代码区域。所以关键段可以用于线程间的互斥，但不可以用于同步（同步需要在一个线程进入，在另一个线程leave） 互斥量互斥与临界区很相似，但是使用时相对复杂一些（互斥量为内核对象），不仅可以在同一应用程序的线程间实现同步，还可以在不同的进程间实现同步，从而实现资源的安全共享。PS: 互斥量由于也有线程所有权的概念，故也只能进行线程间的资源互斥访问，不能由于线程同步； 由于互斥量是内核对象，因此其可以进行进程间通信，同时还具有一个很好的特性，就是在进程间通信时完美的解决了”遗弃”问题 信号量信号量的用法和互斥的用法很相似，不同的是它可以同一时刻允许多个线程访问同一个资源，PV操作PS: 事件可以完美解决线程间的同步问题，同时信号量也属于内核对象，可用于进程间的通信 事件事件分为手动置位事件和自动置位事件。事件Event内部它包含一个使用计数（所有内核对象都有），一个布尔值表示是手动置位事件还是自动置位事件，另一个布尔值用来表示事件有无触发。由SetEvent()来触发，由ResetEvent()来设成未触发。PS:事件是内核对象,可以解决线程间同步问题，因此也能解决互斥问题 进程间通信方式进程间通信又称IPC(Inter-Process Communication),指多个进程之间相互通信，交换信息的方法。根据进程通信时信息量大小的不同,可以将进程通信划分为两大类型: 低级通信,控制信息的通信(主要用于进程之间的同步,互斥,终止和挂起等等控制信息的传递) 高级通信,大批数据信息的通信(主要用于进程间数据块数据的交换和共享,常见的高级通信有管道,消息队列,共享内存等). 管道( pipe )管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 有名管道 (named pipe)有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 信号 ( signal )信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 信号量( semophore )信号量是一个计数器，可以用来控制多个进程对共享资源的访问。不是用于交换大批数据,而用于多线程之间的同步.常作为一种锁机制,防止某进程在访问资源时其它进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 消息队列( message queue )消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 共享内存( shared memory )共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。 套接字( socket ) 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>线程</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web通用返回对象]]></title>
    <url>%2Fweb-response%2F</url>
    <content type="text"><![CDATA[web通用返回对象项目做前后端分离时，我们会经常提供一些数据给前端，为了规范传出数据的格式，通常会定义一个统一的返回工具类，用以标明响应是否成功，数据是否正常返回等。 下文使用到了构建者模式设计了一个通用返回类。使用简单方便，返回格式清晰明了。 Result类属性123456789101112131415161718192021222324public static final int SUCCESS_CODE = 200;public static final int ERROR_CODE = 500;public static final String SUCCESS_MSG = &quot;success&quot;;public static final String FAIL_MSG = &quot;fail&quot;;/** * 返回是否成功 */private Boolean success;/** * 返回信息 */private String msg;/** * 返回消息类型 */private Integer code;/** * 返回数据 */private Object data; 使用Result的构建者123456789# Result的构建者 public static class Builderprivate Boolean success;private String msg = SUCCESS_MSG;private Integer code = SUCCESS_CODE;private Object data; 使用方法1234567891011121314/** * 在Controller中可以直接作为方法的返回值，返回给客户端 * * 1. Result r = Result.createBuilder().build(); * 2. Result r = Result.createBuilder()[.success(true).msg(&quot;msg&quot;).code(0).data(obj)].build(); * 3. Result r = Result.ok().build(); * 4. Result r = Result.ok(&quot;msg&quot;).build(); * 5. Result r = Result.ok(data).build(); * 6. Result r = Result.error().build(); * 7. Result r = Result.error(&quot;msg&quot;).build(); * 8. Result r = Result.error(data).build(); * 9. Result r = Result.error(ErrorStatus.XXX).build(); * 10. Result r = Result.error(ErrorStatus.XXX, &quot;msg1&quot;, &quot;msg2&quot;).build(); */ 源码Result 类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168import com.xxxx.constant.ErrorStatus;import java.text.MessageFormat;/** * @version V1.0 * @author: big jelly * @program: xx * @description: 返回结果类 * @date: 2019-04-01 15:23 **/public class Result &#123; public static final int SUCCESS_CODE = 200; public static final int ERROR_CODE = 500; public static final String SUCCESS_MSG = &quot;success&quot;; public static final String FAIL_MSG = &quot;fail&quot;; /** * 返回是否成功 */ private Boolean success; /** * 返回信息 */ private String msg; /** * 返回消息类型 */ private Integer code; private Object data; private Result(Builder builder) &#123; this.success = builder.success; this.msg = builder.msg; this.code = builder.code; this.data = builder.data; &#125; /** * Result的建造者 * &lt;p&gt; * 使用方法： * 1. Result r = Result.createBuilder().build(); * 2. Result r = Result.createBuilder()[.success(true).msg(&quot;msg&quot;).code(0).data(obj)].build(); * 3. Result r = Result.ok().build(); * 4. Result r = Result.ok(&quot;msg&quot;).build(); * 5. Result r = Result.ok(data).build(); * 6. Result r = Result.error().build(); * 7. Result r = Result.error(&quot;msg&quot;).build(); * 8. Result r = Result.error(data).build(); * 9. Result r = Result.error(ErrorStatus.XXX).build(); * 10. Result r = Result.error(ErrorStatus.XXX, &quot;msg1&quot;, &quot;msg2&quot;).build(); * &lt;/p&gt; */ public static class Builder &#123; private Boolean success; private String msg = SUCCESS_MSG; private Integer code = SUCCESS_CODE; private Object data; public Builder success(Boolean success) &#123; this.success = success; return this; &#125; public Builder msg(String msg) &#123; this.msg = msg; return this; &#125; public Builder code(Integer code) &#123; this.code = code; return this; &#125; public Builder data(Object data) &#123; this.data = data; return this; &#125; public Result build() &#123; return new Result(this); &#125; &#125; public static Builder createBuilder() &#123; return new Builder(); &#125; public static Builder ok() &#123; return createBuilder().success(Boolean.TRUE); &#125; public static Builder ok(String msg) &#123; return ok().msg(msg); &#125; public static Builder ok(Object data) &#123; return ok().data(data); &#125; public static Builder error() &#123; return createBuilder().success(Boolean.FALSE).code(ERROR_CODE).msg(FAIL_MSG); &#125; public static Builder error(String msg) &#123; return error().msg(msg); &#125; public static Builder error(Object data) &#123; return error().data(data); &#125; public static Builder error(ErrorStatus status) &#123; return error(status, &quot;&quot;); &#125; /** * 使用MessageFormat格式化返回消息 * * @param status * @param msgArgs 要替换的msg * @return */ public static Builder error(ErrorStatus status, Object... msgArgs) &#123; String msg = MessageFormat.format(status.message(), msgArgs); return error().code(status.value()).msg(msg); &#125; public Boolean getSuccess() &#123; return success; &#125; public void setSuccess(Boolean success) &#123; this.success = success; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; public Integer getCode() &#123; return code; &#125; public void setCode(Integer code) &#123; this.code = code; &#125; public Object getData() &#123; return data; &#125; public void setData(Object data) &#123; this.data = data; &#125;&#125; ErrorStatus 类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * @version V1.0 * @program: xxx * @description: 错误状态 * @date: 2019-03-11 15:26 **/public enum ErrorStatus &#123; /** * 参数错误 */ ILLEGAL_ARGUMENT(10001, &quot;参数错误&#123;0&#125;&#123;1&#125;&quot;), /** * 业务错误 */ SERVICE_EXCEPTION(10002, &quot;业务错误&quot;), /** * 非法的数据格式，参数没有经过校验 */ ILLEGAL_DATA(10003, &quot;数据错误&#123;0&#125;&quot;), MULTIPART_TOO_LARGE(1004, &quot;文件太大&quot;), /** * 非法状态 */ ILLEGAL_STATE(10005, &quot;非法状态&quot;), /** * 缺少参数 */ MISSING_ARGUMENT(10006, &quot;缺少参数&quot;), /** * 非法访问 */ ILLEGAL_ACCESS(10007, &quot;非法访问,没有认证&quot;), /** * 权限不足 */ UNAUTHORIZED(10008, &quot;权限不足&quot;), /** * 错误的请求 */ METHOD_NOT_ALLOWED(10009, &quot;不支持的方法&quot;), /** * 参数错误 */ ILLEGAL_ARGUMENT_TYPE(10010, &quot;参数类型错误&quot;), /** * 工具使用错误 */ TOOLS_ERROR(30001, &quot;工具使用错误&quot;); private final int value; private final String message; ErrorStatus(int value, String message) &#123; this.value = value; this.message = message; &#125; /** * Return the integer value of this status code. */ public int value() &#123; return this.value; &#125; /** * Return the reason phrase of this status code. */ public String message() &#123; return this.message; &#125;&#125; 使用ResponseEntity类ResponseEntity 是 包org.springframework.http下的http返回类，可以自定义code、body、headers等返回信息。其中Code必须使用 HttpStatus枚举类 定义的状态码。 缺点： 不能使用自定义的状态码，ResponseEntity类不支持自定义状态码，同时浏览器不能识别自定义的状态码。 1234567// 简单示例@GetMapping(&quot;/http-code&quot;)public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; testHttpCode() &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(16); map.put(&quot;msg&quot;, &quot;too big!!&quot;); return new ResponseEntity&lt;&gt;(map, HttpStatus.ACCEPTED);&#125; 收到返回的内容 12345678Request URL: http://localhost:9001/http-codeRequest Method: GETStatus Code: 202 Remote Address: [::1]:9001Referrer Policy: no-referrer-when-downgrade# body中内容 &#123;&quot;msg&quot;:&quot;too big!!&quot;&#125; 使用注解和通用返回类@ResponseStatus(value = HttpStatus.UNAUTHORIZED) 可以指定返回的状态码。配合第一个通用返回类可以达到浏览器识别我们定义的状态码，同时我们自定义属于业务的特定的返回code，msg等。 缺点： 编码复杂的提高，需要提前规划哪些自定义的code属于哪个HttpStatus中的状态码。响应状态码，范围放大到一个请求Mapping，太宽泛。 123456// 简单示例@GetMapping(&quot;/http-code-2&quot;)@ResponseStatus(value = HttpStatus.UNAUTHORIZED)public Result testRes() &#123; return Result.ok(&quot;未授权！&quot;);&#125; 使用ResponseEntity和通用返回类既可以自定义符合业务的code、data、msg而且可以使用浏览器支持的状态码。 1234@GetMapping(&quot;/http-code&quot;)public ResponseEntity&lt;Result&gt; testHttpCode() &#123; return new ResponseEntity&lt;&gt;(Result.ok().msg(&quot;hei 哈！&quot;), HttpStatus.ACCEPTED);&#125;]]></content>
      <categories>
        <category>代码工具</category>
      </categories>
      <tags>
        <tag>java web</tag>
        <tag>构建者模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis如何遍历参数为Map的key和value]]></title>
    <url>%2Fmybatis-param%2F</url>
    <content type="text"><![CDATA[MyBatis如何遍历参数为Map的key和valueMyBatis可以进行动态SQL拼写，极大的方便了SQL编写，和SQL复用。那么MyBatis如何遍历参数为java.util.map的值呢？ Mapper.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt; &lt;!--namespace必须是接口的全类名 --&gt; &lt;mapper namespace="com.genius"&gt; &lt;!-- 1.0 查询表结构是否存在 --&gt; &lt;select id="selectOne" parameterType="java.util.HashMap" resultType="java.util.HashMap"&gt; select count(*) as num from $&#123;tableName&#125; where seq = #&#123;seq&#125;; &lt;/select&gt; &lt;!-- 1.1 插入一条数据 --&gt; &lt;insert id="insertOne" parameterType="java.util.Map"&gt; insert into $&#123;tableName&#125; &lt;foreach collection="content.keys" item="key" open="(" close=")" separator=","&gt; $&#123;key&#125; &lt;/foreach&gt; values &lt;foreach collection="content.values" item="value" open="(" close=")" separator=","&gt; #&#123;value&#125; &lt;/foreach&gt; &lt;/insert&gt; &lt;!-- 1.2 更新记录 --&gt; &lt;update id="updateOne" parameterType="java.util.Map"&gt; UPDATE $&#123;tableName&#125; SET &lt;foreach collection="content.keys" item="key" open="" close="" separator=","&gt; $&#123;key&#125; = #&#123;content[$&#123;key&#125;]&#125; &lt;/foreach&gt; where seq = #&#123;content[seq]&#125; and genius_uid &lt;= #&#123;content[genius_uid]&#125;; &lt;/update&gt; &lt;!-- 1.3 删除无效数据 --&gt; &lt;delete id="deleteOne" parameterType="java.util.Map"&gt; delete from $&#123;tableName&#125; where seq = #&#123;content[seq]&#125;; &lt;/delete&gt; &lt;/mapper&gt; java代码123456789SqlSession session = MyBatisConnectionFactory.getSession("pg"); HashMap&lt;String, Object&gt; params = new HashMap&lt;&gt;(); //传入的参数 params.put("content", tableContent); params.put("tableName", tableName); params.put("seq", seq); int flag = session.delete("deleteOne", params); //删除记录 HashMap&lt;String, Object&gt; map = session.selectOne("selectOne", params); //查询记录是否存在 flag = session.update("updateOne", params) &gt; 0 ? true : false; //更新 flag = session.insert("insertOne", params) &gt; 0 ? true : false; //新增 示例xml的一个123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.qingtengcloud.dao.BOrderMapper"&gt; &lt;!-- mybatis-plus 启用的模板--&gt; &lt;!-- 通用查询映射结果 --&gt; &lt;resultMap id="BaseResultMap" type="com.qingtengcloud.bean.BOrder"&gt; &lt;id column="id" property="id"/&gt; &lt;result column="tenant_id" property="tenantId"/&gt; &lt;result column="salesman_id" property="salesmanId"/&gt; &lt;result column="status" property="status"/&gt; &lt;result column="call_count" property="callCount"/&gt; &lt;result column="operate_user_id" property="operateUserId"/&gt; &lt;result column="hash_key" property="hashKey"/&gt; &lt;result column="call_number_history" property="callNumberHistory"/&gt; &lt;result column="created_at" property="createdAt"/&gt; &lt;result column="updated_at" property="updatedAt"/&gt; &lt;result column="deleted_at" property="deletedAt"/&gt; &lt;/resultMap&gt; &lt;resultMap id="WithBT_BSResultMap" type="com.qingtengcloud.bean.BOrder"&gt; &lt;id column="o_id" property="id"/&gt; &lt;result column="o_tenant_id" property="tenantId"/&gt; &lt;result column="o_salesman_id" property="salesmanId"/&gt; &lt;result column="o_status" property="status"/&gt; &lt;result column="o_call_count" property="callCount"/&gt; &lt;result column="o_operate_user_id" property="operateUserId"/&gt; &lt;result column="o_hash_key" property="hashKey"/&gt; &lt;result column="o_call_number_history" property="callNumberHistory"/&gt; &lt;result column="o_created_at" property="createdAt"/&gt; &lt;result column="o_updated_at" property="updatedAt"/&gt; &lt;result column="o_deleted_at" property="deletedAt"/&gt; &lt;collection property="bTenant" ofType="com.qingtengcloud.bean.BTenant"&gt; &lt;id column="id" property="id"/&gt; &lt;result column="user_id" property="userId"/&gt; &lt;result column="name" property="name"/&gt; &lt;result column="mobile" property="mobile"/&gt; &lt;result column="gender" property="gender"/&gt; &lt;result column="info_type" property="infoType"/&gt; &lt;result column="rent_people" property="rentPeople"/&gt; &lt;result column="share_rent" property="shareRent"/&gt; &lt;result column="price_range" property="priceRange"/&gt; &lt;result column="block_name" property="blockName"/&gt; &lt;result column="channel_origin_id" property="channelOriginId"/&gt; &lt;result column="custom_tag" property="customTag"/&gt; &lt;result column="demand_tag" property="demandTag"/&gt; &lt;result column="tenancy" property="tenancy"/&gt; &lt;result column="looking_date" property="lookingDate"/&gt; &lt;result column="use_date" property="useDate"/&gt; &lt;result column="status" property="status"/&gt; &lt;result column="note" property="note"/&gt; &lt;result column="info_json" property="infoJson"/&gt; &lt;result column="created_at" property="createdAt"/&gt; &lt;result column="updated_at" property="updatedAt"/&gt; &lt;result column="deleted_at" property="deletedAt"/&gt; &lt;/collection&gt; &lt;collection property="bSalesman" ofType="com.qingtengcloud.bean.BSalesman"&gt; &lt;id column="s_id" property="id"/&gt; &lt;result column="s_company_id" property="companyId"/&gt; &lt;result column="s_user_id" property="userId"/&gt; &lt;result column="s_name" property="name"/&gt; &lt;result column="s_mobile" property="mobile"/&gt; &lt;result column="s_note" property="note"/&gt; &lt;result column="s_created_at" property="createdAt"/&gt; &lt;result column="s_updated_at" property="updatedAt"/&gt; &lt;result column="s_deleted_at" property="deletedAt"/&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;!-- 通用查询结果列 --&gt; &lt;sql id="Base_Column_List"&gt; o.id o_id, o.tenant_id o_tenant_id, o.salesman_id o_salesman_id, o.status o_status, o.call_count o_call_count, o.operate_user_id o_operate_user_id, o.hash_key o_hash_key, o.call_number_history o_call_number_history, o.created_at o_created_at, o.updated_at o_updated_at, o.deleted_at o_deleted_at &lt;/sql&gt; &lt;!-- 租客查询结果列 --&gt; &lt;sql id="Tenant_Column_List"&gt; t.id, t.user_id, t.name, t.gender, t.info_type, t.rent_people, t.share_rent, t.price_range, t.block_name, t.channel_origin_id, t.custom_tag, t.demand_tag, t.tenancy, t.looking_date, t.use_date, t.status, t.note, t.created_at, t.updated_at, t.deleted_at &lt;/sql&gt; &lt;!--销售查询结果列--&gt; &lt;sql id="BSalesman_Column_List"&gt; s.id s_id, s.company_id s_company_id, s.user_id s_user_id, s.name s_name, s.mobile s_mobile, s.note s_note, s.created_at s_created_at, s.updated_at s_updated_at, s.deleted_at s_deleted_at &lt;/sql&gt; &lt;sql id="Required_Where_Clause"&gt; &lt;if test="params.block!=null and params.block!=''"&gt; AND t.block_name like #&#123;params.block&#125; &lt;/if&gt; &lt;if test="params.price_range!=null and params.price_range!=''"&gt; AND t.price_range = #&#123;params.price_range&#125; &lt;/if&gt; &lt;if test="params.rent_people!=null and params.rent_people!=''"&gt; AND t.rent_people = #&#123;params.rent_people&#125; &lt;/if&gt; &lt;if test="params.looking_date!=null and params.looking_date!=''"&gt; AND t.looking_date = #&#123;params.looking_date&#125; &lt;/if&gt; &lt;if test="params.ostatus!=null and params.ostatus!=''"&gt; AND o.status = #&#123;params.ostatus&#125; &lt;/if&gt; &lt;if test="params.operate_user_id!=null and params.operate_user_id!=''"&gt; AND o.operate_user_id = #&#123;params.operate_user_id&#125; &lt;/if&gt; &lt;if test="params.s_mobile!=null and params.s_mobile!=''"&gt; AND s.mobile = #&#123;params.s_mobile&#125; &lt;/if&gt; &lt;/sql&gt; &lt;select id="bOrderPagingQueryByUpdateDesc" resultMap="WithBT_BSResultMap"&gt; SELECT &lt;include refid="Base_Column_List"/&gt;, &lt;include refid="Tenant_Column_List"/&gt;, &lt;include refid="BSalesman_Column_List"/&gt; FROM b_salesman AS s, b_order AS o, b_tenant AS t WHERE o.tenant_id = t.id AND o.salesman_id= s.id ORDER BY o.status , o.updated_at DESC &lt;/select&gt; &lt;select id="bOrderSelectByRequired" resultMap="WithBT_BSResultMap" parameterType="java.util.Map" &gt; SELECT &lt;include refid="Base_Column_List"/&gt;, &lt;include refid="Tenant_Column_List"/&gt;, &lt;include refid="BSalesman_Column_List"/&gt; FROM b_salesman AS s, b_order AS o, b_tenant AS t WHERE o.tenant_id = t.id AND o.salesman_id= s.id &lt;include refid="Required_Where_Clause" /&gt; order by o.status , o.updated_at DESC &lt;/select&gt;&lt;/mapper&gt; Dao层的mapper接口1234567891011121314151617181920212223242526272829303132import com.baomidou.mybatisplus.extension.plugins.pagination.Page;import com.qingtengcloud.bean.BOrder;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import org.apache.ibatis.annotations.Param;import java.util.List;import java.util.Map;/** * &lt;p&gt; * 房东-租客-订单表-Jelly Mapper 接口 * &lt;/p&gt; * * @author Jelly * @since 2019-03-15 */public interface BOrderMapper extends BaseMapper&lt;BOrder&gt; &#123; /** * BOrder分页查询 * @param page 分页 * @return BOrder的集合 */ List&lt;BOrder&gt; bOrderPagingQueryByUpdateDesc(Page page); /** * 条件查询 * @param page 分页 * @param map 参数 * @return 分页查询 */ List&lt;BOrder&gt; bOrderSelectByRequired(Page page, @Param("params") Map&lt;String, Object&gt; map);&#125;]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>框架</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot-常见getpost请求参数处理]]></title>
    <url>%2Fspringb-getpost%2F</url>
    <content type="text"><![CDATA[spring boot 常见http get ,post请求参数处理 在定义一个Rest接口时通常会利用GET、POST、PUT、DELETE来实现数据的增删改查；这几种方式有的需要传递参数，后台开发人员必须对接收到的参数进行参数验证来确保程序的健壮性 GET一般用于查询数据，采用明文进行传输，一般用来获取一些无关用户信息的数据POST一般用于插入数据PUT一般用于数据更新DELETE一般用于数据删除一般都是进行逻辑删除（即：仅仅改变记录的状态，而并非真正的删除数据） @PathVaribale 获取url中的数据 @RequestParam 获取请求参数的值 @GetMapping 组合注解，是 @RequestMapping(method = RequestMethod.GET) 的缩写 @RequestBody 利用一个对象去获取前端传过来的数据 PathVaribale 获取url路径的数据请求URL： localhost:8080/hello/id 获取id值 实现代码如下： 1234567@RestControllerpublic class HelloController &#123; @RequestMapping(value="/hello/&#123;id&#125;/&#123;name&#125;",method= RequestMethod.GET) public String sayHello(@PathVariable("id") Integer id,@PathVariable("name") String name)&#123; return "id:"+id+" name:"+name; &#125;&#125; 在浏览器中 输入地址： localhost：8080/hello/100/hello输出： id:100 name:hello RequestParam 获取请求参数的值获取url参数值，默认方式，需要方法参数名称和url参数保持一致 localhost:8080/hello?id=1000 实现代码： 1234567@RestControllerpublic class HelloController &#123; @RequestMapping(value="/hello",method= RequestMethod.GET) public String sayHello(@RequestParam Integer id)&#123; return "id:"+id; &#125;&#125; 输出：id：100 url中有多个参数时，如： localhost:8080/hello?id=98&amp;&amp;name=helloworld 具体代码如下： 1234567@RestControllerpublic class HelloController &#123; @RequestMapping(value="/hello",method= RequestMethod.GET) public String sayHello(@RequestParam Integer id,@RequestParam String name)&#123; return "id:"+id+ " name:"+name; &#125;&#125; 获取url参数值，执行参数名称方式 localhost:8080/hello?userId=1000 具体代码： 1234567@RestControllerpublic class HelloController &#123; @RequestMapping(value="/hello",method= RequestMethod.GET) public String sayHello(@RequestParam("userId") Integer id)&#123; return "id:"+id; &#125;&#125; 输出： id：100 注意：不输入id的具体值，此时返回的结果为null。具体测试结果如下：id：null **不输入id参数，则会报如下错误： **whitelable Error Page错误 GET参数校验用法：不输入id时，使用默认值具体代码如下： localhost：8080/hello 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@RestControllerpublic class HelloController &#123; @RequestMapping(value="/hello",method= RequestMethod.GET) //required=false 表示url中可以无id参数，此时就使用默认参数 public String sayHello(@RequestParam(value="id",required = false,defaultValue = "1") Integer id)&#123; return "id:"+id; &#125;&#125;``` 输出：**id:1** ## POST JSON参数校验 常用校验注解 ![VIZ3CD.png](https://s2.ax1x.com/2019/06/15/VIZ3CD.png) **注意：** 接收到的参数默认都是字符串类型的，有的注解只能用在String类型的属性上**@JsonProperty** 可以实现前端的属性名和后台实体类的属性名不一致问题**校验方式：** 使用**@RequestBody @Valid** 对JSON参数进行获取和校验。 通过**BindingResult bindingResult** 去获取校验结果。BindingResult 源码：![VIZ88e.png](https://s2.ax1x.com/2019/06/15/VIZ88e.png) - 技巧01：利用BindingResult对象的hasErrors方法判断是否有参数错误 - 技巧02：利用BindingResult对象的getFieldErrors方法获取所有有参数错误的属性 - 技巧03：利用错误属性对象的getDefaultMessage去获取错误提示信息 ```java@RequestMapping(value = "/demo5",produces = MediaType.TEXT_PLAIN_VALUE)@ResponseBodypublic String test5(@RequestBody @Valid User user , BindingResult bindingResult)&#123; if(bindingResult.hasErrors())&#123; List&lt;ObjectError&gt; objectErrors = bindingResult.getAllErrors(); System.out.println(objectErrors.toString()); for(ObjectError objectError: objectErrors)&#123; System.out.println("objectError = " + objectError.getObjectName()); System.out.println("objectError = " + objectError.getDefaultMessage()); System.out.println("objectError = " + objectError.getCode()); System.out.println("objectError = " + objectError.getArguments()); &#125; &#125; String str = user.toString(); return str;&#125; 对应User实体类代码： 12345678910111213141516171819202122232425262728293031323334353637383940public class User &#123; @NotEmpty(message = "ID不能为空") @NotBlank(message = "ID不能为空哟") private String id; @Min(value = 18) @Max(value = 30) private Integer age; @NotEmpty(message = "昵称不能为空") @NotBlank(message = "昵称不能为空哟") @JsonProperty("nickname") // 当前端属性为nick后台接收对象的属性为nickName时可以用@JsonProperty来保持一致 private String name; ....省略get set方法 ``` ---# 自定义注解校验## 定义一个校验注解代码如下：```javaimport javax.validation.Constraint;import javax.validation.Payload;import java.lang.annotation.*;@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.PARAMETER, ElementType.FIELD&#125;)@Constraint(validatedBy = MyFormValidatorClass.class)public @interface MyFormValidator &#123; String value(); String message() default "name can be test"; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;&#125; 定义一个约束校验12345678910111213141516171819202122232425import javax.validation.ConstraintValidator;import javax.validation.ConstraintValidatorContext;import java.lang.annotation.Annotation;public class MyFormValidatorClass implements ConstraintValidator&lt;MyFormValidator, Object&gt;, Annotation &#123; private String values; @Override public void initialize(MyFormValidator myFormValidator) &#123; this.values = myFormValidator.value(); &#125; @Override public boolean isValid(Object value, ConstraintValidatorContext context) &#123; if("test".equals((String)value))&#123; return true; &#125; return false; &#125; @Override public Class&lt;? extends Annotation&gt; annotationType() &#123; return null; &#125;&#125; 实体类中使用123456789101112131415public class User2 &#123; @NotEmpty(message = "ID不能为空") @NotBlank(message = "ID不能为空哟") //自定义校验注解-校验id是否为test @MyFormValidator(value = "abc",message = "dd") private String id; @Min(value = 18) @Max(value = 30) private Integer age; @NotEmpty(message = "昵称不能为空") @NotBlank(message = "昵称不能为空哟") @JsonProperty("nickname") // 当前端属性为nick后台接收对象的属性为nickName时可以用@JsonProperty private String name; 测试代码123456789101112131415161718@RequestMapping(value = "/demo6",produces = MediaType.TEXT_PLAIN_VALUE)@ResponseBodypublic String test6(@RequestBody @Valid User2 user , BindingResult bindingResult)&#123; if(bindingResult.hasErrors())&#123; List&lt;ObjectError&gt; objectErrors = bindingResult.getAllErrors(); System.out.println(objectErrors.toString()); for(ObjectError objectError: objectErrors)&#123; System.out.println("objectError = " + objectError.getObjectName()); System.out.println("objectError = " + objectError.getDefaultMessage()); System.out.println("objectError = " + objectError.getCode()); System.out.println("objectError = " + objectError.getArguments()); &#125; &#125; String str = user.toString(); return str;&#125; 当请求参数ID不为test，objectErrors 中有该报错。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>框架</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA中安装配置Gradle]]></title>
    <url>%2Ftool-IDEA-Gradle%2F</url>
    <content type="text"><![CDATA[GradleGradle 的核心在于基于 Groovy 的丰富而可扩展的域描述语言(DSL)。 Groovy 通过声明性的语言元素将基于声明的构建推向下层，你可以按你想要的方式进行组合。 这些元素同样也为支持 Java， Groovy，OSGi，Web 和 Scala 项目提供了基于约定的构建。 并且，这种声明性的语言是可以扩展的。你可以添加新的或增强现有的语言元素。 因此，它提供了简明、可维护和易理解的构建。 介绍Gradle，是一个基于JVM的富有突破性构建工具。它为您提供了: 一个像 ant 一样，通用的灵活的构建工具 一种可切换的，像 maven 一样的基于约定约定优于配置的构建框架 强大的多工程构建支持 强大的依赖管理(基于 ApacheIvy) 对已有的 maven 和 ivy 仓库的全面支持 支持传递性依赖管理，而不需要远程仓库或者 pom.xml 或者 ivy 配置文件 ant 式的任务和构建是 gradle 的第一公民 基于 groovy，其 build 脚本使用 groovy dsl 编写 具有广泛的领域模型支持你的构建 Intellij IDEA 安装配置Gradlewindows下安装 到官网链接下载最新的bin版本，解压到 F:\Tools\Gradle 配置环境变量 123GRADLE_HOME=F:\Tools\GradleGRADLE_USER_HOME=F:\Tools\Gradle\.gradle 注意上面的配置第一个是gradel,是gradle的安装路径第二个是.gradle,注意前面有个点号，这个文件是用来存放Gradle缓存的 将下面的配置添加到Path路径中： F:\Tools\Gradle\bin 使用 gradle -v 命令查看： 1234567891011121314151617181920212223242526$ gradle -vWelcome to Gradle 4.9!Here are the highlights of this release: - Experimental APIs for creating and configuring tasks lazily - Pass arguments to JavaExec via CLI - Auxiliary publication dependency support for multi-project builds - Improved dependency insight reportFor more details see https://docs.gradle.org/4.9/release-notes.html------------------------------------------------------------Gradle 4.9------------------------------------------------------------Build time: 2018-07-16 08:14:03 UTCRevision: efcf8c1cf533b03c70f394f270f46a174c738efcKotlin DSL: 0.18.4Kotlin: 1.2.41Groovy: 2.4.12Ant: Apache Ant(TM) version 1.9.11 compiled on March 23 2018JVM: 1.8.0_102 (Oracle Corporation 25.102-b14)OS: Windows 10 10.0 amd64 提高编译速度在咱们的gradle缓存.gradle目录下创建一个gradle.properties 文件 ，再打开该文件在其中添加如下语句， 可以提高编译速度。 12345678#开启线程守护，第一次编译时开线程，之后就不会再开了org.gradle.daemon=true#配置编译时的虚拟机大小org.gradle.jvmargs=-Xmx2048m -XX:MaxPermSize=512m -XX:+HeapDumpOnOutOfMemoryError -Dfile.encoding=UTF-8#开启并行编译，相当于多条线程再走org.gradle.parallel=true#启用新的孵化模式org.gradle.configureondemand=true 配置远程阿里云仓库 在gradle目录下的init.d目录中创建名为init.gradle文件，内容如下： 1234567891011121314151617allprojects&#123; repositories &#123; def REPOSITORY_URL = 'http://maven.aliyun.com/nexus/content/groups/public/' all &#123; ArtifactRepository repo -&gt; if(repo instanceof MavenArtifactRepository)&#123; def url = repo.url.toString() if (url.startsWith('https://repo1.maven.org/maven2') || url.startsWith('https://jcenter.bintray.com/')) &#123; project.logger.lifecycle "Repository $&#123;repo.url&#125; replaced by $REPOSITORY_URL." remove repo &#125; &#125; &#125; maven &#123; url REPOSITORY_URL &#125; &#125;&#125; IDEA中配置使用gradle Service directory path:就配置到放gradle缓存的地方。Offline work:离线工作，在包全都下载以后可以设置，这样效率高些。（刚开始不要选） Gradle命令gradle -v //版本号 gradle clean //清除build文件夹 gradle build //检查依赖并打包 gradle assembleDebug //编译打包Debug包 gradle assembleRelease //编译打包Release包 gradle installRelease //打包并安装Release包 gradle unstallRelease //卸载Release包 gradle dependencies //查看依赖图表 gradle clean build -x test //跳过测试编译 gradle --profile build //分析构建任务 gradle build --dry-run //编译并不执行任务 gradle install //安置项目jar包到本地Maven仓库 gradle tasks //查看Gradle任务 gradle tasks --all //查看所有Gradle任务 gradle build --daemon //使用Gradle守护程序(Daemon) gradle build --offline //用离线模式运行 gradle clean build --refresh-dependencies //刷新Gradle依赖缓存]]></content>
      <categories>
        <category>代码工具</category>
      </categories>
      <tags>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA中使用Lombok]]></title>
    <url>%2Ftool-IDEA-Lombok%2F</url>
    <content type="text"><![CDATA[Lombok 是一个jar包，可以节约很多敲代码的工作，适当的为自己增加一点趁手的工作。官网地址：https://projectlombok.org/最常用的就是@Data，@Log最近在使用idea，就记录一下在这个下面使用的方式吧。 在IDEA中使用 在步骤4，应该是个install，我的这个截图是已经安装完成的。步骤5，如果在线安装不成，可以试试离线安装。 开启 Enable annotation processing POM 增加依赖123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.18&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 最后一步增加 @Data 注解，可以在类structure直接看到生成的get set 等结构了 lombok-@Accessors注解简介： 一个为getter和setter设计的更流畅的API 概况：@Accessors 因此有3个选择： fluent 一个布尔值。如果为真，pepper的getter就是 pepper()，setter方法就是pepper(T newValue)。并且，除非特别说明，chain默认为真。 chain 一个布尔值。如果为真，产生的setter返回的this而不是void，默认是假。如果fluent=true，那么chain默认为真。set方法返回的是对象的实例，因此可以直接再使用set方法或者直接调用函数 prefix 一系列string类型。如果显示，属性必须加上某些定义的前缀。每个属性名反过来与列表中的每个前缀进行比较，一个找到一个匹配，这个前缀被提取出来为属性创建基本的名字。前缀列表中不包含任何前缀也是合法的，为空则总是匹配。字符都是字母，紧接着前缀后的字符一定不能是小写字母。例如，pepper对前缀p不是相等匹配，而跟pEpper是匹配的(也就意味着属性的基本名字是epper)。 也就是在属性上增加注解，在类上的注解就会自动忽略；使用前缀，匹配有前缀+大写字母这样的匹配才能自动生成忽略前缀的get方法和set方法。]]></content>
      <categories>
        <category>代码工具</category>
      </categories>
      <tags>
        <tag>plugin</tag>
        <tag>lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot-整合redis实现发送短信验证码]]></title>
    <url>%2Fspringb-redis2sms%2F</url>
    <content type="text"><![CDATA[springboot-整合redis实现发送短信验证码用户登录时可以选择使用手机号加验证码的形式进行快速验证登录。整体逻辑，用户输入手机号，点击发送验证码；后台收到手机号，生成指定位数的验证码，存入redis中（设定过期时间）并发送短信。若在过期时间内用户再次点击发送验证码按钮，现在redis中查询当前手机号是否有验证码缓存，有的话读取缓存中验证码更新过期时间并返回，否则生成新的验证码返回。 所需软件 Redis-x64-3.2.100 （我是在windows本地的，远程也可以） 阿里云短信平台（需要付费, 后边有介绍） Spring Boot项目 Redis本地搭建，使用redis客户端线上搭建，使用redis服务器 Windows的Redis下载 解压到一个文件夹内编辑一个文本文件，内容为 1redis-server redis.windows.conf 将文本文件名称改为：startup.bat 双击 startup.bat 看到redis启动的标志图标即为成功了。 双击redis-cli.exe可以启动redis的客户端，查看当前redis中有什么。 Ali的短信平台短信平台是阿里云的，需要付费购买服务，购买地址：https://common-buy.aliyun.com/?spm=5176.8195934.907839.sms6.312c4183mzE9Yb&amp;&amp;commodityCode=newdysmsbag#/buy 付费完成后，首先申请短信签名和短信模板：https://help.aliyun.com/document_detail/55327.html?spm=a2c4g.11186623.6.549.huzd56。 短信签名： 根据用户属性来创建符合自身属性的签名信息。企业用户需要上传相关企业资质证明，个人用户需要上传证明个人身份的证明。注意：短信签名需要审核通过后才可以使用。 短信模板： 短信模板，即具体发送的短信内容。短信模板可以支持验证码、短信通知、推广短信、国际/港澳台消息四种模式。验证码和短信通知，通过变量替换实现个性短信定制。推广短信不支持在模板中添加变量。短信模板需要审核通过后才可以使用。 短信示例： 【阿里云】 验证码${number}，您正进行支付宝的身份验证，打死不告诉别人！这里的短信签名：阿里云，短信模板: 验证码${number}，您正进行支付宝的身份验证，打死不告诉别人！ 最后获取 asscessKeyId 和 accessKeySecret 。结合阿里云提供的开发者文档即可进行接口开发，短信开发api文档：https://help.aliyun.com/product/44282.html?spm=a2c4g.750001.6.1.T84wBi 项目创建Maven项目 添加依赖12345&lt;!--redis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; application.properties1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#--------------------------短信--------------------------aliyun.sms.access-key-id=****aliyun.sms.access-key-secret=***#短信API产品名称（短信产品名固定，无需修改）aliyun.sms.product=Dysmsapi#短信API产品域名（接口地址固定，无需修改）aliyun.sms.domain=dysmsapi.aliyuncs.com# 初始化acsClient,暂不支持region化aliyun.sms.region-id=cn-hangzhoualiyun.sms.endpoint-name=cn-hangzhou#短信签名-可在短信控制台中找到aliyun.sms.sign-name=***aliyun.sms.date-format=yyyyMMddaliyun.sms.template-code=SMS_160220108#-------------------------Redis--------------------------spring.redis.host=127.0.0.1spring.redis.password=spring.redis.port=6379#默认过期时间、如果返回值存在过期时间则使用返回值中的过期时间ali.tokenExpire=3600ali.refreshTokenExpire=2592000# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=r-2ze3ede749e90084.redis.rds.aliyuncs.com# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=QTOwer*&amp;(192# 连接超时时间（毫秒）spring.redis.timeout=5000# 连接池最大连接数（使用负值表示没有限制） 默认 8spring.redis.lettuce.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1spring.redis.lettuce.pool.max-wait=-1# 连接池中的最大空闲连接 默认 8spring.redis.lettuce.pool.max-idle=8# 连接池中的最小空闲连接 默认 0spring.redis.lettuce.pool.min-idle=0``` ## 生成随机码的工具类 ```javapublic class IdentifyCodeUtil &#123; public static String getRandom() &#123; String num = ""; for (int i = 0; i &lt; 6; i++) &#123; num = num + String.valueOf((int) Math.floor(Math.random() * 9 + 1)); &#125; return num; &#125;&#125; 发送短信，查询短信发送情况123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192import com.aliyuncs.DefaultAcsClient;import com.aliyuncs.IAcsClient;import com.aliyuncs.dysmsapi.model.v20170525.QuerySendDetailsRequest;import com.aliyuncs.dysmsapi.model.v20170525.QuerySendDetailsResponse;import com.aliyuncs.dysmsapi.model.v20170525.SendSmsRequest;import com.aliyuncs.dysmsapi.model.v20170525.SendSmsResponse;import com.aliyuncs.exceptions.ClientException;import com.aliyuncs.profile.DefaultProfile;import com.aliyuncs.profile.IClientProfile;import com.qingtengcloud.daisy.utils.log.LogTypeEnum;import com.qingtengcloud.daisy.utils.log.LogUtils;import lombok.Data;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;import java.text.SimpleDateFormat;import java.util.Date;/** * @version V1.0 * @author: Jelly * @program: daisy * @description: * @date: 2019-03-13 12:06 **/@Component@Slf4jpublic class AliSmsSendTool &#123; // 自动注册短信服务的配置 @Value("$&#123;aliyun.sms.access-key-id&#125;") private String accessKeyId; @Value("$&#123;aliyun.sms.access-key-secret&#125;") private String accessKeySecret; @Value("$&#123;aliyun.sms.product&#125;") private String product; @Value("$&#123;aliyun.sms.domain&#125;") private String domain; @Value("$&#123;aliyun.sms.region-id&#125;") private String regionId; @Value("$&#123;aliyun.sms.endpoint-name&#125;") private String endpointName; @Value("$&#123;aliyun.sms.sign-name&#125;") private String signName; @Value("$&#123;aliyun.sms.date-format&#125;") private String dateFormat; public static SMS newSMS() &#123; return new SMS(); &#125; /** * 一个短信实体 */ @Data public static class SMS &#123; private String phoneNumbers; private String templateParam; private String outId; private String templateCode; &#125; /** * 获取短信发送服务机 * * @return */ private IAcsClient getClient() &#123; IClientProfile profile = DefaultProfile.getProfile(regionId, accessKeyId, accessKeySecret); try &#123; DefaultProfile.addEndpoint(endpointName, regionId, product, domain); &#125; catch (ClientException e) &#123; e.printStackTrace(); &#125; return new DefaultAcsClient(profile); &#125; /** * 获取短信请求 * * @param sms * @return */ private SendSmsRequest getRequest(SMS sms) &#123; SendSmsRequest request = new SendSmsRequest(); if (sms.getPhoneNumbers() == null) &#123; LogUtils.error(AliSmsSendTool.class, LogTypeEnum.TOOLS, "接收短信手机号为空！"); return null; &#125; request.setPhoneNumbers(sms.getPhoneNumbers()); request.setSignName(signName); if (sms.getTemplateCode() == null) &#123; LogUtils.error(AliSmsSendTool.class, LogTypeEnum.TOOLS, "短信模板为空！"); return null; &#125; request.setTemplateCode(sms.getTemplateCode()); if (sms.getTemplateParam() == null) &#123; LogUtils.error(AliSmsSendTool.class, LogTypeEnum.TOOLS, "模板中替换JSON串de变量为空！"); return null; &#125; request.setTemplateParam(sms.getTemplateParam()); if (sms.getOutId() == null) &#123; LogUtils.warn(AliSmsSendTool.class, LogTypeEnum.TOOLS, "提供给业务方扩展字段 outId为空！"); &#125; else &#123; request.setOutId(sms.getOutId()); &#125; return request; &#125; @Data public static class SendResult &#123; private SendSmsResponse sendSmsResponse; private SMS sms; &#125; @Data public static class QueryResult &#123; private QuerySendDetailsResponse querySendDetailsResponse; private Query query; &#125; /** * 发送短信 * &lt;p&gt; * &lt;p&gt; * 发送验证码类的短信时，每个号码每分钟最多发送一次，每个小时最多发送5次。 * 其它类短信频控请参考阿里云 * * @param sms 短信 */ public SendResult sendSms(SMS sms) &#123; IAcsClient acsClient = getClient(); SendSmsRequest request = getRequest(sms); SendSmsResponse sendSmsResponse = null; try &#123; if (request != null) &#123; sendSmsResponse = acsClient.getAcsResponse(request); &#125; &#125; catch (ClientException e) &#123; log.error("发送短信发生错误。错误代码是 [&#123;&#125;]，错误消息是 [&#123;&#125;]，错误请求ID是 [&#123;&#125;]，错误Msg是 [&#123;&#125;]，错误类型是 [&#123;&#125;]", e.getErrCode(), e.getMessage(), e.getRequestId(), e.getErrMsg(), e.getErrorType()); //错误消息是 [SDK.InvalidRegionId : Can not find endpoint to access.]，错误请求ID是 [null]，错误Msg是 [Can not find endpoint to access.]，错误类型是 [Client] e.printStackTrace(); &#125; SendResult result = new SendResult(); result.setSendSmsResponse(sendSmsResponse); result.setSms(sms); return result; &#125; public static Query newQuery() &#123; return new Query(); &#125; // 构建一个查询器 @Data public static class Query &#123; private String bizId; //业务ID private String phoneNumber; private Date sendDate; private Long pageSize; private Long currentPage; &#125; /** * 查询短信发送结果 * * @param query 查询条件 */ public QueryResult querySendDetails(Query query) &#123; IAcsClient acsClient = getClient(); QuerySendDetailsRequest request = new QuerySendDetailsRequest(); request.setPhoneNumber(query.getPhoneNumber()); request.setBizId(query.getBizId()); SimpleDateFormat ft = new SimpleDateFormat(dateFormat); request.setSendDate(ft.format(query.getSendDate())); request.setPageSize(query.getPageSize()); request.setCurrentPage(query.getCurrentPage()); QuerySendDetailsResponse querySendDetailsResponse = null; try &#123; querySendDetailsResponse = acsClient.getAcsResponse(request); &#125; catch (ClientException e) &#123; e.printStackTrace(); &#125; QueryResult result = new QueryResult(); result.setQuerySendDetailsResponse(querySendDetailsResponse); result.setQuery(query); return result; &#125;&#125; 发送短信配置常量类sprringboot启动类Application.java加入注解：@EnableCaching 配置redis采用缓存，设置key和value的序列化方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225/** * @version V1.0 * @author: Jelly * @description: * @date: 2019-02-22 09:39 **/public class Constants &#123; public static final int SUCCESS = 200; public static final int FAILED = 101; public final static String SMS_AUTH_TYPE = "sms"; public final static String SMS_AUTH_CODE = "DaisySms"; public final static String SMS_SEND_STATUS_OK = "OK"; public final static long SMS_EXPIRE_TIME = 5*60; public final static int SMS_CODE_LENGTH = 6;&#125;``` ## redis实现类保存、获取、删除验证码接口实现方法。(可以使用spring-boot自带的 **stringRedisTemplate** )```javaimport org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.*;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;import org.springframework.stereotype.Service;import java.io.Serializable;import java.util.List;import java.util.Set;import java.util.concurrent.TimeUnit;/** * @version V1.0 * @author: Jelly * @description: redis操作方法 * @date: 2019-03-15 11:33 **/@Servicepublic class RedisService &#123; private RedisTemplate redisTemplate; @Autowired(required = false) public void setRedisTemplate(RedisTemplate redisTemplate) &#123; RedisSerializer stringSerializer = new StringRedisSerializer(); redisTemplate.setKeySerializer(stringSerializer); redisTemplate.setValueSerializer(stringSerializer); redisTemplate.setHashKeySerializer(stringSerializer); redisTemplate.setHashValueSerializer(stringSerializer); this.redisTemplate = redisTemplate; &#125; /** * 写入缓存 * @param key * @param value * @return */ public boolean set(final String key, Object value) &#123; boolean result = false; try &#123; ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); operations.set(key, value); result = true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return result; &#125; /** * 写入缓存设置时效时间 * @param key * @param value * @return */ public boolean set(final String key, Object value, Long expireTime) &#123; boolean result = false; try &#123; ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); operations.set(key, value); redisTemplate.expire(key, expireTime, TimeUnit.SECONDS); result = true; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return result; &#125; /** * 批量删除对应的value * @param keys */ public void remove(final String... keys) &#123; for (String key : keys) &#123; remove(key); &#125; &#125; /** * 批量删除key * @param pattern */ public void removePattern(final String pattern) &#123; Set&lt;Serializable&gt; keys = redisTemplate.keys(pattern); if (keys.size() &gt; 0) redisTemplate.delete(keys); &#125; /** * 删除对应的value * @param key */ public void remove(final String key) &#123; if (exists(key)) &#123; redisTemplate.delete(key); &#125; &#125; /** * 判断缓存中是否有对应的value * @param key * @return */ public boolean exists(final String key) &#123; return redisTemplate.hasKey(key); &#125; /** * 读取缓存 * @param key * @return */ public Object get(final String key) &#123; Object result = null; ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); result = operations.get(key); return result; &#125; /** * 哈希 添加 * @param key * @param hashKey * @param value */ public void hmSet(String key, Object hashKey, Object value)&#123; HashOperations&lt;String, Object, Object&gt; hash = redisTemplate.opsForHash(); hash.put(key,hashKey,value); &#125; /** * 哈希获取数据 * @param key * @param hashKey * @return */ public Object hmGet(String key, Object hashKey)&#123; HashOperations&lt;String, Object, Object&gt; hash = redisTemplate.opsForHash(); return hash.get(key,hashKey); &#125; /** * 列表添加 * @param k * @param v */ public void lPush(String k,Object v)&#123; ListOperations&lt;String, Object&gt; list = redisTemplate.opsForList(); list.rightPush(k,v); &#125; /** * 列表获取 * @param k * @param l * @param l1 * @return */ public List&lt;Object&gt; lRange(String k, long l, long l1)&#123; ListOperations&lt;String, Object&gt; list = redisTemplate.opsForList(); return list.range(k,l,l1); &#125; /** * 集合添加 * @param key * @param value */ public void add(String key,Object value)&#123; SetOperations&lt;String, Object&gt; set = redisTemplate.opsForSet(); set.add(key,value); &#125; /** * 集合获取 * @param key * @return */ public Set&lt;Object&gt; setMembers(String key)&#123; SetOperations&lt;String, Object&gt; set = redisTemplate.opsForSet(); return set.members(key); &#125; /** * 有序集合添加 * @param key * @param value * @param scoure */ public void zAdd(String key,Object value,double scoure)&#123; ZSetOperations&lt;String, Object&gt; zset = redisTemplate.opsForZSet(); zset.add(key,value,scoure); &#125; /** * 有序集合获取 * @param key * @param scoure * @param scoure1 * @return */ public Set&lt;Object&gt; rangeByScore(String key,double scoure,double scoure1)&#123; ZSetOperations&lt;String, Object&gt; zset = redisTemplate.opsForZSet(); return zset.rangeByScore(key, scoure, scoure1); &#125;&#125; 发送短信接口1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import com.aliyuncs.dysmsapi.model.v20170525.QuerySendDetailsResponse;import com.aliyuncs.exceptions.ClientException;import com.qingtengcloud.daisy.protocol.Result;import com.qingtengcloud.daisy.utils.AliSmsSendTool;import java.security.NoSuchAlgorithmException;/** * @version V1.0 * @author: Jelly * @description: * @date: 2019-03-20 15:11 **/public interface ISmsService &#123; /** * 发送短信接口 * * @param phoneNums 手机号码 * @param templeteCode 模板代码 * @param templateParam 模板替换参数 * @return * @throws ClientException */ Object sendSms(String phoneNums, String templeteCode, String templateParam ) throws ClientException; /** * 查询短信发送明细 * * @param phoneNumber * @param bizId 业务流水号 * @return * @throws ClientException */ Result querySendDetails(String phoneNumber, String bizId) throws ClientException; /** * 发送短信服务 * * @param mobile 手机号 * @return */ Result sendMessage(String mobile) throws NoSuchAlgorithmException; /** * 判断验证码是否正确 * * @param mobile * @param identifyCode * @return */ Boolean checkIsCorrectCode(String mobile, String identifyCode) throws NoSuchAlgorithmException;&#125; 发送短信实现类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156import com.alibaba.fastjson.JSON;import com.aliyuncs.exceptions.ClientException;import com.qingtengcloud.daisy.constant.Constants;import com.qingtengcloud.daisy.constant.ErrorStatus;import com.qingtengcloud.daisy.protocol.Result;import com.qingtengcloud.daisy.service.ISmsService;import com.qingtengcloud.daisy.service.RedisService;import com.qingtengcloud.daisy.utils.AliSmsSendTool;import com.qingtengcloud.daisy.utils.Tools;import com.qingtengcloud.daisy.utils.log.LogTypeEnum;import com.qingtengcloud.daisy.utils.log.LogUtils;import org.apache.commons.lang3.StringUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Service;import javax.annotation.Resource;import java.security.NoSuchAlgorithmException;import java.util.Date;import java.util.HashMap;import java.util.Map;/** * @version V1.0 * @author: Jelly * @description: * @date: 2019-03-20 15:31 **/@Servicepublic class SmsService implements ISmsService &#123; @Value("$&#123;aliyun.sms.template-code&#125;") private String templateCode; @Resource private RedisService redisService; @Autowired private AliSmsSendTool aliSmsSendTool; /** * 发送短信服务 * * @param mobile * @return */ public Result sendMessage(String mobile) throws NoSuchAlgorithmException &#123; if (StringUtils.isEmpty(mobile)) &#123; return Result.buildFailure(ErrorStatus.MISSING_ARGUMENT); &#125; String identifyCode; //1. 判断是否缓存该账号验证码 String returnCode = (String) redisService.get(Constants.SMS_AUTH_CODE + Tools.MD5(Constants.SMS_AUTH_CODE + mobile)); if (!StringUtils.isEmpty(returnCode)) &#123; LogUtils.info(SmsService.class, LogTypeEnum.REDIS, "Redis中存在验证码 "); identifyCode = returnCode.substring(Constants.SMS_CODE_LENGTH); &#125; else &#123; identifyCode = Tools.smsCodeUtil(); LogUtils.info(SmsService.class, LogTypeEnum.TOOLS, "生成新的验证码 "); &#125; //2.发送短信 Map&lt;String, String&gt; codeMap = new HashMap&lt;&gt;(); codeMap.put("code", identifyCode); AliSmsSendTool.SendResult response; try &#123; response = sendSms(mobile, templateCode, JSON.toJSONString(codeMap)); //短信发送成功后存入redis if (response != null &amp;&amp; Constants.SMS_SEND_STATUS_OK.equalsIgnoreCase(response.getSendSmsResponse().getCode())) &#123; boolean redis = redisService.set(Constants.SMS_AUTH_CODE + Tools.MD5(Constants.SMS_AUTH_CODE + mobile), identifyCode + mobile, Constants.SMS_EXPIRE_TIME ); if (!redis) &#123; LogUtils.error(SmsService.class, LogTypeEnum.REDIS, "Redis存储错误 "); return Result.buildFailure(ErrorStatus.INTERNAL_SERVER_ERROR); &#125; else &#123; return Result.buildSuccess(response); &#125; &#125; return Result.buildFailure(ErrorStatus.SERVICE_EXCEPTION); &#125; catch (Exception e) &#123; LogUtils.error(SmsService.class, LogTypeEnum.SMS, "sendMessage method invoke error: ", e.getMessage()); &#125; return Result.buildFailure(ErrorStatus.INTERNAL_SERVER_ERROR); &#125; /** * 发送短信接口 * * @param mobile 手机号 * @param templeteCode 模板代码 * @param param 模板替换参数 * @return 发送结果 * @throws ClientException 异常 */ @Override public AliSmsSendTool.SendResult sendSms(String mobile, String templeteCode, String param) throws ClientException &#123; AliSmsSendTool.SMS sms = AliSmsSendTool.newSMS(); sms.setPhoneNumbers(mobile); sms.setTemplateParam(param);//code有要求 "message":"params must be [a-zA-Z0-9] for verification sms" sms.setTemplateCode(templeteCode); AliSmsSendTool.SendResult sendResult = aliSmsSendTool.sendSms(sms); if (sendResult == null || !sendResult.getSendSmsResponse().getCode().equals(Constants.SMS_SEND_STATUS_OK)) &#123; LogUtils.error(SmsService.class, LogTypeEnum.SMS, "发送短信失败 ", sendResult); return null; &#125; LogUtils.info(SmsService.class, LogTypeEnum.SMS, "发送短信 成功 ", sendResult); return sendResult; &#125; /** * 判断验证码是否正确 * * @param mobile * @param identifyCode * @return */ public Boolean checkIsCorrectCode(String mobile, String identifyCode) throws NoSuchAlgorithmException &#123; if (StringUtils.isEmpty(mobile) || StringUtils.isEmpty(identifyCode)) &#123; LogUtils.error(SmsService.class, LogTypeEnum.SMS, "验证码校验失败，手机号或验证码错误"); return false; &#125; String returnCode = null; returnCode = (String) redisService.get(Constants.SMS_AUTH_CODE + Tools.MD5(Constants.SMS_AUTH_CODE + mobile)); if (!StringUtils.isEmpty(returnCode) &amp;&amp; returnCode.substring(0, Constants.SMS_CODE_LENGTH).equals(identifyCode) &amp;&amp; returnCode.substring(Constants.SMS_CODE_LENGTH).equals(mobile)) &#123; LogUtils.info(SmsService.class, LogTypeEnum.SMS, "验证码校验成功"); return true; &#125; LogUtils.error(SmsService.class, LogTypeEnum.SMS, "验证码校验失败"); return false; &#125; /** * 查询短信发送明细 * * @param phoneNumber * @param bizId * @return * @throws ClientException */ @Override public Result querySendDetails(String phoneNumber, String bizId) throws ClientException &#123; AliSmsSendTool.Query query = new AliSmsSendTool.Query(); query.setBizId(bizId); query.setCurrentPage(1L); query.setPageSize(10L); query.setPhoneNumber(phoneNumber); query.setSendDate(new Date());// // 查询发送结果 AliSmsSendTool.QueryResult queryResult = aliSmsSendTool.querySendDetails(query); if (queryResult == null) &#123; LogUtils.error(SmsService.class, LogTypeEnum.SMS, "没有该短信记录 "); return Result.buildFailure(queryResult); &#125; LogUtils.info(SmsService.class, LogTypeEnum.SMS, "查找短信记录成功 "); return Result.buildSuccess(queryResult); &#125;&#125; 发送短信controller类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import com.qingtengcloud.daisy.protocol.Result;import com.qingtengcloud.daisy.service.ISmsService;import com.qingtengcloud.daisy.utils.AliSmsSendTool;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;import java.security.NoSuchAlgorithmException;/** * @version V1.0 * @author: Jelly * @description: * @date: 2019-03-13 12:31 **/@RestControllerpublic class AliSmsSendController &#123; @Autowired private AliSmsSendTool aliSmsSendTool; @Resource private ISmsService smsService; /** * 发送短信验证码 * * @param mobile 手机号 * @return */ @RequestMapping("/sms/sendMessage") public Object sendMessage(@RequestParam String mobile) throws NoSuchAlgorithmException &#123; return smsService.sendMessage(mobile); &#125; /** * 判断验证码是否正确 * * @param mobile 手机号 * @param identifyCode 确认码 * @return */ @RequestMapping("/sms/checkIsCorrectCode") public Object checkIsCorrectCode(@RequestParam String mobile, @RequestParam String identifyCode) throws NoSuchAlgorithmException &#123; Boolean isOk = smsService.checkIsCorrectCode(mobile, identifyCode); if (isOk)&#123; return Result.buildSuccess("isOk"); &#125; return Result.buildFailure("Fail"); &#125; @GetMapping("/sms/auto") public Object smsTest() &#123; String mobile = "18846816914"; String templateCode = "SMS_160220108"; AliSmsSendTool.SMS sms = AliSmsSendTool.newSMS(); sms.setPhoneNumbers(mobile); sms.setTemplateParam("&#123;\"code\":\"fwzd\"&#125;");//code有要求 "message":"params must be [a-zA-Z0-9] for verification sms" sms.setTemplateCode(templateCode); AliSmsSendTool.SendResult sendResult = aliSmsSendTool.sendSms(sms);// 由于响应不及时，不能在这里构建查询，直接查询，smsSendDetailDTOs 会获取到null，// 可以选择在别处查询，保证用户良好体验，系统响应快。考虑异步方法 线程睡眠5秒再查询，结果保存数据库进行持久化// // 构建查询// AliSmsSendTool.Query query = new AliSmsSendTool.Query();// query.setBizId(sendResult.getSendSmsResponse().getBizId());// query.setCurrentPage(1L);// query.setPageSize(10L);// query.setPhoneNumber(sms.getPhoneNumbers());// query.setSendDate(new Date());//// // 查询发送结果// AliSmsSendTool.QueryResult queryResult= aliSmsSendTool.querySendDetails(query); return sendResult; &#125;&#125;]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>框架</tag>
        <tag>redis</tag>
        <tag>springboot</tag>
        <tag>验证码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot-使用枚举整合性别等]]></title>
    <url>%2Fspringb-enum-gender%2F</url>
    <content type="text"><![CDATA[使用背景在项目中需要将数据库中的gender（1男，0女），读取时做一个转换，转换为文字 男、女。同时，有另一个字段 info_tpye(三个不同的类型，数据库存储的是 1，2，3，但是需要展示对应的文字信息)。于是，使用bean对象集成枚举，在读取、插入数据时进行转换。 《阿里巴巴Java开发手册》将接口中枚举的使用分为两类，即 接口参数和接口返回值，并规定： 接口参数可以使用枚举类型，但接口返回值不可以使用枚举类型（包括含枚举类型的POJO对象）。 小小讨论： Java中出现的任何元素，在Gosling的角度都会有背后的思考和逻辑（尽管并非绝对完美，但Java的顶层抽象已经是天才级了），比如：接口、抽象类、注解、和本文提到的枚举。枚举有好处，类型安全，清晰直接，还可以使用等号来判断，也可以用在switch中。它的劣势也是明显的，就是不要扩展。可是为什么在返回值和参数进行了区分呢，如果不兼容，那么两个都有问题，怎么允许参数可以有枚举。当时的考虑，如果参数也不能用，那么枚举几乎无用武之地了。参数输出，毕竟是本地决定的，你本地有的，传送过去，向前兼容是不会有问题的。但如果是接口返回，就比较恶心了，因为解析回来的这个枚举值，可能本地还没有，这时就会抛出序列化异常。 比如：你的本地枚举类，有一个天气Enum：SUNNY, RAINY, CLOUDY，如果根据天气计算心情的方法：guess(WeatcherEnum xx)，传入这三个值都是可以的。返回值：Weather guess(参数)，那么对方运算后，返回一个SNOWY，本地枚举里没有这个值，傻眼了 定义接口 和 枚举类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public interface ValueEnum&lt;T&gt; &#123; T value();&#125;public interface DescriptionEnum &#123; String description();&#125;public enum Gender implements ValueEnum&lt;Integer&gt;,DescriptionEnum &#123; /** * 性别男 */ MALE(1,"男"), /** * 性别女 */ FEMALE(2,"女"); private Integer value; private String description; Gender(Integer value,String description) &#123; this.value = value; this.description = description; &#125; @Override public String description() &#123; return description; &#125; @Override public Integer value() &#123; return value; &#125; &#125;``` 有个使用Gender的pojo类User（@Data为lombok注解）```java@Datapublic class User &#123; private Long id; private String name; private Gender gender; private String email;&#125; 使用枚举作为接口参数 Spring 默认使用Bean接收枚举参数时支持 字面量，这也是我们常见的做法。 12345678910111213141516@Datapublic class UserCommand &#123; private String name; private Gender gender; private String email;&#125; @ApiOperation("添加用户") @PostMapping("/users") public User users(User command)&#123; User user = new User(); BeanUtils.copyProperties(command,user); return user; &#125; 注意这种方式不支持枚举的ordinal值 使用Json接收枚举参数Json数据都放在请求体中，后台使用注解 @RequestBody+command bean接收（也可以从HttpServletRequest的getInputStream获取） 1234567@ApiOperation("添加用户")@PostMapping("/users")public User users(@RequestBody UserCommand userCommand) &#123; User user = new User(); BeanUtils.copyProperties(userCommand,user); return user;&#125; 这种方式支持字面量，ordinary 自定义@RequestBody 和@ResponseBody处理枚举参数单独使用@JsonValue 123456789101112131415161718192021222324252627282930public enum Gender implements ValueEnum&lt;Integer&gt;,DescriptionEnum&#123; /** * 性别男 */ MALE(10,"男"), /** * 性别女 */ FEMALE(20,"女"); private Integer value; private String description; Gender(Integer value,String description) &#123; this.value = value; this.description = description; &#125; @Override public String description() &#123; return description; &#125; @JsonValue @Override public Integer value() &#123; return value; &#125;&#125; @JsonValue 决定了序列化的字段，表明该枚举类型只能使用该字段值传值。它可标注在字段和getter方法上，推荐标注在getter方法上。因为标注在字段上，swagger参数列表只显示字面值，但实际不能使用字面值传值，这样会给使用该接口的开发人员造成误解。标注value字段上: 标注在value方法上 这种方案虽然简单，但是只能单独使用某个字段传值。 使用@JsonValue+@JsonCreator,代码如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public enum Gender implements ValueEnum&lt;Integer&gt;,DescriptionEnum&#123; /** * 性别男 */ MALE(10,"男"), /** * 性别女 */ FEMALE(20,"女"); private Integer value; private String description; Gender(Integer value,String description) &#123; this.value = value; this.description = description; &#125; @JsonValue @Override public String description() &#123; return description; &#125; @Override public Integer value() &#123; return value; &#125; @JsonCreator public static Gender create(String value)&#123; try&#123; return Gender.valueOf(value); &#125;catch (IllegalArgumentException e)&#123; for (Gender gender : Gender.values()) &#123; try &#123; if (gender.value.equals(Integer.parseInt(value))) &#123; return gender; &#125; &#125;catch (NumberFormatException n) &#123; if (gender.description.equals(value)) &#123; return gender; &#125; &#125; &#125; throw new IllegalArgumentException("No element matches "+value); &#125; &#125;&#125; @JsonValue 是可选的，标注在getter方法上或者字段上，但是标注字段上Swagger显示参数不起作用，它可决定枚举反序列化的字段。如下 @JsonCreator 标注在静态方法上，表明使用该方法序列化和反序列化，方法内部是序列化的逻辑 上面的示例代码可使用三种方式传值。枚举类型的字面值，value属性或description属性，。这种方案就比较灵活可以任意决定一个或多个字段传值 示例配置文件123# application.properties中mybatis-plus.type-handlers-package=com.qingtengcloud.utils.enumHandlermybatis-plus.type-enums-package=com.qingtengcloud.utils.enums bean对象12345678910111213141516171819202122232425262728public class BTenant &#123; /** * 主键 */ private Long id; /** * 租客名称 */ private String name; /** * 手机号码 */ private String mobile; /** * 性别：1男 2女 */ private GenderEnum gender; /** * 0 无类型 1-有效未推送、2-蛋壳无效、3-其他 */ private BTenantInfoTypeEnum infoType; ****get、set方法 枚举类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134public enum GenderEnum &#123; OTHER("0", "未知"), MAN("1", "男"), FEMALE("2", "女"); private String key; private String value; private static Map&lt;String, GenderEnum&gt; genderEnumMap = new HashMap&lt;&gt;(); static &#123; for (GenderEnum sexEnum : GenderEnum.values()) &#123; genderEnumMap.put(sexEnum.getKey(), sexEnum); &#125; &#125; /** * 私有化构造函数 * * @param key * @param value */ private GenderEnum(String key, String value) &#123; this.key = key; this.value = value; &#125; /** * @param key * @return * @Title: getGenderEnumByKey * @Description: 依据key获取枚举 */ public static GenderEnum getGenderEnumByKey(String key) &#123; return genderEnumMap.get(key); &#125; public String getKey() &#123; return key; &#125; public void setKey(String key) &#123; this.key = key; &#125; @JsonValue public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; @JsonCreator public static GenderEnum create(String value)&#123; try&#123; return GenderEnum.valueOf(value); &#125;catch (IllegalArgumentException e)&#123; for (GenderEnum gender : GenderEnum.values()) &#123; try &#123; if (gender.value.equals(Integer.parseInt(value))) &#123; return gender; &#125; &#125;catch (NumberFormatException n) &#123; if (gender.value.equals(value)) &#123; return gender; &#125; &#125; &#125; throw new IllegalArgumentException("No element matches "+value); &#125; &#125;&#125;``` ## 枚举控制器```javapublic class GenderEnumHandler extends BaseTypeHandler&lt;GenderEnum&gt; &#123; /** * 用于定义设置参数时，该如何把Java类型的参数转换为对应的数据库类型 */ @Override public void setNonNullParameter(PreparedStatement ps, int i, GenderEnum parameter, JdbcType jdbcType) throws SQLException &#123; // baseTypeHandler已经帮我们做了parameter的null判断 // 第二个参数 : 存入到数据库中的值 ps.setString(i, parameter.getKey()); &#125; /** * 用于定义通过字段名称获取字段数据时，如何把数据库类型转换为对应的Java类型 */ @Override public GenderEnum getNullableResult(ResultSet rs, String columnName) throws SQLException &#123; // 根据数据库存储类型决定获取类型，本例子中数据库中存放String类型 String key = rs.getString(columnName); if (rs.wasNull()) &#123; return null; &#125; else &#123; // 根据数据库中的key值，定位GenderEnum子类 return GenderEnum.getGenderEnumByKey(key); &#125; &#125; /** * 用于定义通过字段索引获取字段数据时，如何把数据库类型转换为对应的Java类型 */ @Override public GenderEnum getNullableResult(ResultSet rs, int columnIndex) throws SQLException &#123; // 根据数据库存储类型决定获取类型，本例子中数据库中存放String类型 String key = rs.getString(columnIndex); if (rs.wasNull()) &#123; return null; &#125; else &#123; // 根据数据库中的key值，定位GenderEnum子类 return GenderEnum.getGenderEnumByKey(key); &#125; &#125; /** * 用定义调用存储过程后，如何把数据库类型转换为对应的Java类型 */ @Override public GenderEnum getNullableResult(CallableStatement cs, int columnIndex) throws SQLException &#123; // 根据数据库存储类型决定获取类型，本例子中数据库中存放String类型 String key = cs.getString(columnIndex); if (cs.wasNull()) &#123; return null; &#125; else &#123; // 根据数据库中的key值，定位GenderEnum子类 return GenderEnum.getGenderEnumByKey(key); &#125; &#125;&#125;]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>枚举映射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis-plus入坑指南]]></title>
    <url>%2Fmybatis-plusStart%2F</url>
    <content type="text"><![CDATA[mybatis-plus入坑指南简介 MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。 特性 无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错 支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer2005、SQLServer 等多种数据库 支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题 支持 XML 热加载：Mapper 对应的 XML 支持热加载，对于简单的 CRUD 操作，甚至可以无 XML 启动 支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作 支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ） 支持关键词自动转义：支持数据库关键词（order、key……）自动转义，还可自定义关键词 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用 内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询 内置性能分析插件：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询 内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作 内置 Sql 注入剥离器：支持 Sql 注入剥离，有效预防 Sql 注入攻击 框架结构 好了官网的简介完了，附上github地址：Mybatis-plus的GIthub基本使用 代码生成器，又被叫做逆向工程，MyBatis官方为了推广，自己也写了一个，我之前也使用这个，功能也是非常强大，强大以为支持自定义配置，那么问题来了，我该怎么配置才合理呢，所以，有人把所有的配置项都弄成中文的，还有人开发了生成插件，这些在我以往的博文中都看看到。MyBatis-Plus的代码生成器到底怎么样，这我就不评判了，我就这样说，用用看吧。 在MyBatis-Plus的官网文档中，有将代码生成器的问题，有配置详解，也有项目示例代码，复制来就可用。 功能列表： 自动生成model类 自动生成dao接口 自动生成xml文件 自动生成service接口 自动生成service实现类 model支持Builder模式 支持swagger2 支持生成数据库字段常量 支持生成Kotlin代码 [] …… 安装添加依赖无论SSM项目还是SpringBoot项目，在原来基础上添加以下依赖 12345678910&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; 添加包扫描springboot项目 在启动类上使用注解扫描mapper包（dao层）(Spring Boot项目) 1@MapperScan("com.xxx.xxxx.mapper") springMvc项目 配置 MapperScan 123&lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.baomidou.mybatisplus.samples.quickstart.mapper"/&gt; &lt;/bean&gt; 调整 SqlSessionFactory 为 MyBatis-Plus 的 SqlSessionFactory 123&lt;bean id="sqlSessionFactory" class="com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"/&gt;&lt;/bean&gt; 警告WARNING 引入 MyBatis-Plus 之后请不要再次引入 MyBatis 以及 MyBatis-Spring，以避免因版本差异导致的问题。 Mybatis-plus的配置在application.yml中添加数据源1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# DataSource Configspring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/test?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8&amp;characterSetResults=utf8 username: root password:# Logger Configlogging: level: com.mybatisplus.demo03: debug#MP所支持的application.yml设置 具体参考官方文档https://jobob.gitee.io/mp3doc/中设置部分mybatis-plus:# config-location: classpath:mybatis/mybatis-config.xml #如果需要使用原生mybatis设置文件，则这里需要指明具体路径# mapper-locations: classpath:/mybatis/mapper/*DAO.xml #在resource目录下的写法# mapper-locations: classpath:/com/mpspringboot/mapper/xml/*Mapper.xml #在src/main/java下的写法(同时配置POM文件中source属性)# mapper-locations: classpath*:/mybatis/mapper/*DAO.xml #Maven多项目模块下使用classpath*写法# type-aliases-package: com.XX.entity #设置类名别名扫描位置，设置后可使用类名替代全限定类名，多个package用逗号或者分号分隔# type-aliases-super-type: java.lang.Object #请和typeAliasesPackage一起使用，设置后仅会扫描路径下以该类作为父类的域对象 。# type-handlers-package: com.XX.handler #设置类型转换类所在的包位置# type-enums-package: com.XX.enums #枚举字段扫描，支持实体的枚举字段# check-config-location: false #启动时是否检查 MyBatis XML 文件的存在，默认不检查。# executor-type: simple #通过该属性可指定 MyBatis 的执行器，默认值为SIMPLE，MyBatis 的执行器总共有三种：# ExecutorType.SIMPLE：该执行器类型不做特殊的事情，为每个语句的执行创建一个新的预处理语句（PreparedStatement）# ExecutorType.REUSE：该执行器类型会复用预处理语句（PreparedStatement）# ExecutorType.BATCH：该执行器类型会批量执行所有的更新语句# configuration-properties: classpath:mybatis/config.properties #指定外部化 MyBatis Properties 配置，通过该配置可以抽离配置，实现不同环境的配置部署。 #MyBatis-Plus 全局策略配置 global-config: refresh: true #启动后，修改Target中的XML即可更新对应Mapper的逻辑，用于调试；生产中不要启动# sql-parser-cache: true #是否缓存 Sql 解析，默认不缓存。# sql-session: com.xxx.SqlSession #单例重用 SqlSession# sql-session-factory: com.xxx.SqlSessionFactory # #全局配置中关于DB的设置 db-config: db-type: MYSQL #数据库类型 capital-mode: true #是否开启大写命名，开启后生成SQL语句都为大写；默认不开启。# table-prefix: sys #生成的SQL会在表名上增加此前缀 table-underline: true #生成的SQL语句中，表名是否自动加入驼峰转下划线（如SystemUser=&gt;system_user） field-strategy: NOT_NULL #字段更新插入策略 0:"忽略判断",1:"非 NULL 判断"),2:"非空判断"# IGNORED：所有字段都更新和插入# NOT_NULL：只更新和插入非NULL值# NOT_EMPTY：只更新和插入非NULL值且非空字符串# DEFAULT：默认NOT_NULL id-type: UUID #主键类型 0:"数据库ID自增", 1:"用户输入ID",2:"全局唯一ID (数字类型唯一ID)", 3:"全局唯一ID UUID";# AUTO(0)：MP自动决定# NONE(1)：生成语句插入null，需要数据库自增时可以使用# INPUT(2)：根据用户输入值# ID_WORKER(3)：全局唯一ID (数字类型唯一ID)# UUID(4)：全局唯一ID UUID# ID_WORKER_STR(5)：全局唯一ID (字符型类型唯一ID) column-like: false #逻辑删除字段表示未删除的值 logic-delete-value: 1 #逻辑删除字段表示删除的值 logic-not-delete-value: 0 #逻辑删除字段表示未删除的值 #一部分对原生MyBatis所支持的配置，我建议使用config-location加mybatis-config.xml实现比较清晰，不要在这里使用# configuration:# mapUnderscoreToCamelCase: true #默认true，是否开启自动驼峰命名规则（camel case）映射，即从经典数据库列名 A_COLUMN 到经典 Java 属性名 aColumn 的类似映射。# aggressive-lazy-loading: true #当设置为 true 的时候，懒加载的对象可能被任何懒属性全部加载，否则，每个属性都按需加载。需要和 lazyLoadingEnabled 一起使用。# auto-mapping-unknown-column-behavior: none #MyBatis 自动映射策略，通过该配置可指定 MyBatis 是否并且如何来自动映射数据表字段与对象的属性，总共有 3 种可选值：# AutoMappingBehavior.NONE：不启用自动映射# AutoMappingBehavior.PARTIAL：只对非嵌套的 resultMap 进行自动映射# AutoMappingBehavior.FULL：对所有的 resultMap 都进行自动映射# auto-mapping-behavior: partial #MyBatis 自动映射时未知列或未知属性处理策略，通过该配置可指定 MyBatis 在自动映射过程中遇到未知列或者未知属性时如何处理，总共有 3 种可选值：# AutoMappingUnknownColumnBehavior.NONE：不做任何处理 (默认值)# AutoMappingUnknownColumnBehavior.WARNING：以日志的形式打印相关警告信息# AutoMappingUnknownColumnBehavior.FAILING：当作映射失败处理，并抛出异常和详细信息# cache-enabled: true #全局地开启或关闭配置文件中的所有映射器已经配置的任何缓存，默认为 true。# call-setters-on-nulls: false #指定当结果集中值为 null 的时候是否调用映射对象的 Setter（Map 对象时为 put）方法，通常运用于有 Map.keySet() 依赖或 null 值初始化的情况。# 通俗的讲，即 MyBatis 在使用 resultMap 来映射查询结果中的列，如果查询结果中包含空值的列，则 MyBatis 在映射的时候，不会映射这个字段，这就导致在调用到该字段的时候由于没有映射，取不到而报空指针异常。# 当您遇到类似的情况，请针对该属性进行相关配置以解决以上问题。# WARNING# 基本类型（int、boolean 等）是不能设置成 null 的。# configuration-factory: com.xxx.SampleConfigurationFactory #指定一个提供 Configuration 实例的工厂类。 #该工厂生产的实例将用来加载已经被反序列化对象的懒加载属性值，其必须包含一个签名方法static Configuration getConfiguration()。（从 3.2.3 版本开始） 或者 12345678mybatis-plus: # xml mapper-locations: classpath:mapper/*Mapper.xml # 实体扫描，多个package用逗号或者分号分隔 type-aliases-package: com.fengwenyi.mp3demo.model configuration: # 这个配置会将执行的sql打印出来，在开发或测试的时候可以用 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 将sql打印在控制台中 核心功能代码生成器① 添加依赖 AutoGenerator 是 MyBatis-Plus 的代码生成器，通过 AutoGenerator 可以快速生成 Entity、Mapper、Mapper XML、Service、Controller 等各个模块的代码，极大的提升了开发效率。 1234567891011&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;最新版本&lt;/version&gt;&lt;/dependency&gt;&lt;!-- freemarker 模板引擎 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;最新版本&lt;/version&gt;&lt;/dependency&gt; ② Generator类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class MysqlGenerator &#123; //要生成的表，及输出路径 static String[] TO_CREATE_TABLES = new String[]&#123;"block", "channel_origin", "channel_target", "order", "tenant", "user", "oauth_user", "oauth_session_key"&#125;; static String BASE_OUT_PUT_DIR = "src/main/java"; static String XML_OUT_PUT_DIR = "src/main/resources/mapper"; static String AUTHOR = "Jelly"; //配置数据源 static String DATA_SOURCE_URL = "jdbc:mysql://localhost:3306/qingteng?useUnicode=true&amp;useSSL=false&amp;characterEncoding=utf8&amp;serverTimezone=GMT%2B8"; static String DATA_SOURCE_DRIVER = "com.mysql.cj.jdbc.Driver"; static String DATA_SOURCE_USER = "root"; static String DATA_SOURCE_PASSWORD = "123456"; //生成表的父类 static String SUPER_CONTROLLER = "com.qingtengcloud.web.v1.base.BaseController"; public static void main(String[] args) &#123; /** * 代码生成器 * */ AutoGenerator mpg = new AutoGenerator(); /** * 包配置 */ PackageConfig pc = new PackageConfig(); pc.setParent("com.qingtengcloud"); //父包名。如果为空，将下面子包名必须写全部， 否则就只需写子包名 pc.setEntity("bean"); pc.setController("web.v1"); pc.setMapper("dao"); pc.setXml("mapper"); mpg.setPackageInfo(pc); /** * 全局配置 * */ GlobalConfig gc = new GlobalConfig(); String projectPath = System.getProperty("user.dir"); gc.setOpen(false);// 否打开输出目录 gc.setOutputDir(BASE_OUT_PUT_DIR); //生成文件的输出目录 gc.setFileOverride(false);// 是否覆盖文件 gc.setActiveRecord(true); //开启 activeRecord gc.setEnableCache(false);// xml 二级缓存 gc.setBaseResultMap(true); //xml resultMap gc.setBaseColumnList(true);//xml columList gc.setDateType(DateType.SQL_PACK); gc.setAuthor(AUTHOR); gc.setXmlName("%sMapper");//Mapper xml 命名方式 gc.setMapperName("%sMapper");//mapper 命名方式 gc.setServiceName("%sService");//service 命名方式 gc.setServiceImplName("%sServiceImpl");//service impl 命名方式 gc.setControllerName("%sController");//controller 命名方式 mpg.setGlobalConfig(gc); /** * 数据源配置 */ DataSourceConfig dsc = new DataSourceConfig(); dsc.setUrl(DATA_SOURCE_URL); // dsc.setSchemaName("public"); dsc.setDriverName(DATA_SOURCE_DRIVER); dsc.setUsername(DATA_SOURCE_USER); dsc.setPassword(DATA_SOURCE_PASSWORD); mpg.setDataSource(dsc); /** * 自定义配置 */ InjectionConfig cfg = new InjectionConfig() &#123; @Override public void initMap() &#123; // to do nothing &#125; &#125;; List&lt;FileOutConfig&gt; focList = new ArrayList&lt;&gt;(); focList.add(new FileOutConfig("templates/mapper.xml.ftl") &#123; @Override public String outputFile(TableInfo tableInfo) &#123; // 自定义输入文件名称 return XML_OUT_PUT_DIR + "/" + tableInfo.getEntityName() + "Mapper" + StringPool.DOT_XML; &#125; &#125;); cfg.setFileOutConfigList(focList); mpg.setCfg(cfg); mpg.setTemplate(new TemplateConfig().setXml(null)); /** * 策略配置 */ StrategyConfig strategy = new StrategyConfig(); strategy.setNaming(NamingStrategy.underline_to_camel); //数据库表名映射策略，下划线转驼峰命名 strategy.setColumnNaming(NamingStrategy.underline_to_camel); //数据库表字段映射到实体的命名策略，下划线转驼峰命名 strategy.setInclude(TO_CREATE_TABLES);//需要包含的表名，允许正则表达式（与exclude二选一配置）// strategy.setExclude(new String[]&#123;"test"&#125;); // 排除生成的表 strategy.setEntityBuilderModel(true);//是否为构建者模型 strategy.setEntityLombokModel(true); //是否为lombok模型 strategy.setSuperControllerClass(SUPER_CONTROLLER);//自定义继承的Controller类全称，带包名 strategy.setControllerMappingHyphenStyle(true);// Controller中驼峰转连字符 strategy.setRestControllerStyle(true); //生成 @RestController 控制器 strategy.setTablePrefix(pc.getModuleName() + "_");//表前缀 mpg.setStrategy(strategy); // 选择 freemarker 引擎需要指定如下加，注意 pom 依赖必须有！ mpg.setTemplateEngine(new FreemarkerTemplateEngine()); mpg.execute(); &#125;&#125; CRUD接口Mapper CRUD 接口说明: 通用 CRUD 封装BaseMapper接口，为 Mybatis-Plus 启动时自动解析实体表关系映射转换为 Mybatis 内部对象注入容器 泛型 T 为任意实体对象 参数 Serializable 为任意类型主键 Mybatis-Plus 不推荐使用复合主键约定每一张表都有自己的唯一 id 主键 对象 Wrapper 为 条件构造器 Service CRUD 接口说明: 通用 Service CRUD 封装IService接口，进一步封装 CRUD 采用 get 查询单行 remove 删除 list 查询集合 page 分页 前缀命名方式区分 Mapper 层避免混淆， 泛型 T 为任意实体对象 建议如果存在自定义通用 Service 方法的可能，请创建自己的 IBaseService 继承 Mybatis-Plus 提供的基类 对象 Wrapper 为 条件构造器 条件构造器示例： 12345public List&lt;Order&gt; orderPagingQueryStatus2() &#123; QueryWrapper&lt;Order&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.lambda().eq(Order::getStatus, 0).gt(Order::getCreatedAt,"2019-02-25 12:00:00"); return list(queryWrapper);&#125; 分页插件1234567&lt;!-- spring xml 方式 --&gt;&lt;plugins&gt; &lt;plugin interceptor="com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor"&gt; &lt;property name="sqlParser" ref="自定义解析类、可以没有" /&gt; &lt;property name="dialectClazz" value="自定义方言类、可以没有" /&gt; &lt;/plugin&gt;&lt;/plugins&gt; 1234567891011121314//Spring boot方式@EnableTransactionManagement@Configuration@MapperScan("com.baomidou.cloud.service.*.mapper*")public class MybatisPlusConfig &#123; /** * 分页插件 */ @Bean public PaginationInterceptor paginationInterceptor() &#123; return new PaginationInterceptor(); &#125;&#125; 示例： 123456789101112131415161718192021222324252627282930313233343536373839Mapper.java /** * 包含街区、租客多表查询(注解和xml同时存在的时候，跳过注解) * @param page 分页 * @return */ List&lt;Order&gt; orderPagingQuery(Page page, @Param("operateUserId") Long operateUserId);Service.java /** * 订单分页查询 * @param page * @return */ Page&lt;Order&gt; orderPagingQuery(Page&lt;Order&gt; page, Long operate_user_id);ServiceImpl.java /** * 订单分页查询 * @param page * @return */ @Override public Page&lt;Order&gt; orderPagingQuery(Page&lt;Order&gt; page, Long operateUserId) &#123; return page.setRecords(this.baseMapper.orderPagingQuery(page, operateUserId)); &#125; Controller.java @GetMapping(value = "/orders" ) public Object orders(@RequestParam(value = "page", defaultValue = "1") Integer pn, @RequestParam(value = "size", defaultValue = "10") Integer pageSize, Principal principal) &#123; //获取当前用户的订单,需要另外写 long operate_user_id = userService.selectUserByMobile(principal.getName()).getId(); //利用mybatis-plus的分页查询 Page&lt;Order&gt; obt = orderService.orderPagingQuery(new Page&lt;&gt;(pn, pageSize), operate_user_id); return new RetResult(obt); &#125; 同时可以自定义分页 UserMapper.java12345678910111213public interface UserMapper&#123;//可以继承或者不继承BaseMapper /** * &lt;p&gt; * 查询 : 根据state状态查询用户列表，分页显示 * 注意!!: 如果入参是有多个,需要加注解指定参数名才能在xml中取值 * &lt;/p&gt; * * @param page 分页对象,xml中可以从里面进行取值,传递参数 Page 即自动分页,必须放在第一位(你可以继承Page实现自己的分页对象) * @param state 状态 * @return 分页对象 */ IPage&lt;User&gt; selectPageVo(Page page, @Param("state") Integer state);&#125; UserMapper.xml等同于编写一个普通 list 查询，mybatis-plus 自动替你分页 123&lt;select id="selectPageVo" resultType="com.baomidou.cloud.entity.UserVo"&gt; SELECT id,name FROM user WHERE state=#&#123;state&#125;&lt;/select&gt; UserServiceImpl.java调用分页方法 1234567public IPage&lt;User&gt; selectUserPage(Page&lt;User&gt; page, Integer state) &#123; // 不进行 count sql 优化，解决 MP 无法自动优化 SQL 问题，这时候你需要自己查询 count 部分 // page.setOptimizeCountSql(false); // 当 total 为非 0 时(默认为 0),分页插件不会进行 count 查询 // 要点!! 分页返回的对象与传入的对象是同一个 return userMapper.selectPageVo(page, state));&#125; 小问题① 使用条件构造器的orderByDesc()等排序功能时会有，idea会报警告，目前无法解决。]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>框架</tag>
        <tag>mybatis</tag>
        <tag>plugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高频算法题-zs]]></title>
    <url>%2Falg-frequenceCode%2F</url>
    <content type="text"><![CDATA[来源《程序员代码面试指南》左程云著 排序问题小和问题在一个数组中， 每一个数左边比当前数小的数累加起来， 叫做这个数组的小和。 求一个数组的小和。 12345678例子：[1,3,4,2,5]1左边比1小的数， 没有；3左边比3小的数， 1；4左边比4小的数， 1、 3；2左边比2小的数， 1；5左边比5小的数， 1、 3、 4、 2；所以小和为1+1+3+1+1+3+4+2=16 题解： 利用归并排序，在merge的时候计算有几个数比它小。因为分区两边都将是有序的，当左边分组元素小于右边分组元素，将会有 (r - p2 + 1) * arr[p1] 个小数。r为最右边边界，p2为右边分组元素下标，arr[p1] 为左边分组元素，相加则为产生的小和。 因为整体将趋于有序，而且每次merge之后元素都将归入左边，所有之后不会重复计算小和。 1234567891011121314151617181920212223242526272829303132333435public static int smallSum(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return 0; &#125; return mergeSort(arr, 0, arr.length - 1);&#125;public static int mergeSort(int[] arr, int l, int r) &#123; if (l == r) &#123; return 0; &#125; int mid = l + ((r - l) &gt;&gt; 1); return mergeSort(arr, l, mid) + mergeSort(arr, mid + 1, r) + merge(arr, l, mid, r);&#125;public static int merge(int[] arr, int l, int m, int r) &#123; int[] help = new int[r - l + 1]; int i = 0; int p1 = l; int p2 = m + 1; int res = 0; while (p1 &lt;= m &amp;&amp; p2 &lt;= r) &#123; //计算小和 res += arr[p1] &lt; arr[p2] ? (r - p2 + 1) * arr[p1] : 0; help[i++] = arr[p1] &lt; arr[p2] ? arr[p1++] : arr[p2++]; &#125; while (p1 &lt;= m) &#123; help[i++] = arr[p1++]; &#125; while (p2 &lt;= r) &#123; help[i++] = arr[p2++]; &#125; for (i = 0; i &lt; help.length; i++) &#123; arr[l + i] = help[i]; &#125; return res;&#125; 逆序对问题在一个数组中， 左边的数如果比右边的数大， 则折两个数构成一个逆序对， 请打印所有逆序对。 题解： 与上题解题思路一致。将计算小和改为判断 arr[p1] &gt; arr[p2] 如果是，则打印 arr[p1], arr[p2]即可。 相邻两数的最大差值给定一个数组， 求如果排序之后， 相邻两数的最大差值。 要求时间复杂度O(N),且要求不能用非基于比较的排序。 题解： 使用桶排序的概念，在此基础上进行优化。 遍历给定的数组，找到数组中的最大值、最小值(最大值等于最小值时说明，数组中数据都一样，返回 0 ),用于计算桶id。 准备n+1 个桶，对于每个桶中的元素设定三个标志位。是否有数据 hasNum、最大值 maxs、最小值 mins。 再次遍历标志位。第0 个桶一定非空，且为最小值。从第一个桶开始遍历，找到每个非空桶(hasNum[i] 为 true)，非空桶的最小值与它前边最近的非空桶的最大值 作差，与全局变量res作比较。遍历结束之后将得到最大的差值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public static int maxGap(int[] nums) &#123; if (nums == null || nums.length &lt; 2) &#123; return 0; &#125; int len = nums.length; int min = Integer.MAX_VALUE; int max = Integer.MIN_VALUE; for (int i = 0; i &lt; len; i++) &#123; min = Math.min(min, nums[i]); max = Math.max(max, nums[i]); &#125; // 如果最小值等于最大值，则数组中只有相同的数，最大差值为 0. if (min == max) &#123; return 0; &#125; // 计算每个桶中的三个标志位。 boolean[] hasNum = new boolean[len + 1]; int[] maxs = new int[len + 1]; int[] mins = new int[len + 1]; int bid = 0; for (int i = 0; i &lt; len; i++) &#123; bid = bucket(nums[i], len, min, max); mins[bid] = hasNum[bid] ? Math.min(mins[bid], nums[i]) : nums maxs[bid] = hasNum[bid] ? Math.max(maxs[bid], nums[i]) : nums hasNum[bid] = true; &#125; // 从第一个桶开始。寻找不为空的桶，它的最小值和它之前最近的桶的最大值的差值， // 与全局变量res进行比较，遍历完则找到最大差值。 int res = 0; int lastMax = maxs[0]; int i = 1; for (; i &lt;= len; i++) &#123; if (hasNum[i]) &#123; res = Math.max(res, mins[i] - lastMax); lastMax = maxs[i]; &#125; &#125; return res;&#125;// 最小值将存在0号桶，最大值将存在length号桶。public static int bucket(long num, long len, long min, long max) &#123; return (int) ((num - min) * len / (max - min));&#125; 栈和队列数组实现固定大小的队列和栈123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133package com.jelly.algorithm.array;public class Array2QueueStack &#123; public static void main(String[] args) &#123; // 数组实现队列 测试 AQueue aQueue = new AQueue(3); aQueue.offer(1); aQueue.offer(2); aQueue.offer(3); aQueue.offer(4); System.out.println(aQueue.poll()); aQueue.offer(5); System.out.println(aQueue.peek()); // 数组实现栈 测试 AStack aStack = new AStack(3); aStack.push(1); aStack.push(2); aStack.push(3); aStack.push(4); System.out.println(aStack.pop()); aStack.push(5); System.out.println(aStack.peek()); &#125;&#125;/** * 数组实现大小固定的队列。 * &lt;p&gt; * arr：存储队列中的数据。 * size：记录队列中有多少数据了。 * start：记录出队列的位置。每次出start位置上的数据。 * end：记录入队列的位置。每次入队列存入end的位置。 */class AQueue &#123; private int[] arr; private int size; private int start; private int end; public AQueue(int initSize) &#123; this.arr = new int[initSize]; this.size = 0; this.start = 0; this.end = 0; &#125; public boolean offer(Integer n) &#123; if (size == arr.length) &#123; System.out.println("queue is full!"); return false; &#125; size++; arr[end] = n; end = end == arr.length - 1 ? 0 : end + 1; return true; &#125; public Integer poll() &#123; if (size == 0) &#123; System.out.println("queue is empty!"); return null; &#125; size--; int tmp = arr[start]; start = start == arr.length - 1 ? 0 : start + 1; return tmp; &#125; public Integer peek() &#123; if (size == 0) &#123; System.out.println("queue is empty!"); return null; &#125; return arr[start]; &#125;&#125;/** * 数组实现大小固定的栈。 * &lt;p&gt; * arr：存储栈中的数据。 * size：栈中存储多少数据。 */class AStack &#123; private int[] arr; private int size; public AStack(int initSize) &#123; this.arr = new int[initSize]; &#125; public boolean push(Integer n) &#123; if (size == arr.length) &#123; System.out.println("stack is full!"); return false; &#125; arr[size++] = n; return true; &#125; public Integer pop() &#123; if (size == 0) &#123; System.out.println("stack is empty!"); return null; &#125; return arr[--size]; &#125; public Integer peek() &#123; if (size == 0) &#123; System.out.println("stack is empty!"); return null; &#125; return arr[size - 1]; &#125;&#125; 实现返回栈中最小元素实现一个特殊的栈， 在实现栈的基本功能的基础上， 再实现返回栈中最小元素的操作。 要求 pop、 push、 getMin操作的时间复杂度都是O(1)。 设计的栈类型可以使用现成的栈结构。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.jelly.algorithm.array;import java.util.Stack;public class GetMinStack &#123; public static void main(String[] args) &#123; MyStack myStack = new MyStack(); myStack.push(5); myStack.push(1); System.out.println(myStack.getMin()); System.out.println(myStack.pop()); myStack.push(3); myStack.push(8); System.out.println(myStack.getMin()); &#125;&#125;/** * 可以返回栈中最小元素的栈。 * &lt;p&gt; * pop、 push、 getMin操作的时间复杂度都是O(1) */class MyStack &#123; private Stack&lt;Integer&gt; stackData; private Stack&lt;Integer&gt; stackMin; public MyStack() &#123; this.stackData = new Stack&lt;&gt;(); this.stackMin = new Stack&lt;&gt;(); &#125; public void push(Integer n) &#123; // 最小值栈中没有数据直接进栈。 // 栈中有数据判断插入数据n 是否小于当前栈中最小值，小则插入n，否则再次插入栈中最小值 if (stackMin.isEmpty()) &#123; stackMin.push(n); &#125; else if (n &lt;= getMin()) &#123; stackMin.push(n); &#125; else &#123; stackMin.push(getMin()); &#125; stackData.push(n); &#125; public Integer pop() &#123; if (stackData.isEmpty()) &#123; System.out.println("stack is empty!"); return null; &#125; // 弹栈时，数据栈和最小值栈同时弹出。 stackMin.pop(); return stackData.pop(); &#125; public Integer getMin() &#123; if (stackMin.isEmpty()) &#123; System.out.println("stack is empty!!"); return null; &#125; return stackMin.peek(); &#125;&#125; 如何仅用队列结构实现栈结构？见下题 如何仅用栈结构实现队列结构？123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package com.jelly.algorithm.stack;import java.util.LinkedList;import java.util.Queue;import java.util.Stack;public class StackAndQueueConvert &#123; public static void main(String[] args) &#123; // 栈实现队列，应打印 1,2 Stack2Queue stack2Queue = new Stack2Queue(); stack2Queue.offer(1); stack2Queue.offer(2); stack2Queue.offer(3); System.out.println(stack2Queue.poll()); stack2Queue.offer(4); stack2Queue.offer(5); System.out.println(stack2Queue.peek()); System.out.println("----------------------"); // 队列实现栈，应打印 3,5 Queue2Stack queue2Stack = new Queue2Stack(); queue2Stack.push(1); queue2Stack.push(2); queue2Stack.push(3); System.out.println(queue2Stack.pop()); queue2Stack.push(4); queue2Stack.push(5); System.out.println(queue2Stack.peek()); &#125;&#125;/** * 两个栈实现队列 * &lt;p&gt; * 入队列栈中数据倒入出队列栈中的数据时，要保证出队列栈中无数据。 */class Stack2Queue &#123; private Stack&lt;Integer&gt; in; private Stack&lt;Integer&gt; out; public Stack2Queue() &#123; this.in = new Stack&lt;&gt;(); this.out = new Stack&lt;&gt;(); &#125; public void offer(Integer n) &#123; in.push(n); &#125; public Integer poll() &#123; if (out.empty() &amp;&amp; in.empty()) &#123; System.out.println("queue is empty!"); return null; &#125; else if (out.empty()) &#123; while (!in.empty()) &#123; out.push(in.pop()); &#125; &#125; return out.pop(); &#125; public Integer peek() &#123; if (out.empty() &amp;&amp; in.empty()) &#123; System.out.println("queue is empty!"); return null; &#125; else if (out.empty()) &#123; while (!in.empty()) &#123; out.push(in.pop()); &#125; &#125; return out.peek(); &#125;&#125;/** * 两个队列实现栈 * &lt;p&gt; * 入栈直接放入stack这个队列中。 * 每次出栈，将n-1个数据通过help队列保存，返回第n个数据，然后改变help、stack指针 即可。 */class Queue2Stack &#123; private Queue&lt;Integer&gt; stack; private Queue&lt;Integer&gt; help; public Queue2Stack() &#123; this.stack = new LinkedList&lt;&gt;(); this.help = new LinkedList&lt;&gt;(); &#125; public void push(Integer n) &#123; stack.offer(n); &#125; public Integer pop() &#123; if (stack.isEmpty()) &#123; System.out.println("stack is empty!"); return null; &#125; while (stack.size() &gt; 1) &#123; help.offer(stack.poll()); &#125; int res = stack.poll(); swap(); return res; &#125; private void swap() &#123; Queue&lt;Integer&gt; tmp = help; help = stack; stack = tmp; &#125; public Integer peek() &#123; if (stack.isEmpty()) &#123; System.out.println("stack is empty!"); return null; &#125; while (stack.size() &gt; 1) &#123; help.offer(stack.poll()); &#125; int res = stack.poll(); // peek 不删除，需加上res help.offer(res); swap(); return res; &#125;&#125; 猫狗队列1234567891011121314151617181920212223public class Pet &#123; private String type; public Pet(String type) &#123; this.type = type; &#125; public String getPetType() &#123; return this.type; &#125;&#125;public class Dog extends Pet &#123; public Dog() &#123; super("dog"); &#125;&#125;public class Cat extends Pet &#123; public Cat() &#123; super("cat"); &#125;&#125; 实现一种狗猫队列的结构， 要求 用户可以调用add方法将cat类或dog类的实例放入队列中； 用户可以调用pollAll方法，将队列中所有的实例按照进队列的先后顺序依次弹出； 用户可以调用pollDog方法，将队列中dog类的实例按照进队列的先后顺序依次弹出； 用户可以调用pollCat方法，将队列中cat类的实例按照进队列的先后顺序依次弹出； 用户可以调用isEmpty方法， 检查队列中是否还有dog或cat的实例； 用户可以调用isDogEmpty方法，检查队列中是否有dog类的实例； 用户可以调用isCatEmpty方法， 检查队列中是否有cat类的实例。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151package com.jelly.algorithm.queue;import java.util.LinkedList;import java.util.Queue;public class CatDogQueue &#123; private Queue&lt;PetEntity&gt; catQ; private Queue&lt;PetEntity&gt; dogQ; private Long count; public CatDogQueue() &#123; this.catQ = new LinkedList&lt;&gt;(); this.dogQ = new LinkedList&lt;&gt;(); this.count = 0L; &#125; public boolean add(Pet pet) &#123; if (pet.getPetType().equals("cat")) &#123; catQ.add(new PetEntity(pet, this.count++)); return true; &#125; else if (pet.getPetType().equals("dog")) &#123; dogQ.add(new PetEntity(pet, this.count++)); return true; &#125; else &#123; throw new IllegalArgumentException("NOT cat or dog!"); &#125; &#125; public Pet pollAll() &#123; if (!catQ.isEmpty() &amp;&amp; !dogQ.isEmpty()) &#123; if (catQ.peek().getCount() &lt; dogQ.peek().getCount()) &#123; return catQ.poll().getPet(); &#125; else &#123; return dogQ.poll().getPet(); &#125; &#125; else if (!catQ.isEmpty()) &#123; return catQ.poll().getPet(); &#125; else if (!dogQ.isEmpty()) &#123; return dogQ.poll().getPet(); &#125; else &#123; throw new RuntimeException("queue is empty!"); &#125; &#125; public Cat pollCat() &#123; if (catQ.isEmpty()) &#123; throw new RuntimeException("queue is empty!"); &#125; return (Cat) catQ.poll().getPet(); &#125; public Dog pollDog() &#123; if (dogQ.isEmpty()) &#123; throw new RuntimeException("queue is empty!"); &#125; return (Dog) dogQ.poll().getPet(); &#125; public boolean isEmpty() &#123; return catQ.isEmpty() &amp;&amp; dogQ.isEmpty(); &#125; public boolean isCatQueueEmpty() &#123; return catQ.isEmpty(); &#125; public boolean isDogQueueEmpty() &#123; return dogQ.isEmpty(); &#125; public static void main(String[] args) &#123; CatDogQueue test = new CatDogQueue(); Pet dog1 = new Dog(); Pet cat1 = new Cat(); Pet dog2 = new Dog(); Pet cat2 = new Cat(); Pet dog3 = new Dog(); Pet cat3 = new Cat(); test.add(dog1); test.add(cat1); test.add(dog2); test.add(cat2); test.add(dog3); test.add(cat3); test.add(dog1); test.add(cat1); test.add(dog2); test.add(cat2); test.add(dog3); test.add(cat3); test.add(dog1); test.add(cat1); test.add(dog2); test.add(cat2); test.add(dog3); test.add(cat3); while (!test.isDogQueueEmpty()) &#123; System.out.println(test.pollDog().getPetType()); &#125; while (!test.isEmpty()) &#123; System.out.println(test.pollAll().getPetType()); &#125; &#125;&#125;class Pet &#123; private String type; public Pet(String type) &#123; this.type = type; &#125; public String getPetType() &#123; return this.type; &#125;&#125;class Dog extends Pet &#123; public Dog() &#123; super("dog"); &#125;&#125;class Cat extends Pet &#123; public Cat() &#123; super("cat"); &#125;&#125;class PetEntity &#123; private Pet pet; private Long count; public PetEntity(Pet pet, Long count) &#123; this.pet = pet; this.count = count; &#125; public Pet getPet() &#123; return pet; &#125; public Long getCount() &#123; return count; &#125;&#125; 矩阵转圈打印矩阵给定一个整型矩阵matrix， 请按照转圈的方式打印它。 12345678例如：1 2 3 45 6 7 89 10 11 1213 14 15 16 打印结果为： 1，2，3，4，8，12，16，15，14，13，9，5，6，7，11，10 要求额外空间复杂度为O(1)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.jelly.algorithm.matrix;public class RotateMatrix &#123; public static void main(String[] args) &#123; int[][] matrix = &#123;&#123;1, 2, 3, 4&#125;, &#123;5, 6, 7, 8&#125;, &#123;9, 10, 11, 12&#125;, &#123;13, 14, 15, 16&#125;&#125;; int[][] matrix1 = &#123;&#123;3, 4, 5, 8, 0&#125;&#125;; rotate(matrix); &#125; /** * 旋转打印 * 每次层数减一，像剥洋葱一样，一次一层。 * * @param matrix 矩阵 */ public static void spiralOrderPrint(int[][] matrix) &#123; int ar = 0; int ac = 0; int br = matrix.length - 1; int bc = matrix[0].length - 1; while (ar &lt;= br &amp;&amp; ac &lt;= bc) &#123; printEdge(matrix, ar++, ac++, br--, bc--); &#125; &#125; /** * 顺时针打印矩阵的环 * * @param matrix 待打印的矩阵 * @param ar 左上角行数 * @param ac 左上角列数 * @param br 右下角行数 * @param bc 右下角列数 */ private static void printEdge(int[][] matrix, int ar, int ac, int br, int bc) &#123; if (ar == br) &#123; // 只有一行 for (int i = ac; i &lt;= bc; i++) &#123; System.out.print(matrix[ar][i] + " "); &#125; &#125; else if (ac == bc) &#123; // 只有一列 for (int i = ar; i &lt;= br; i++) &#123; System.out.print(matrix[i][ac] + " "); &#125; &#125; else &#123; int curR = ar; int curC = ac; while (curC &lt; bc) &#123; System.out.print(matrix[curR][curC++] + " "); &#125; while (curR &lt; br) &#123; System.out.print(matrix[curR++][curC] + " "); &#125; while (curC &gt; ac) &#123; System.out.print(matrix[curR][curC--] + " "); &#125; while (curR &gt; ar) &#123; System.out.print(matrix[curR--][curC] + " "); &#125; &#125; &#125;&#125; 旋转正方形矩阵给定一个整型正方形矩阵matrix，请把该矩阵调整成顺时针旋转90度的样子。 要求额外空间复杂度为O(1)。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.jelly.algorithm.matrix;/** * 旋转正方形矩阵 */public class RotateMatrix &#123; public static void main(String[] args) &#123; int[][] matrix = &#123;&#123;1, 2, 3, 4&#125;, &#123;5, 6, 7, 8&#125;, &#123;9, 10, 11, 12&#125;, &#123;13, 14, 15, 16&#125;&#125;; printMatrix(matrix); rotate(matrix); System.out.println("======================="); printMatrix(matrix); &#125; /** * 顺时针旋转矩阵 * * @param matrix 矩阵 */ private static void rotate(int[][] matrix) &#123; int ar = 0; int ac = 0; int br = matrix.length - 1; int bc = matrix[0].length - 1; while (ar &lt; br) &#123; rotateEdge(matrix, ar++, ac++, br--, bc--); &#125; &#125; /** * 转动矩阵边缘 * * @param matrix 待转动的矩阵 * @param ar 矩阵左上角行。 * @param ac 矩阵左上角列。 * @param br 矩阵右下角行。 * @param bc 矩阵右下角列。 */ private static void rotateEdge(int[][] matrix, int ar, int ac, int br, int bc) &#123; int times = bc - ac; int tmp = 0; for (int i = 0; i &lt; times; i++) &#123; tmp = matrix[ar][ac + i]; matrix[ar][ac + i] = matrix[br - i][ac]; matrix[br - i][ac] = matrix[br][bc - i]; matrix[br][bc - i] = matrix[ar + i][bc]; matrix[ar + i][bc] = tmp; &#125; &#125; /** * 打印矩阵当前状态 * * @param matrix 矩阵 */ public static void printMatrix(int[][] matrix) &#123; for (int i = 0; i &lt; matrix.length; i++) &#123; for (int j = 0; j &lt; matrix[i].length; j++) &#123; System.out.print(matrix[i][j] + " "); &#125; System.out.println(); &#125; &#125;&#125; 反转单向和双向链表分别实现反转单向链表和反转双向链表的函数。 要求如果链表长度为N， 时间复杂度要求为O(N)， 额外空间复杂度要求为O(1) 1234567891011121314151617181920public static class Node &#123; public int value; public Node next; public Node(int data) &#123; this.value = data; &#125; &#125; public static Node reverseList(Node head) &#123; Node pre = null; Node next = null; while (head != null) &#123; next = head.next; head.next = pre; pre = head; head = next; &#125; return pre; &#125; “之” 字形打印矩阵给定一个矩阵matrix， 按照“之” 字形的方式打印这个矩阵， 例如： 1 2 3 4 5 6 7 8 9 10 11 12 “之” 字形打印的结果为： 1， 2， 5， 9， 6， 3， 4， 7， 10， 11，8， 12 要求额外空间复杂度为O(1) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.jelly.algorithm.matrix;public class PrintMatrixZig &#123; public static void printMatrixZigZag(int[][] matrix) &#123; int ar = 0, ac = 0; int br = 0, bc = 0; int endR = matrix.length - 1; int endC = matrix[0].length - 1; boolean fromUp = false; while (br &lt;= endR) &#123; printSlash(matrix, ar, ac, br, bc, fromUp); // 下面四个顺序很重要，修改判断条件的操作放在后边 ac = ar == endR ? ac + 1 : ac; ar = ar == endR ? ar : ar + 1; br = bc == endC ? br + 1 : br; bc = bc == endC ? bc : bc + 1; fromUp = !fromUp; &#125; &#125; /** * 打印斜线 * * @param matrix 二维数组 * @param ar a点横坐标 * @param ac a点纵坐标 * @param br b点横坐标 * @param bc b点纵坐标 * @param f 是否为从上到下 */ private static void printSlash(int[][] matrix, int ar, int ac, int br, int bc, boolean f) &#123; if (f) &#123; while (ar &gt;= br) &#123; System.out.print(matrix[br++][bc--] + " "); &#125; &#125; else &#123; while (ar &gt;= br) &#123; System.out.print(matrix[ar--][ac++] + " "); &#125; &#125; &#125; public static void main(String[] args) &#123; int[][] matrix = &#123;&#123;1, 2, 3, 4&#125;, &#123;5, 6, 7, 8&#125;, &#123;9, 10, 11, 12&#125;, &#123;13, 14, 15, 16&#125;&#125;; printMatrixZigZag(matrix); &#125;&#125; 在行列都排好序的矩阵中找数给定一个有N*M的整型矩阵matrix和一个整数K，matrix的每一行和每一 列都是排好序的。 实现一个函数， 判断K是否在matrix中。 例如： 0 1 2 5 2 3 4 7 44 4 8 5 7 7 9 如果K为7， 返回true； 如果K为6， 返回false。 要求时间复杂度为O(N+M)， 额外空间复杂度为O(1)。 1234567891011121314151617181920212223242526272829303132333435363738394041package com.jelly.algorithm.matrix;public class FindNumInSortedMatrix &#123; public static void main(String[] args) &#123; int[][] matrix = new int[][]&#123;&#123;0, 1, 2, 3, 4, 5, 6&#125;,// 0 &#123;10, 12, 13, 15, 16, 17, 18&#125;,// 1 &#123;23, 24, 25, 26, 27, 28, 29&#125;,// 2 &#123;44, 45, 46, 47, 48, 49, 50&#125;,// 3 &#123;65, 66, 67, 68, 69, 70, 71&#125;,// 4 &#123;96, 97, 98, 99, 100, 111, 122&#125;,// 5 &#123;166, 176, 186, 187, 190, 195, 200&#125;,// 6 &#123;233, 243, 321, 341, 356, 370, 380&#125; // 7 &#125;; int K = 233; System.out.println(isContains(matrix, K)); &#125; /** * 查找思路，从右上角进行查找 * * @param matrix 矩阵 * @param k 查找的key * @return Boolean */ private static boolean isContains(int[][] matrix, int k) &#123; int r = 0; int c = matrix[0].length - 1; // 行要小于矩阵的行数。列要大于-1. while (r &lt; matrix.length &amp;&amp; c &gt; -1) &#123; if (matrix[r][c] == k) &#123; return true; &#125; else if (matrix[r][c] &gt; k) &#123; c--; &#125; else &#123; r++; &#125; &#125; return false; &#125;&#125; 链表打印两个有序链表的公共节点给定两个有序链表的头指针head1和head2， 打印两链表的公共节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.jelly.algorithm.list.s;import com.jelly.algorithm.list.ListNode;/** * 打印两个有序链表的公共节点 */public class PrintCommonPart &#123; public static void printCommonPart(ListNode head1, ListNode head2) &#123; while (head1 != null &amp;&amp; head2 != null) &#123; if (head1.val &lt; head2.val) &#123; head1 = head1.next; &#125; else if (head1.val &gt; head2.val) &#123; head2 = head2.next; &#125; else &#123; System.out.print(head1.val + " "); head1 = head1.next; head2 = head2.next; &#125; &#125; &#125; private static void printLinkedList(ListNode node) &#123; System.out.println("node: "); while (node != null) &#123; System.out.print(node.val + " "); node = node.next; &#125; System.out.println(); &#125; public static void main(String[] args) &#123; ListNode node1 = new ListNode(2); node1.next = new ListNode(3); node1.next.next = new ListNode(5); node1.next.next.next = new ListNode(6); ListNode node2 = new ListNode(1); node2.next = new ListNode(2); node2.next.next = new ListNode(5); node2.next.next.next = new ListNode(7); node2.next.next.next.next = new ListNode(8); printLinkedList(node1); printLinkedList(node2); printCommonPart(node1, node2); &#125;&#125; 判断一个链表是否为回文结构给定一个链表的头节点head，请判断该链表是否为回文结构。 例如： 12341-&gt;2-&gt;1， 返回true。 1-&gt;2-&gt;2-&gt;1，返回true。15-&gt;6-&gt;15， 返回true。 1-&gt;2-&gt;3， 返回false。 进阶： 如果链表长度为N， 时间复杂度达到O(N)， 额外空间复杂度达到O(1)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122package com.jelly.algorithm.list.s;import com.jelly.algorithm.list.ListNode;import java.util.Stack;/** * @version V1.0 * @program: study-leetcode * @description: 判断链表是否为回文链表 * @date: 2019-10-27 14:35 **/public class IsPalindrome &#123; // need n extra space public static boolean isPalindrome1(ListNode head) &#123; Stack&lt;ListNode&gt; stack = new Stack&lt;ListNode&gt;(); ListNode cur = head; while (cur != null) &#123; stack.push(cur); cur = cur.next; &#125; while (head != null) &#123; if (head.val != stack.pop().val) &#123; return false; &#125; head = head.next; &#125; return true; &#125; // need n/2 extra space public static boolean isPalindrome2(ListNode head) &#123; if (head == null || head.next == null) &#123; return true; &#125; ListNode right = head.next; ListNode cur = head; while (cur.next != null &amp;&amp; cur.next.next != null) &#123; right = right.next; cur = cur.next.next; &#125; Stack&lt;ListNode&gt; stack = new Stack&lt;ListNode&gt;(); while (right != null) &#123; stack.push(right); right = right.next; &#125; while (!stack.isEmpty()) &#123; if (head.val != stack.pop().val) &#123; return false; &#125; head = head.next; &#125; return true; &#125; // need O(1) extra space public static boolean isPalindrome(ListNode head) &#123; if (head == null || head.next == null) &#123; return true; &#125; // find mid. n1 point mid after loop ListNode n1 = head; ListNode n2 = head; while (n2.next != null &amp;&amp; n2.next.next != null) &#123; // find mid ListNode n1 = n1.next; n2 = n2.next.next; &#125; n2 = n1.next; // n2 -&gt; right part first ListNode n1.next = null; // mid.next -&gt; null // reverse second half ListNode n3 = null; while (n2 != null) &#123; n3 = n2.next; n2.next = n1; n1 = n2; n2 = n3; &#125; n3 = n1; // n3 -&gt; save last ListNode n2 = head;// n2 -&gt; left first ListNode // check palindrome boolean res = true; while (n1 != null &amp;&amp; n2 != null) &#123; if (n1.val != n2.val) &#123; res = false; break; &#125; n1 = n1.next; // left to mid n2 = n2.next; // right to mid &#125; n1 = n3.next; n3.next = null; // recover list while (n1 != null) &#123; n2 = n1.next; n1.next = n3; n3 = n1; n1 = n2; &#125; return res; &#125; public static void main(String[] args) &#123; ListNode head = new ListNode(1); ListNode node2 = new ListNode(2); ListNode node3 = new ListNode(3); ListNode node4 = new ListNode(4); ListNode node5 = new ListNode(3); ListNode node6 = new ListNode(2); ListNode node7 = new ListNode(1); head.next = node2; node2.next = node3; node3.next = node4; node4.next = node5; node5.next = node6; node6.next = node7; System.out.println(isPalindrome(head)); &#125;&#125; 将单向链表按某值划分成左边小、 中间相等、 右边大的形式给定一个单向链表的头节点head，节点的值类型是整型，再给定一个整 数pivot。 实现一个调整链表的函数，将链表调整为左部分都是值小于 pivot的节点，中间部分都是值等于pivot的节点， 右部分都是值大于 pivot的节点。除这个要求外，对调整后的节点顺序没有更多的要求。 12345例如： 链表 9-&gt;0-&gt;4-&gt;5-&gt;1， pivot=3。 调整后链表可以是 1-&gt;0-&gt;4-&gt;9-&gt;5，也可以是0-&gt;1-&gt;9-&gt;5-&gt;4。 总之， 满 足左部分都是小于3的节点， 中间部分都是等于3的节点（本例中这个部分为空） ， 右部分都是大于3的节点即可。 对某部分内部的节点顺序不做要求。 进阶： 在原问题的要求之上再增加如下两个要求。在左、 中、 右三个部分的内部也做顺序要求， 要求每部分里的节点从左 到右的顺序与原链表中节点的先后次序一致。 例如： 链表9-&gt;0-&gt;4-&gt;5-&gt;1， pivot=3。调整后的链表是0-&gt;1-&gt;9-&gt;4-&gt;5。 在满足原问题要求的同时， 左部分节点从左到右为0、 1。 在原链表中也 是先出现0， 后出现1； 中间部分在本例中为空， 不再讨论； 右部分节点 从左到右为9、 4、 5。 在原链表中也是先出现9， 然后出现4，最后出现5。如果链表长度为N， 时间复杂度请达到O(N)， 额外空间复杂度请达到O(1) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public static ListNode listPartition2(ListNode head, int pivot) &#123; ListNode sH = null; // small head ListNode sT = null; // small tail ListNode eH = null; // equal head ListNode eT = null; // equal tail ListNode bH = null; // big head ListNode bT = null; // big tail ListNode next; // save next node while (head != null) &#123; next = head.next; //释放 head.next = null; if (head.val &lt; pivot) &#123; if (sH == null) &#123; sH = head; sT = head; &#125; else &#123; sT.next = head; sT = head; &#125; &#125; else if (head.val &gt; pivot) &#123; if (eH == null) &#123; eH = head; eT = head; &#125; else &#123; eT.next = head; eT = head; &#125; &#125; else &#123; if (bH == null) &#123; bH = head; bT = head; &#125; else &#123; bT.next = head; bT = head; &#125; &#125; head = next; &#125; // small and equal reconnect if (sT != null) &#123; sT.next = eH; eT = eT == null ? sT : eT; &#125; // all reconnect if (eT != null) &#123; eT.next = bH; &#125; return sH != null ? sH : eH != null ? eH : bH; &#125; 复制含有随机指针节点的链表一种特殊的链表节点类描述如下： 12345678public class Node &#123; public int value; public Node next; public Node rand; public Node(int data) &#123; this.value = data; &#125;&#125; Node类中的value是节点值,next指针和正常单链表中next指针的意义一样，都指向下一个节点，rand指针是Node类中新增的指针,这个指针可能指向链表中的任意一个节点， 也可能指向null。 给定一个由Node节点类型组成的无环单链表的头节点head，请实现一个函数完成这个链表中所有结构的复制， 并返回复制的新链表的头节点。 进阶：不使用额外的数据结构，只用有限几个变量， 且在时间复杂度为O(N)内完成原问题要实现的函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package com.jelly.algorithm.list.m;import java.util.HashMap;public class CopyListWithRandom &#123; public static class Node &#123; public int value; public Node next; public Node rand; public Node(int data) &#123; this.value = data; &#125; &#125; /** * 将节点拷贝到map中，利用map获取源节点的next、rand指针。 * * @param head 头节点 */ public static Node copyListWithRand1(Node head) &#123; HashMap&lt;Node, Node&gt; map = new HashMap&lt;Node, Node&gt;(); Node cur = head; while (cur != null) &#123; map.put(cur, new Node(cur.value)); cur = cur.next; &#125; cur = head; while (cur != null) &#123; map.get(cur).next = map.get(cur.next); map.get(cur).rand = map.get(cur.rand); cur = cur.next; &#125; return map.get(head); &#125; /** * 节点的下一个为其next，让后将所有的拷贝节点提取出来 * * @param head 头指针 */ public static Node copyListWithRand2(Node head) &#123; if (head == null) &#123; return null; &#125; Node cur = head; // copy next Node next; while (cur != null) &#123; next = cur.next; cur.next = new Node(cur.value); cur.next.next = next; cur = next; &#125; // copy rand cur = head; while (cur != null) &#123; next = cur.next.next; cur.next.rand = cur.rand == null ? null : cur.rand.next; cur = next; &#125; // split Node res = head.next; Node curCopy; cur = head; while (cur != null) &#123; next = cur.next.next; curCopy = cur.next; cur.next = next; curCopy.next = next != null ? next.next : null; cur = next; &#125; return res; &#125; public static void printRandLinkedList(Node head) &#123; Node cur = head; System.out.print("order: "); while (cur != null) &#123; System.out.print(cur.value + " "); cur = cur.next; &#125; System.out.println(); cur = head; System.out.print("rand: "); while (cur != null) &#123; System.out.print(cur.rand == null ? "- " : cur.rand.value + " "); cur = cur.next; &#125; System.out.println(); &#125; public static void main(String[] args) &#123; Node head = null; Node res1 = null; Node res2 = null; head = new Node(1); head.next = new Node(2); head.next.next = new Node(3); head.next.next.next = new Node(4); head.next.next.next.next = new Node(5); head.next.next.next.next.next = new Node(6); head.rand = head.next.next.next.next.next; // 1 -&gt; 6 head.next.rand = head.next.next.next.next.next; // 2 -&gt; 6 head.next.next.rand = head.next.next.next.next; // 3 -&gt; 5 head.next.next.next.rand = head.next.next; // 4 -&gt; 3 head.next.next.next.next.rand = null; // 5 -&gt; null head.next.next.next.next.next.rand = head.next.next.next; // 6 -&gt; 4 System.out.println("head"); printRandLinkedList(head); System.out.println("Rand1"); res1 = copyListWithRand1(head); printRandLinkedList(res1); System.out.println("Rand2"); res2 = copyListWithRand2(head); printRandLinkedList(res2); System.out.println("head"); printRandLinkedList(head); &#125;&#125; 两个单链表相交的一系列问题单链表可能有环，也可能无环。给定两个单链表的头节点 head1和head2，这两个链表可能相交，也可能不相交。 请实现一个函数， 如果两个链表相交， 请返回相交的第一个节点； 如果不相交， 返回null 即可。 要求： 如果链表1 的长度为N， 链表2的长度为M， 时间复杂度请达到 O(N+M)， 额外空间复杂度请达到O(1) 可能情况 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174package com.jelly.algorithm.list.m;import com.jelly.algorithm.list.ListNode;/** * 寻找两个链表交点 */public class FindFirstIntersectNode &#123; public static ListNode getIntersectNode(ListNode head1, ListNode head2) &#123; if (head1 == null || head2 == null) &#123; return null; &#125; ListNode loop1 = getLoopNode(head1); ListNode loop2 = getLoopNode(head2); //both no loop if (loop1 == null &amp;&amp; loop2 == null) &#123; return noLoop(head1, head2); &#125; //both has loop if (loop1 != null &amp;&amp; loop2 != null) &#123; return bothLoop(head1, loop1, head2, loop2); &#125; //one has loop the other has no loop. don't intersect. return null; &#125; /** * Get the entry node of the ring */ public static ListNode getLoopNode(ListNode head) &#123; if (head == null || head.next == null || head.next.next == null) &#123; return null; &#125; ListNode n1 = head.next; // n1 -&gt; slow ListNode n2 = head.next.next; // n2 -&gt; fast while (n1 != n2) &#123; if (n2.next == null || n2.next.next == null) &#123; return null; &#125; n2 = n2.next.next; n1 = n1.next; &#125; n2 = head; // n2 -&gt; walk again from head while (n1 != n2) &#123; n1 = n1.next; n2 = n2.next; &#125; return n1; &#125; /** * two no loop list */ public static ListNode noLoop(ListNode head1, ListNode head2) &#123; if (head1 == null || head2 == null) &#123; return null; &#125; ListNode cur1 = head1; ListNode cur2 = head2; int n = 0; while (cur1.next != null) &#123; n++; cur1 = cur1.next; &#125; while (cur2.next != null) &#123; n--; cur2 = cur2.next; &#125; // end different if (cur1 != cur2) &#123; return null; &#125; // cur1 is longer. cur1 = n &gt; 0 ? head1 : head2; cur2 = cur1 == head1 ? head2 : head1; n = Math.abs(n); while (n != 0) &#123; n--; cur1 = cur1.next; &#125; while (cur1 != cur2) &#123; cur1 = cur1.next; cur2 = cur2.next; &#125; return cur1; &#125; /** * both has loop */ public static ListNode bothLoop(ListNode head1, ListNode loop1, ListNode head2, ListNode loop2) &#123; ListNode cur1 = null; ListNode cur2 = null; // 入口节点相同 if (loop1 == loop2) &#123; cur1 = head1; cur2 = head2; int n = 0; while (cur1 != loop1) &#123; n++; cur1 = cur1.next; &#125; while (cur2 != loop2) &#123; n--; cur2 = cur2.next; &#125; // cur1 is longer cur1 = n &gt; 0 ? head1 : head2; cur2 = cur1 == head1 ? head2 : head1; n = Math.abs(n); while (n != 0) &#123; n--; cur1 = cur1.next; &#125; while (cur1 != cur2) &#123; cur1 = cur1.next; cur2 = cur2.next; &#125; return cur1; &#125; else &#123; //入口节点不同 cur1 = loop1.next; while (cur1 != loop1) &#123; if (cur1 == loop2) &#123; return loop1; &#125; cur1 = cur1.next; &#125; return null; &#125; &#125; public static void main(String[] args) &#123; // 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6-&gt;7-&gt;null ListNode head1 = new ListNode(1); head1.next = new ListNode(2); head1.next.next = new ListNode(3); head1.next.next.next = new ListNode(4); head1.next.next.next.next = new ListNode(5); head1.next.next.next.next.next = new ListNode(6); head1.next.next.next.next.next.next = new ListNode(7); // 0-&gt;9-&gt;8-&gt;6-&gt;7-&gt;null ListNode head2 = new ListNode(0); head2.next = new ListNode(9); head2.next.next = new ListNode(8); head2.next.next.next = head1.next.next.next.next.next; // 8-&gt;6 System.out.println(getIntersectNode(head1, head2).val); // 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6-&gt;7-&gt;4... head1 = new ListNode(1); head1.next = new ListNode(2); head1.next.next = new ListNode(3); head1.next.next.next = new ListNode(4); head1.next.next.next.next = new ListNode(5); head1.next.next.next.next.next = new ListNode(6); head1.next.next.next.next.next.next = new ListNode(7); head1.next.next.next.next.next.next = head1.next.next.next; // 7-&gt;4 // 0-&gt;9-&gt;8-&gt;2... head2 = new ListNode(0); head2.next = new ListNode(9); head2.next.next = new ListNode(8); head2.next.next.next = head1.next; // 8-&gt;2 System.out.println(getIntersectNode(head1, head2).val); // 0-&gt;9-&gt;8-&gt;6-&gt;4-&gt;5-&gt;6.. head2 = new ListNode(0); head2.next = new ListNode(9); head2.next.next = new ListNode(8); head2.next.next.next = head1.next.next.next.next.next; // 8-&gt;6 System.out.println(getIntersectNode(head1, head2).val); &#125;&#125; 二叉树在二叉树中找到一个节点的后继节点现在有一种新的二叉树节点类型如下： 123456789public class Node &#123; public int value; public Node left; public Node right; public Node parent; public Node(int data) &#123; this.value = data; &#125;&#125; 该结构比普通二叉树节点结构多了一个指向父节点的parent指针。 假设有一棵Node类型的节点组成的二叉树， 树中每个节点的parent指针都正确地指向 自己的父节点， 头节点的parent指向null。 只给一个在二叉树中的某个节点 node， 请实现返回node的后继节点的函数。 在二叉树的中序遍历的序列中，node的下一个节点叫作node的后继节点. 中序遍历 左、根、右 123456789101112131415161718192021222324252627public static Node getSuccessorNode(Node node) &#123; if (node == null) &#123; return node; &#125; //右节点不为空时，下一个节点为右节点的最左节点 if (node.right != null) &#123; return getLeftMost(node.right); &#125; else &#123; //右节点为空，当前是左子节点，返回其父节点，否则找到祖父节点返回 Node parent = node.parent; while (parent != null &amp;&amp; parent.left != node) &#123; node = parent; parent = node.parent; &#125; return parent; &#125;&#125;public static Node getLeftMost(Node node) &#123; if (node == null) &#123; return node; &#125; while (node.left != null) &#123; node = node.left; &#125; return node;&#125; 判断一棵二叉树是否是平衡二叉树12345678910111213141516171819// 检验是否是平衡树public boolean isBalanced(TreeNode root) &#123; return process(root) != -1;&#125;private int process(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int left = process(root.left); if (left == -1) &#123; return -1; &#125; int right = process(root.right); if (right == -1) &#123; return -1; &#125; return Math.abs(left - right) &gt; 1 ? -1 : Math.max(left, right) + 1;&#125; 判断一棵树是否是搜索二叉树、1234567891011121314151617181920// 校验是否是平衡二叉搜索树.中序遍历，递增public boolean isValidBST(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); middleOrder(root, res); for (int i = 1; i &lt; res.size(); i++) &#123; if (res.get(i - 1) &gt; res.get(i)) &#123; return false; &#125; &#125; return true;&#125;private void middleOrder(TreeNode root, List&lt;Integer&gt; res) &#123; if (root == null) &#123; return; &#125; middleOrder(root.left, res); res.add(root.val); middleOrder(root.right, res);&#125; 判断一棵树是否是完全二叉树123456789101112131415161718192021222324252627282930public static boolean isCBT(Node head) &#123; if (head == null) &#123; return true; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;Node&gt;(); boolean leaf = false; Node l = null; Node r = null; queue.offer(head); while (!queue.isEmpty()) &#123; head = queue.poll(); l = head.left; r = head.right; // leaf为true后，左右节点均为空 // 左节点为空，右节点必须为空 if ((leaf &amp;&amp; (l != null || r != null)) || (l == null &amp;&amp; r != null)) &#123; return false; &#125; if (l != null) &#123; queue.offer(l); &#125; // 右节点为空，leaf标记为true if (r != null) &#123; queue.offer(r); &#125; else &#123; leaf = true; &#125; &#125; return true;&#125; 已知一棵完全二叉树， 求其节点的个数要求： 时间复杂度低于O(N)， N为这棵树的节点个数 1234567891011121314151617181920212223242526272829public static int nodeNum(Node head) &#123; if (head == null) &#123; return 0; &#125; return bs(head, 1, mostLeftLevel(head, 1));&#125;public static int bs(Node node, int l, int h) &#123; // leval 和 height相同时，返回1 if (l == h) &#123; return 1; &#125; // 右子树高度和完全二叉树高度相等，说明，左树为满树 // 2^(h-l) 个 + 右子树节点个数 if (mostLeftLevel(node.right, l + 1) == h) &#123; return (1 &lt;&lt; (h - l)) + bs(node.right, l + 1, h); &#125; else &#123; // 右树层数小1，+ 加上左子树节点个数 return (1 &lt;&lt; (h - l - 1)) + bs(node.left, l + 1, h); &#125;&#125;public static int mostLeftLevel(Node node, int level) &#123; while (node != null) &#123; level++; node = node.left; &#125; return level - 1;&#125; 折纸问题请把一段纸条竖着放在桌子上， 然后从纸条的下边向上方对折1次， 压出折痕后展开。 此时 折痕是凹下去的， 即折痕突起的方向指向纸条的背面。 如果从纸条的下边向上方连续对折2 次， 压出折痕后展开， 此时有三条折痕， 从上到下依次是下折痕、 下折痕和上折痕。给定一 个输入参数N， 代表纸条都从下边向上方连续对折N次，请从上到下打印所有折痕的方向。 例如： N=1时， 打印： downN=2时， 打印： down down up 类似二叉树： 1234右、中、左的遍历顺序。 下 上 下 上 下 上 下 1234567891011public static void printAllFolds(int N) &#123; printProcess(1, N, true);&#125;public static void printProcess(int i, int N, boolean down) &#123; if (i &gt; N) &#123; return; &#125; printProcess(i + 1, N, true); System.out.println(down ? "down " : "up "); printProcess(i + 1, N, false);&#125; 布隆过滤器 bit数组大小：m= - n * ln(p) / (ln2)^2 n: 样本量 p: 0.0001 预期失误率 哈希函数个数：k = ln2 * m / n = 0.7 * m/n 真实失误率：（1-e^(-n*k/m) )^k URL筛选不安全网页的黑名单包含100亿个黑名单网页，每个网页的URL最多占用64B，现在要实现一个网页过滤系统，根据网页的URL判断该网页是否在黑名单上。 要求 允许一定的判断失误率 空间内存限制在30GB以内 如果是直接用哈希函数处理，肯定会长处空间限制，所以这里要用到的是布隆过滤器。 布隆过滤器实际上是一个位图bitMap，我们现在假设有一个长度为m的bit类型的数组，以及 k 个互相独立的优秀的哈希函数，且这k个哈希函数的输出域都大于或等于m。 我们将网页的URL作为k个哈希函数的输入对象进行哈希处理，分别得到 k 个值，这k个值中可能有相同的，但是值之间互相独立不关联的。我们将这k个值对m模运算，得到的 k 个值都在 0~m之间。最后将这 k 个值对应的bitMap的值置为1，当我们将所有的URL都处理完毕后，bitMap上的很多位都被置为了1。 当我们要查询一个URL是否在黑名单内时，我们先将这个URL进行哈希处理 ，因为有K个函数所以得到 k 个值。接着检查这 k 个值对应的bitMap 位是否为1，如果有一个不为 1，那么说明这个URL不在这个这里面，是安全的网站，如果对应的 bitMap 位的值都是 1 那么说明这个URL可能在这里面。说明可能是因为当URL的数量很多时，可能会出现不同URL哈希处理后得到相同的值，所以说是有可能在这里面。 一致性哈希所有机器经过hash后，按照顺序排序。分担所有hash的数据。 新机器加入：新机器按照其hash分布到所有的hash环上，该点到下一点的数据拷贝到新机器上即可。 旧机器删除：删除该机器，该点管控数据，拷贝给他相邻节点。 问题机器必须达到一定数量，否则数据可能分布严重不均。 解决办法每个物理机增加一定数量的虚拟节点，均分整个hash环，根据虚拟节点的数量将数据划分给特定的宿主机存储。 岛问题一个矩阵中只有0和1两种值，每个位置都可以和自己的上、下、左、右 四个位置相连，如果有一片1连在一起，这个部分叫做一个岛，求一个 矩阵中有多少个岛？举例：0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0这个矩阵中有三个岛 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static int countIslands(int[][] m) &#123; if (m == null || m[0] == null) &#123; return 0; &#125; int N = m.length; int M = m[0].length; int res = 0; for (int i = 0; i &lt; N; i++) &#123; for (int j = 0; j &lt; M; j++) &#123; if (m[i][j] == 1) &#123; res++; infect(m, i, j, N, M); &#125; &#125; &#125; return res;&#125;public static void infect(int[][] m, int i, int j, int N, int M) &#123; if (i &lt; 0 || i &gt;= N || j &lt; 0 || j &gt;= M || m[i][j] != 1) &#123; return; &#125; m[i][j] = 2; infect(m, i + 1, j, N, M); infect(m, i - 1, j, N, M); infect(m, i, j + 1, N, M); infect(m, i, j - 1, N, M);&#125;public static void main(String[] args) &#123; int[][] m1 = &#123; &#123; 0, 0, 0, 0, 0, 0, 0, 0, 0 &#125;, &#123; 0, 1, 1, 1, 0, 1, 1, 1, 0 &#125;, &#123; 0, 1, 1, 1, 0, 0, 0, 1, 0 &#125;, &#123; 0, 1, 1, 0, 0, 0, 0, 0, 0 &#125;, &#123; 0, 0, 0, 0, 0, 1, 1, 0, 0 &#125;, &#123; 0, 0, 0, 0, 1, 1, 1, 0, 0 &#125;, &#123; 0, 0, 0, 0, 0, 0, 0, 0, 0 &#125;, &#125;; System.out.println(countIslands(m1)); int[][] m2 = &#123; &#123; 0, 0, 0, 0, 0, 0, 0, 0, 0 &#125;, &#123; 0, 1, 1, 1, 1, 1, 1, 1, 0 &#125;, &#123; 0, 1, 1, 1, 0, 0, 0, 1, 0 &#125;, &#123; 0, 1, 1, 0, 0, 0, 1, 1, 0 &#125;, &#123; 0, 0, 0, 0, 0, 1, 1, 0, 0 &#125;, &#123; 0, 0, 0, 0, 1, 1, 1, 0, 0 &#125;, &#123; 0, 0, 0, 0, 0, 0, 0, 0, 0 &#125;, &#125;; System.out.println(countIslands(m2));&#125; 并查集一种结构，主要提供两种功能 两个集合是否属于一个集合 合并两个集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static class UnionFindSet &#123; // k：当前节点，v：父节点 public HashMap&lt;Node, Node&gt; fatherMap; // k：当前节点，v：当前节点所代表的集合中有多少其他节点 public HashMap&lt;Node, Integer&gt; sizeMap; // 构造函数，必须一次给定所有的节点 public UnionFindSet(List&lt;Node&gt; nodes) &#123; makeSets(nodes); &#125; // 初始化所有节点，初始化时所有节点指向自己，size为 1 private void makeSets(List&lt;Node&gt; nodes) &#123; fatherMap = new HashMap&lt;Node, Node&gt;(); sizeMap = new HashMap&lt;Node, Integer&gt;(); for (Node node : nodes) &#123; fatherMap.put(node, node); sizeMap.put(node, 1); &#125; &#125; // 递归找到node的父节点 // 然后并将查找路径上的节点，挂在代表节点下 private Node findHead(Node node) &#123; Node father = fatherMap.get(node); if (father != node) &#123; father = findHead(father); &#125; fatherMap.put(node, father); return father; &#125; // 对外提供的方法，两个节点是否属于同一个集合 public boolean isSameSet(Node a, Node b) &#123; return findHead(a) == findHead(b); &#125; // 合并两个集合，参数为两个集合的代表节点 public void union(Node a, Node b) &#123; if (a == null || b == null) &#123; return; &#125; Node aHead = findHead(a); Node bHead = findHead(b); if (aHead != bHead) &#123; int aSetSize= sizeMap.get(aHead); int bSetSize = sizeMap.get(bHead); if (aSetSize &lt;= bSetSize) &#123; fatherMap.put(aHead, bHead); sizeMap.put(bHead, aSetSize + bSetSize); &#125; else &#123; fatherMap.put(bHead, aHead); sizeMap.put(aHead, aSetSize + bSetSize); &#125; &#125; &#125;&#125; 前缀树arr2中有哪些字符，是arr1中出现的？请打印 arr2中有哪些字符，是作为arr1中某个字符串前缀出现的？请 打印 arr2中有哪些字符，是作为arr1中某个字符串前缀出现的？请打印 arr2中出现次数最大的前缀。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public static class TrieNode &#123; public int path; public int end; public TrieNode[] nexts; public TrieNode() &#123; path = 0; end = 0; nexts = new TrieNode[26]; &#125;&#125;public static class Trie &#123; private TrieNode root; public Trie() &#123; root = new TrieNode(); &#125; public void insert(String word) &#123; if (word == null) &#123; return; &#125; char[] chs = word.toCharArray(); TrieNode node = root; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; index = chs[i] - 'a'; if (node.nexts[index] == null) &#123; node.nexts[index] = new TrieNode(); &#125; node = node.nexts[index]; node.path++; &#125; node.end++; &#125; public void delete(String word) &#123; if (search(word) != 0) &#123; char[] chs = word.toCharArray(); TrieNode node = root; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; index = chs[i] - 'a'; if (--node.nexts[index].path == 0) &#123; node.nexts[index] = null; return; &#125; node = node.nexts[index]; &#125; node.end--; &#125; &#125; public int search(String word) &#123; if (word == null) &#123; return 0; &#125; char[] chs = word.toCharArray(); TrieNode node = root; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; index = chs[i] - 'a'; if (node.nexts[index] == null) &#123; return 0; &#125; node = node.nexts[index]; &#125; return node.end; &#125; public int prefixNumber(String pre) &#123; if (pre == null) &#123; return 0; &#125; char[] chs = pre.toCharArray(); TrieNode node = root; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; index = chs[i] - 'a'; if (node.nexts[index] == null) &#123; return 0; &#125; node = node.nexts[index]; &#125; return node.path; &#125;&#125;public static void main(String[] args) &#123; Trie trie = new Trie(); System.out.println(trie.search("zuo")); trie.insert("zuo"); System.out.println(trie.search("zuo")); trie.delete("zuo"); System.out.println(trie.search("zuo")); trie.insert("zuo"); trie.insert("zuo"); trie.delete("zuo"); System.out.println(trie.search("zuo")); trie.delete("zuo"); System.out.println(trie.search("zuo")); trie.insert("zuoa"); trie.insert("zuoac"); trie.insert("zuoab"); trie.insert("zuoad"); trie.delete("zuoa"); System.out.println(trie.search("zuoa")); System.out.println(trie.prefixNumber("zuo"));&#125; 贪心算法切金条一块金条切成两半，是需要花费和长度数值一样的铜板的。比如 长度为20的 金条，不管切成长度多大的两半，都要花费20个铜 板。一群人想整分整块金 条，怎么分最省铜板？ 例如,给定数组{10,20,30}，代表一共三个人，整块金条长度为 10+20+30=60. 金条要分成10,20,30三个部分。 如果， 先把长 度60的金条分成10和50，花费60 再把长度50的金条分成20和30， 花费50 一共花费110铜板。 但是如果， 先把长度60的金条分成30和30，花费60 再把长度30 金条分成10和20，花费30 一共花费90铜板。 输入一个数组，返回分割的最小代价。 1234567891011121314public static int lessMoney(int[] arr) &#123; PriorityQueue&lt;Integer&gt; pQ = new PriorityQueue&lt;&gt;(); for (int i = 0; i &lt; arr.length; i++) &#123; pQ.add(arr[i]); &#125; int sum = 0; int cur = 0; while (pQ.size() &gt; 1) &#123; cur = pQ.poll() + pQ.poll(); sum += cur; pQ.add(cur); &#125; return sum; &#125; 做项目(IPO)输入： 参数1，正数数组costs 参数2，正数数组profits 参数3， 正数k 参数4，正数m costs[i]表示i号项目的花费 profits[i]表示i号项目在扣除花 费之后还能挣到的钱(利润) k表示你不能并行、只能串行的最多 做k个项目 m表示你初始的资金 说明：你每做完一个项目，马上获得的收益，可以支持你去做下 一个 项目。 输出： 你最后获得的最大钱数。 构建两个堆： 按照花费构建小根堆，当花费小于当前所有资金时，进入按照收益构建的大根堆，每次大根堆中给的第一个。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public static class Node &#123; public int p; public int c; public Node(int p, int c) &#123; this.p = p; this.c = c; &#125; &#125; public static class MinCostComparator implements Comparator&lt;Node&gt; &#123; @Override public int compare(Node o1, Node o2) &#123; return o1.c - o2.c; &#125; &#125; public static class MaxProfitComparator implements Comparator&lt;Node&gt; &#123; @Override public int compare(Node o1, Node o2) &#123; return o2.p - o1.p; &#125; &#125; public static int findMaximizedCapital(int k, int W, int[] Profits, int[] Capital) &#123; Node[] nodes = new Node[Profits.length]; for (int i = 0; i &lt; Profits.length; i++) &#123; nodes[i] = new Node(Profits[i], Capital[i]); &#125; PriorityQueue&lt;Node&gt; minCostQ = new PriorityQueue&lt;&gt;(new MinCostComparator()); PriorityQueue&lt;Node&gt; maxProfitQ = new PriorityQueue&lt;&gt;(new MaxProfitComparator()); for (int i = 0; i &lt; nodes.length; i++) &#123; minCostQ.add(nodes[i]); &#125; for (int i = 0; i &lt; k; i++) &#123; while (!minCostQ.isEmpty() &amp;&amp; minCostQ.peek().c &lt;= W) &#123; maxProfitQ.add(minCostQ.poll()); &#125; if (maxProfitQ.isEmpty()) &#123; return W; &#125; W += maxProfitQ.poll().p; &#125; return W; &#125; 一个数据流中，随时可以取得中位数最低字典序给定一个字符串类型的数组strs，找到一种拼接方式，使得把所有字符串拼起来之后形成的字符串具有最低的字典序。 注意： 不能直接按照字典序比较，如 ba、b 直接按照字典序比较 ba &gt; b 拼接字符串 bba，但是bab更小。 12345678910111213141516171819202122232425262728public static class MyComparator implements Comparator&lt;String&gt; &#123; @Override public int compare(String a, String b) &#123; // 直接按照字典序比较是错误的 return (a + b).compareTo(b + a); &#125;&#125;public static String lowestString(String[] strs) &#123; if (strs == null || strs.length == 0) &#123; return ""; &#125; Arrays.sort(strs, new MyComparator()); String res = ""; for (int i = 0; i &lt; strs.length; i++) &#123; res += strs[i]; &#125; return res;&#125;public static void main(String[] args) &#123; String[] strs1 = &#123; "jibw", "ji", "jp", "bw", "jibw" &#125;; System.out.println(lowestString(strs1)); String[] strs2 = &#123; "ba", "b" &#125;; System.out.println(lowestString(strs2));&#125; 宣讲会一些项目要占用一个会议室宣讲，会议室不能同时容纳两个项目 的宣讲。 给你每一个项目开始的时间和结束的时间(给你一个数 组，里面 是一个个具体的项目)，你来安排宣讲的日程，要求会 议室进行 的宣讲的场次最多。返回这个最多的宣讲场次。 按照结束时间排序 123456789101112131415161718192021222324252627282930public static class Program &#123; public int start; public int end; public Program(int start, int end) &#123; this.start = start; this.end = end; &#125; &#125; public static class ProgramComparator implements Comparator&lt;Program&gt; &#123; @Override public int compare(Program o1, Program o2) &#123; return o1.end - o2.end; &#125; &#125; public static int bestArrange(Program[] programs, int start) &#123; Arrays.sort(programs, new ProgramComparator()); int result = 0; for (int i = 0; i &lt; programs.length; i++) &#123; if (start &lt;= programs[i].start) &#123; result++; start = programs[i].end; &#125; &#125; return result; &#125; – 递归&amp;动态规划暴力递归： 把问题转化为规模缩小了的同类问题的子问题 有明确的不需要继续进行递归的条件(base case) 有当得到了子问题的结果之后的决策过程 不记录每一个 子问题的解 动态规划 从暴力递归中来 将每一个子问题的解记录下来，避免重复计算 把暴力递归的过程，抽象成了状态表达 并且存在化简状态表达，使其更加简洁的可能 求n!的结果n的阶乘依赖于 n-1 的阶乘， n-1 的阶乘依赖于 n-2 的阶乘……依赖 1 的阶乘。 于是，反过来，可以从 1 的阶乘计算到 n的阶乘 1234567891011121314151617181920public static long getFactorial1(int n) &#123; if (n == 1) &#123; return 1L; &#125; return (long) n * getFactorial1(n - 1);&#125;public static long getFactorial2(int n) &#123; long result = 1L; for (int i = 1; i &lt;= n; i++) &#123; result *= i; &#125; return result;&#125;public static void main(String[] args) &#123; int n = 5; System.out.println(getFactorial1(n)); System.out.println(getFactorial2(n));&#125; 汉诺塔问题三个柱子。from、to、help 抽象问题： 将from 上的 n 个盘子中的 n-1 个移动到 help上 将from 剩余的第 n 个盘子移动到to上 将help 上的n-1 个盘子移动到to上 123456789101112131415public static void hanoi(int n) &#123; if (n &gt; 0) &#123; func(n, n, "left", "mid", "right"); &#125;&#125;public static void func(int rest, int down, String from, String help, String to) &#123; if (rest == 1) &#123; System.out.println("move " + down + " from " + from + " to " + to); &#125; else &#123; func(rest - 1, down - 1, from, to, help); func(1, down, from, help, to); func(rest - 1, down - 1, help, from, to); &#125;&#125; 打印全部子序列打印一个字符串的全部子序列，包括空字符串 1234567891011121314151617public static void printAllSubsquence(String str) &#123; if(str == null|| "".equal(str))&#123; return; &#125; process(str.toCharArray(), 0 ,"");&#125;public static void process(char[] str, int i, String res)&#123; if(i == str.length)&#123; System.out.println(res); return; &#125; // 决策：不加当前字符 process(str, i+1, res); // 决策：加当前字符 process(str, i+1, res+String.valueOf(str[i]));&#125; 打印全排列打印一个字符串的全部排列 123456789101112131415161718192021222324252627282930313233343536package com.jelly.algorithm.string;import java.util.Arrays;/** * 字符串的全排列 */public class AllPermutations &#123; public static void printAllPermutations(String str) &#123; if (str == null || "".equals(str)) &#123; return; &#125; process(str.toCharArray(), 0); &#125; private static void process(char[] chs, int i) &#123; if (i == chs.length) &#123; System.out.println(String.valueOf(chs)); &#125; for (int j = i; j &lt; chs.length; j++) &#123; process(deepCopyAndSwap(chs, i, j), i + 1); &#125; &#125; private static char[] deepCopyAndSwap(char[] chs, int i, int j) &#123; char[] res = Arrays.copyOf(chs, chs.length); char tmp = res[i]; res[i] = res[j]; res[j] = tmp; return res; &#125; public static void main(String[] args) &#123; printAllPermutations("abc"); &#125;&#125; 生牛问题母牛每年生一只母牛，新出生的母牛成长三年后也能每年生一只母牛，假设不会死。求N年后，母牛的数量。 因为题中牛不会死，三年后可以生母牛。那么可以得到递推公式： 12f(n) = f(n-1) + f(n-3)今年牛数量 = 去年牛数量 + 三年前牛数量(它们将会生小牛) 123456789101112131415161718192021222324252627282930313233343536373839public static int cowNumber1(int n) &#123; if (n &lt; 1) &#123; return 0; &#125; if (n == 1 || n == 2 || n == 3) &#123; return n; &#125; return cowNumber1(n - 1) + cowNumber1(n - 3);&#125;public static int cowNumber2(int n) &#123; if (n &lt; 1) &#123; return 0; &#125; if (n == 1 || n == 2 || n == 3) &#123; return n; &#125; int res = 3; int pre = 2; int prepre = 1; int tmp1 = 0; int tmp2 = 0; for (int i = 4; i &lt;= n; i++) &#123; tmp1 = res; tmp2 = pre; res = res + prepre; pre = tmp1; prepre = tmp2; &#125; return res;&#125;public static void main(String[] args) &#123; int n = 20; System.out.println(cowNumber1(n)); System.out.println(cowNumber2(n));&#125; 生牛问题(母牛只能活10年)如果每只母牛只能活10年（先生后死），求N年后，母牛的数量。 12f(n) = f(n-1) + f(n-3) - (f(n-10) - f(n-11))今年牛数量 = 去年牛数量 + 三年前牛数量(它们将会生小牛) - 十年前出生的小牛(如果是第十年没生小牛就死亡，应减2倍 十年前出生小牛的量) 递归逆序栈给你一个栈，请你逆序这个栈，不能申请额外的数据结构，只能 使用递归函数。如何实现？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.jelly.algorithm.stack;import java.util.Stack;/** * 递归查找栈底元素弹出，然后入栈 */public class ReverseStackUsingRecursive &#123; public static void reverse(Stack&lt;Integer&gt; stack) &#123; if (stack == null || stack.isEmpty()) &#123; return; &#125; int last = getAndRemoveLast(stack); reverse(stack); stack.push(last); &#125; private static int getAndRemoveLast(Stack&lt;Integer&gt; stack) &#123; Integer pop = stack.pop(); if (stack.isEmpty()) &#123; return pop; &#125; else &#123; // 弹出的pop不是栈底元素，递归查找，并将pop重新入栈 int last = getAndRemoveLast(stack); stack.push(pop); return last; &#125; &#125; public static void main(String[] args) &#123; Stack&lt;Integer&gt; stack = initStack(); reverse(stack); printStack(stack); &#125; // 测试 初始化栈 private static Stack&lt;Integer&gt; initStack() &#123; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); stack.push(1); stack.push(2); stack.push(3); stack.push(4); return stack; &#125; // 测试 打印栈 private static void printStack(Stack&lt;Integer&gt; stack) &#123; while (!stack.isEmpty()) &#123; System.out.print(stack.pop() + " "); &#125; &#125;&#125; 最小路径无后效性问题都可以改成动态规划 无后效性，当前选择对后边选择决策无关。当前可变参数确定，最后返回值是确定的。 给你一个二维数组，二维数组中的每个数都是正数，要求从左上角走到右下角，每一步只能向右或者向下。沿途经过的数字要累加起来。返回最小的路径和 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public static int minPath1(int[][] matrix) &#123; return process1(matrix, matrix.length - 1, matrix[0].length - 1);&#125;// 递归版public static int process1(int[][] matrix, int i, int j) &#123; int res = matrix[i][j]; if (i == 0 &amp;&amp; j == 0) &#123; return res; &#125; if (i == 0 &amp;&amp; j != 0) &#123; return res + process1(matrix, i, j - 1); &#125; if (i != 0 &amp;&amp; j == 0) &#123; return res + process1(matrix, i - 1, j); &#125; return res + Math.min(process1(matrix, i, j - 1), process1(matrix, i - 1, j));&#125;// 动态规划版public static int minPath2(int[][] m) &#123; if (m == null || m.length == 0 || m[0] == null || m[0].length == 0) &#123; return 0; &#125; int row = m.length; int col = m[0].length; int[][] dp = new int[row][col]; dp[0][0] = m[0][0]; for (int i = 1; i &lt; row; i++) &#123; dp[i][0] = dp[i - 1][0] + m[i][0]; &#125; for (int j = 1; j &lt; col; j++) &#123; dp[0][j] = dp[0][j - 1] + m[0][j]; &#125; for (int i = 1; i &lt; row; i++) &#123; for (int j = 1; j &lt; col; j++) &#123; dp[i][j] = Math.min(dp[i - 1][j], dp[i][j - 1]) + m[i][j]; &#125; &#125; return dp[row - 1][col - 1];&#125; // for testpublic static int[][] generateRandomMatrix(int rowSize, int colSize) &#123; if (rowSize &lt; 0 || colSize &lt; 0) &#123; return null; &#125; int[][] result = new int[rowSize][colSize]; for (int i = 0; i != result.length; i++) &#123; for (int j = 0; j != result[0].length; j++) &#123; result[i][j] = (int) (Math.random() * 10); &#125; &#125; return result;&#125; public static void main(String[] args) &#123; int[][] m = &#123; &#123; 1, 3, 5, 9 &#125;, &#123; 8, 1, 3, 4 &#125;, &#123; 5, 0, 6, 1 &#125;, &#123; 8, 8, 4, 0 &#125; &#125;; System.out.println(minPath1(m)); System.out.println(minPath2(m)); m = generateRandomMatrix(6, 7); System.out.println(minPath1(m)); System.out.println(minPath2(m));&#125; 背包问题给你一个数组arr，和一个整数aim。如果可以任意选择arr中的数字，能不能累加得到aim，返回true或者false 分析每个位置 i 有 要和不要 两种选择；叶节点会看自己这里的结果是不是 aim，从而向父结点返回 true 或 false，父结点比较子节点的结果，有一个为 true 就一直返回 true，否则返回 false。 如上图所示：数组 arr = {3, 2, 5} ，aim = 7： f(0, 0)：代表0位置处状态值为0的点； f(2, 5)：代表2位置处状态值为5的点。 只要有叶节点的值等于 aim 的值，则会返回 true。 动态规划版图解： 123456789101112131415161718192021222324252627282930313233343536public static boolean money1(int[] arr, int aim) &#123; return process(arr, 0, 0, aim);&#125;public static boolean process(int[] arr, int i, int sum, int aim) &#123; if (sum == aim) &#123; return true; &#125; // sum != aim if (i == arr.length) &#123; return false; &#125; return process(arr, i + 1, sum, aim) || process(arr, i + 1, sum + arr[i], aim);&#125;// 动态规划版public static boolean money2(int[] arr, int aim) &#123; boolean[][] dp = new boolean[arr.length + 1][aim + 1]; for (int i = 0; i &lt; dp.length; i++) &#123; dp[i][aim] = true; &#125; for (int i = arr.length - 1; i &gt;= 0; i--) &#123; for (int j = aim - 1; j &gt;= 0; j--) &#123; dp[i][j] = dp[i + 1][j]; if (j + arr[i] &lt;= aim) &#123; dp[i][j] = dp[i][j] || dp[i + 1][j + arr[i]]; &#125; &#125; &#125; return dp[0][0];&#125;public static void main(String[] args) &#123; int[] arr = &#123; 1, 4, 8 &#125;; int aim = 12; System.out.println(money1(arr, aim)); System.out.println(money2(arr, aim));&#125; 商品价值给定两个数组w和v，两个数组长度相等，w[i]表示第i件商品的 重量，v[i]表示第i件商品的价值。 再给定一个整数bag，要求 你挑选商品的重量加起来一定不能超 过bag，返回满足这个条件 下，你能获得的最大价值。 1234567891011121314151617181920212223242526272829303132333435363738public static int maxValue1(int[] c, int[] p, int bag) &#123; return process1(c, p, 0, 0, bag);&#125;public static int process1(int[] weights, int[] values, int i, int alreadyweight, int bag) &#123; if (alreadyweight &gt; bag) &#123; return 0; &#125; if (i == weights.length) &#123; return 0; &#125; return Math.max( process1(weights, values, i + 1, alreadyweight, bag), values[i] + process1(weights, values, i + 1, alreadyweight + weights[i], bag) );&#125;public static int maxValue2(int[] c, int[] p, int bag) &#123; int[][] dp = new int[c.length + 1][bag + 1]; for (int i = c.length - 1; i &gt;= 0; i--) &#123; for (int j = bag; j &gt;= 0; j--) &#123; dp[i][j] = dp[i + 1][j]; if (j + c[i] &lt;= bag) &#123; dp[i][j] = Math.max(dp[i][j], p[i] + dp[i + 1][j + c[i]]); &#125; &#125; &#125; return dp[0][0];&#125;public static void main(String[] args) &#123; int[] c = &#123; 3, 2, 4, 7 &#125;; int[] p = &#123; 5, 6, 3, 19 &#125;; int bag = 11; System.out.println(maxValue1(c, p, bag)); System.out.println(maxValue2(c, p, bag));&#125;]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[master公式&归并排序]]></title>
    <url>%2Falg-masterForm%2F</url>
    <content type="text"><![CDATA[剖析递归行为和递归行为时间复杂度的估算以及归并排序 剖析递归行为和递归行为时间复杂度的估算一个递归行为的例子 master公式的使用 T(N) = a*T(N/b) + O(N^d) T(N)是样本量为N时的时间复杂度，N/b是划分成子问题的样本量，子问题发生了a次，后面O(N^d)是除去调用子过程之外的时间复杂度。 比如要求一个数组的最大值： 1234567891011public static int getMax(int[] arr, int L, int R) &#123; if (L == R) &#123; return arr[L]; &#125; int mid = (L + R) &gt;&gt;&gt; 1; int maxLeft = getMax(arr, L, mid); int maxRight = getMax(arr, mid + 1, R); return Math.max(maxLeft, maxRight);&#125;//master公式： T(N) = 2*T(N/2) + O(1); 这里划分成的递归子过程的样本量是N/2，这个相同的样本量发生了2次，除去调用子过程之外的时间复杂度是O(1),因为求最大值和判断if复杂度是O(1),所以N^d=1，所以d=0. 那么根据如下公式判断 log(b,a) &gt; d -&gt; 复杂度为O(N^log(b,a)) log(b,a) = d -&gt; 复杂度为O(N^d * logN) log(b,a) &lt; d -&gt; 复杂度为O(N^d) 这里log(b, a)(以b为底a的对数) = log(2, 2)=1 &gt; d=0所以复杂度为O(N^log(2, 2))===&gt;O(N)，因此也就可以解释为什么归并排序的时间复杂度为nlogn了 归并排序 归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。 可以看到这种结构很像一棵完全二叉树，本文的归并排序我们采用递归去实现（也可采用迭代的方式去实现）。分阶段可以理解为就是递归拆分子序列的过程，递归深度为log2n。 12345678910111213141516171819202122232425262728293031323334public static void mergeSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; mergeSort(arr, 0, arr.length - 1);&#125;public static void mergeSort(int[] arr, int l, int r) &#123; if (l == r) &#123; return; &#125; int mid = l + ((r - l) &gt;&gt; 1); mergeSort(arr, l, mid); mergeSort(arr, mid + 1, r); merge(arr, l, mid, r);&#125;public static void merge(int[] arr, int l, int m, int r) &#123; int[] help = new int[r - l + 1]; int i = 0; int p1 = l; int p2 = m + 1; while (p1 &lt;= m &amp;&amp; p2 &lt;= r) &#123; help[i++] = arr[p1] &lt; arr[p2] ? arr[p1++] :arr[p2++]; &#125; while (p1 &lt;= m) &#123; help[i++] = arr[p1++]; &#125; while (p2 &lt;= r) &#123; help[i++] = arr[p2++]; &#125; for (i = 0; i &lt; help.length; i++) &#123; arr[l + i] = help[i]; &#125;&#125; ### 总结： 归并排序是稳定排序，他也是一种十分高效的排序，能利用完全二叉树特性的排序一般性能都不会太差。java中Arrays.sort()采用了一种名为TimSort的排序算法，就是归并排序的优化版本。从上文的图中可看出，每次合并操作的平均时间复杂度为O(n)，而完全二叉树的深度为|log2n|。总的平均时间复杂度为O(nlogn)。而且，归并排序的最好，最坏，平均时间复杂度均为O(nlogn)。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>master公式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法]]></title>
    <url>%2Falg-simpleSort%2F</url>
    <content type="text"><![CDATA[排序有内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。我们这里说说八大排序的内部排序。 概述排序有内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。我们这里说说八大排序的内部排序。 当n较大，则应采用时间复杂度为O(nlog2n)的排序方法：快速排序、堆排序或归并排序序。 快速排序：是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短；* 如何分析一个算法算法的执行效率 最好情况、最坏情况、平均情况时间复杂度 我们在分析排序算法的时间复杂度时，要分别给出最好情况、最坏情况、平均情况下的时间复杂度。除此之外，你还要说出最好、最坏时间复杂度对应的要排序的原始数据是什么样的。 为什么要区分这三种时间复杂度呢？第一，有些排序算法会区分，为了好对比，所以我们最好都做一下区分。第二，对于要排序的数据，有的接近有序，有的完全无序。有序度不同的数据，对于排序的执行时间肯定是有影响的，我们要知道排序算法在不同数据下的性能表现。 时间复杂度的系数、常数 、低阶 我们知道，时间复杂度反应的是数据规模n很大的时候的一个增长趋势，所以它表示的时候会忽略系数、常数、低阶。但是实际的软件开发中，我们排序的可能是10个、 100个、 1000个这样规模很小的数据，所以，在对同一阶时间复杂度的排序算法性能对比的时候，我们就要把系数、常数、低阶也考虑进来。 比较次数和交换（或移动）次数 基于比较的排序算法的执行过程，会涉及两种操作，一种是元素比较大小，另一种是元素交换或移动。所以，如果我们在分析排序算法的执行效率的时候，应该把比较次数和交换（或移动）次数也考虑进去。 排序算法的内存消耗我们前面讲过，算法的内存消耗可以通过空间复杂度来衡量，排序算法也不例外。不过，针对排序算法的空间复杂度，我们还引入了一个新的概念， 原地排序（Sorted in place）。原地排序算法，就是特指空间复杂度是O(1)的排序算法。 冒泡排序、插入排序、选择排序，都是原地排序算法。 排序算法的稳定性这个概念是说，如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。 我通过一个例子来解释一下。比如我们有一组数据2， 9， 3， 4， 8， 3，按照大小排序之后就是2， 3， 3， 4， 8， 9。 这组数据里有两个3。经过某种排序算法排序之后，如果两个3的前后顺序没有改变，那我们就把这种排序算法叫作稳定的排序算法；如果前后顺序发生变化，那对应的排序算法就叫作不稳定的排序算法。 有序度/逆序度有序度是数组中具有有序关系的元素对的个数。有序元素对用数学表达式表示就是这样： 12有序元素对： a[i] &lt;= a[j], 如果i &lt; j 2, 4, 3, 1, 5, 6 这组数据的有序度 11，其有序元素对为11个，分别为： 12345(2,4), (2,3), (2,5), (2,6), (4,5), (4,6),(3,5), (3,6),(1,5),(5,6) 同理，对于一个倒序排列的数组，比如6， 5， 4， 3， 2， 1，有序度是0；对于一个完全有序的数组，比如1， 2， 3， 4， 5， 6，有序度就是 n * (n-1) / 2 ，也就是15。我们把这种完全有序的数组的有序度叫作满有序度。 逆序度的定义正好跟有序度相反（默认从小到大为有序）。 12逆序元素对： a[i] &gt; a[j], 如果i &lt; j。 公式(n为元素个数) 满有序度 = n * (n-1) / 2 逆序度=满有序度-有序度。 举个栗子要排序的数组的初始状态是4， 5， 6， 3， 2， 1 其中，有序元素对有(4， 5) (4， 6)(5， 6)，所以有序度是3。 n=6，所以排序完成之后终态的满有序度为 n * (n-1) / 2 = 15。 冒泡排序包含两个操作原子， 比较和交换。每交换一次，有序度就加1。不管算法怎么改进，交换次数总是确定的，即为逆序度， 也就是 n * (n-1) / 2 – 初始有序度。此例中就是15–3=12，要进行12次交换操作。 经典算法示例基于比较的排序冒泡排序 原地排序算法 稳定的排序算法 最好时间复杂度O(n) 最坏时间复杂度O(n^2) 平均时间复杂度O(n^2) 冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为O(1) 在冒泡排序中，只有交换才可以改变两个元素的前后顺序。为了保证冒泡排序算法的稳定性，当有相邻的两个元素大小相等的时候，我们不做交换，相同大小的数据在排序前后不会改变顺序，所以冒泡排序是稳定的排序算法。 最好情况下，要排序的数据已经是有序的了，我们只需要进行一次冒泡操作，就可以结束了， 冒泡排序的核心是从头遍历序列。以升序排列为例：将第一个元素和第二个元素比较，若前者大于后者，则交换两者的位置，再将第二个元素与第三个元素比较，若前者大于后者则交换两者位置，以此类推直到倒数第二个元素与最后一个元素比较，若前者大于后者，则交换两者位置。这样一轮比较下来将会把序列中最大的元素移至序列末尾，这样就安排好了最大数的位置(每次找到一个最大的)，接下来只需对剩下的（n-1）个元素，重复上述操作即可. 123456789101112131415161718//时间复杂度O(N^2)， 额外空间复杂度O(1)public class Sort_01_bubbleSort &#123; public static void bubbleSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = arr.length - 1; i &gt; 0; i--) &#123; for (int j = 0; j &lt; i; j++) &#123; if (arr[j] &gt; arr[j + 1]) swap(arr, j, j + 1); &#125; &#125; &#125; private static void swap(int[] arr, int i, int j) &#123; arr[i] = arr[i] ^ arr[j]; arr[j] = arr[i] ^ arr[j]; arr[i] = arr[i] ^ arr[j]; &#125;&#125; 插入排序 原地排序算法 稳定的排序算法 最好时间复杂度O(n) 最坏时间复杂度O(n^2) 平均时间复杂度O(n^2) 从实现过程可以很明显地看出，插入排序算法的运行并不需要额外的存储空间，所以空间复杂度是O(1)，也就是说，这是一个原地排序算法。 在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现元素的后面，这样就可以保持原有的前后顺序不变，所以插入排序是稳定的排序算法。 如果要排序的数据已经是有序的，我们并不需要搬移任何数据。如果我们从尾到头在有序数据组里面查找插入位置，每次只需要比较一个数据就能确定插入的位置。所以这种情况下，最好是时间复杂度为O(n)。注意，这里是从尾到头遍历已经有序的数据。如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，所以最坏情况时间复杂度为O(n2)。 还记得我们在数组中插入一个数据的平均时间复杂度是多少吗？没错，是O(n)。所以，对于插入排序来说，每次插入操作都相当于在数组中插入一个数据，循环执行n次插入操作，所以平均时间复杂度为O(n2)。 插入即表示将一个新的数据插入到一个有序数组中，并继续保持有序。例如有一个长度为N的无序数组，进行N-1次的插入即能完成排序；第一次，数组第1个数认为是有序的数组，将数组第二个元素插入仅有1个有序的数组中；第二次，数组前两个元素组成有序的数组，将数组第三个元素插入由两个元素构成的有序数组中……第N-1次，数组前N-1个元素组成有序的数组，将数组的第N个元素插入由N-1个元素构成的有序数组中，则完成了整个插入排序。 类似手里有一把排好序的牌，心哪一张和最后一个比较，看能插到前边哪个位置上。 12345678910111213141516171819//时间复杂度O(N^2)， 额外空间复杂度O(1)//实际时间和数据有关系O(N)~O(N^2)// 排好序的数据~逆序数据public class Sort_02_insertSort &#123; public static void insertSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 1; i &lt; arr.length; i++) &#123; for (int j = i - 1; j &gt;= 0 &amp;&amp; arr[j] &gt; arr[j + 1]; j--) &#123; swap(arr, j, j + 1); &#125; &#125; &#125; private static void swap(int[] arr, int i, int j) &#123; arr[i] = arr[i] ^ arr[j]; arr[j] = arr[i] ^ arr[j]; arr[i] = arr[i] ^ arr[j]; &#125;&#125; 选择排序 原地排序算法 稳定的排序算法 最好时间复杂度O(n^2) 最坏时间复杂度O(n^2) 平均时间复杂度O(n^2) 选择排序空间复杂度为O(1)，是一种原地排序算法。选择排序的最好情况时间复杂度、最坏情况和平均情况时间复杂度都为O(n2)。 选择排序是一种不稳定的排序算法。选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样破坏了稳定性。 比如5， 8， 5， 2， 9这样一组数据，使用选择排序算法来排序的话，第一次找到最小元素2，与第一个5交换位置，那第一个5和中间的5顺序就变了，所以就不稳定了。正是因此，相对于冒泡排序和插入排序，选择排序就稍微逊色了。 选择排序也是一种简单直观的排序算法。它的工作原理很容易理解：初始时在序列中找到最小（大）元素，放到序列的起始位置作为已排序序列；然后，再从剩余未排序元素中继续寻找最小（大）元素，放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 注意: 选择排序与冒泡排序的区别：冒泡排序通过依次交换相邻两个顺序不合法的元素位置，从而将当前最小（大）元素放到合适的位置；而选择排序每遍历一次都记住了当前最小（大）元素的位置，最后仅需一次交换操作即可将其放到合适的位置 12345678910111213141516171819//时间复杂度O(N^2)， 额外空间复杂度O(1)public class Sort_03_selectSort &#123; public static void selectSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; for (int i = 0; i &lt; arr.length - 1; i++) &#123; int minIndex = i; for(int j = i + 1; j &lt; arr.length; j++)&#123; minIndex = arr[j] &lt; arr[minIndex] ? j: minIndex; &#125; swap(arr, i, minIndex); &#125; &#125; private static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; 归并排序 原地排序算法 稳定的排序算法 最好时间复杂度O(nlogn) 最坏时间复杂度O(nlogn) 平均时间复杂度O(nlogn) 递归方法的复杂度分析，见另一篇 master公式。 归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。 归并排序是稳定排序，他也是一种十分高效的排序，能利用完全二叉树特性的排序一般性能都不会太差。java中Arrays.sort()采用了一种名为TimSort的排序算法，就是归并排序的优化版本。 从上图中可看出，每次合并操作的平均时间复杂度为O(n)，而完全二叉树的深度为|log2n|。总的平均时间复杂度为O(nlogn)。而且，归并排序的最好，最坏，平均时间复杂度均为O(nlogn)。 12345678910111213141516171819202122232425262728293031323334/** * 归并排序。 * * 时间复杂度O(N*logN)，额外空间复杂度O(N) * * @author Jelly * */public class Sort_04_mergeSort &#123; public static void mergeSort(int[] arr, int l, int r) &#123; if(l == r) return; int mid = l + ((r - l) &gt;&gt; 1); mergeSort(arr, l, mid); mergeSort(arr, mid + 1, r); merge(arr, l, mid, r); &#125; private static void merge(int[] arr, int l, int mid, int r) &#123; int[] help = new int[r - l + 1]; int left = l; int right = mid + 1; int i = 0; while(left &lt;= mid &amp;&amp; right &lt;= r) help[i++] = arr[left] &lt; arr[right] ? arr[left++] : arr[right++]; while(left &lt;= mid) help[i++] = arr[left++]; while(right &lt;= r) help[i++] = arr[right++]; //将help数组拷贝到arr数组中 System.arraycopy(help, 0, arr, l, help.length); &#125;&#125; 快速排序 原地排序算法 稳定的排序算法 最好时间复杂度O(nlogn) 最坏时间复杂度O(n^2) 平均时间复杂度O(nlogn) 归并-快排对比归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。 归并排序虽然是稳定的、时间复杂度为O(nlogn)的排序算法，但是它是非原地排序算法。 我们前面讲过，归并之所以是非原地排序算法，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。 12345678910111213141516171819202122232425262728293031323334353637383940/** * 快速排序。（随机快排） * * 时间复杂度O(N*logN), 额外空间复杂度O(logN) * * @author Jelly * */public class Sort_05_quickSort &#123; public static void quickSort(int[] arr, int l, int r) &#123; if (l &lt; r) &#123; swap(arr, (int) (l + Math.random() * (r - l + 1)), r);// 随机快排，减少出现最坏的情况 int[] p = partition(arr, l, r); quickSort(arr, l, p[0]); quickSort(arr, p[1], r); &#125; &#125; private static int[] partition(int[] arr, int l, int r) &#123; int less = l - 1; int more = r; while(l &lt; more) &#123; if(arr[l] &lt; arr[r]) swap(arr, ++less, l++); else if(arr[l] &gt; arr[r]) swap(arr, --more, l); else l++; &#125; swap(arr, more, r); return new int[] &#123;less, more&#125;; &#125; private static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125;&#125; 非基于比较的排序桶排序 原地排序算法 稳定的排序算法 最好时间复杂度O(n) 最坏时间复杂度O(n) 平均时间复杂度O(n) 如果要排序的数据有n个，我们把它们均匀地划分到m个桶内，每个桶里就有k=n/m个元素。每个桶内部使用快速排序，时间复杂度为O(k * logk)。 m个桶排序的时间复杂度就是O(m * k * logk)，因为k=n/m，所以整个桶排序的时间复杂度就是O(n*log(n/m))。当桶的个数m接近数据个数n时， log(n/m)就是一个非常小的常量，这个时候桶排序的时间复杂度接近O(n)。 核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。 设置一个定量的数组当作空桶。 Divide - 从待排序数组中取出元素，将元素按照一定的规则塞进对应的桶子去。 对每个非空桶进行排序，通常可在塞元素入桶时进行插入排序。 Conquer - 从非空桶把元素再放回原来的数组中。 12345678910111213141516171819202122232425262728293031323334353637/** * 桶排序。 * * N为待排数据，M个桶 * * 平均时间复杂度O(N + C), 其中C = N*(logN-logM)。空间复杂度 O(N+M) * * 对于同样的N，桶的数量M越大，其效率越高。 * * @author Jelly * */public class Sort_07_bucketSort &#123; public static void bucketSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) return; // 找到数组中最大的一个元素 int max = Integer.MIN_VALUE; for (int i = 0; i &lt; arr.length; i++) &#123; max = arr[i] &gt; max ? arr[i] : max; &#125; // 创建一个比最大元素大 1 的桶 int[] bucket = new int[max + 1]; // 遍历数组,将元素做为桶的下标，找到桶的位置.相同的元素，则在当前位置加1 for (int i = 0; i &lt; arr.length; i++) &#123; bucket[arr[i]]++; &#125; // 遍历桶 int i = 0; for (int j = 0; j &lt; bucket.length; j++) &#123; while (bucket[j]-- &gt; 0) &#123; // 该位置桶的value时多少，原数组就有几个该数据 arr[i++] = j; &#125; &#125; &#125;&#125; 计数排序 顾名思义，就是对待排序数组按元素进行计数。使用前提是需要先知道待排序数组的元素范围，将这些一定范围的元素置于新数组中，新数组的大小为待排序数组中最大元素与最小元素的差值。 维基上总结的四个步骤如下： 定新数组大小——找出待排序的数组中最大和最小的元素 统计次数——统计数组中每个值为i的元素出现的次数，存入新数组C的第i项 对统计次数逐个累加——对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加） 反向填充目标数组——将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1 其中反向填充主要是为了避免重复元素落入新数组的同一索引处。 基数排序原理类似桶排序,这里总是需要10个桶,多次使用 首先以个位数的值进行装桶,即个位数为1则放入1号桶,为9则放入9号桶,暂时忽视十位数 例如 待排序数组[62,14,59,88,16]简单点五个数字 分配10个桶,桶编号为0-9,以个位数数字为桶编号依次入桶,变成下边这样 | 0 | 0 | 62 | 0 | 14 | 0 | 16 | 0 | 88 | 59 | | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |桶编号 将桶里的数字顺序取出来, 输出结果:[62,14,16,88,59] 再次入桶,不过这次以十位数的数字为准,进入相应的桶,变成下边这样: 由于前边做了个位数的排序,所以当十位数相等时,个位数字是由小到大的顺序入桶的,就是说,入完桶还是有序 | 0 | 14,16 | 0 | 0 | 0 | 59 | 62 | 0 | 88 | 0 | | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |桶编号 因为没有大过100的数字,没有百位数,所以到这排序完毕,顺序取出即可 最后输出结果:[14,16,59,62,88] 小结 如果对小规模数据进行排序，可以选择时间复杂度是O(n2)的算法；如果对大规模数据进行排序，时间复杂度是O(nlogn)的算法更加高效。 所以，为了兼顾任意规模数据的排序，一般都会首选时间复杂度是O(nlogn)的排序算法来实现排序函数。 工程中使用数据量小于60会使用插入排序原因： 虽然插入排序时间复杂度O(n^2) 但是常数项较小，在数据量小的时候，复杂度不会表现出劣势 数据是基础类型用快排原因： 因为基础类型数据不用区分数据的先后顺序，是无差别的。即基础数据不用关心排序的稳定性。 数据是自定义类型用归并排序归并排序可以保持排序后的稳定性。 堆排序 原地排序算法 稳定的排序算法 最好时间复杂度O(nlogn) 最坏时间复杂度O(nlogn) 平均时间复杂度O(nlogn) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149/** * 大根堆。从0开始的数组。 * 父节点:i；左子节点:2*i+1；右子节点:2*i+2 * 子节点:i；父节点：floor((i-1)/2) */class MaxHeap &#123; /** * 堆数据区 */ private int[] data; /** * 堆中数据数量 */ private int size; /** * 堆最大容量 */ private int capacity; public MaxHeap(int capacity) &#123; this.data = new int[capacity]; this.size = 0; this.capacity = capacity; &#125; /** * 修改了调整堆的方法。从最后的元素开始shiftDown, 每次构建只调整 n/2 次，构建完成即获取到了调整好的大根堆。 * * @param arr 构建堆元数据。 * @param capacity 堆大小 */ public MaxHeap(int[] arr, int capacity) &#123; int arrSize = arr.length; //当arr容量大于给定的capacity时，只存储capacity大小的数据。 if (capacity &lt; arrSize) &#123; arrSize = capacity; &#125; this.data = new int[capacity]; System.arraycopy(arr, 0, this.data, 0, arrSize); this.capacity = capacity; this.size = arrSize; for (int i = size - 1; i &gt;= 0; i--) &#123; shiftDown(i); &#125; &#125; public void insert(int d) &#123; if (size &gt;= capacity) &#123; System.out.println("heap is full!"); return; &#125; //插入堆尾 data[size++] = d; //调整堆 shiftUp(size - 1); &#125; private void shiftUp(int cur) &#123; while (cur &gt; 0) &#123; int p = (cur - 1) / 2; if (data[cur] &gt; data[p]) &#123; swap(data, cur, p); &#125; cur = p; &#125; &#125; public int pop() &#123; if (size == 0) &#123; System.out.println("heap is empty!!"); return -1; &#125; //弹出顶部元素 int t = data[0]; //将最后一个元素换到顶部 data[0] = data[--size]; //将第一个元素下移到适当位置 shiftDown(0); return t; &#125; private void shiftDown(int cur) &#123; int left = cur * 2 + 1; while (left &lt; size) &#123; //找到两个子节点中较大的一个 if (left + 1 &lt; size &amp;&amp; data[left] &lt; data[left + 1]) &#123; left++; &#125; if (data[cur] &gt;= data[left]) &#123; break; &#125; //元素下移 swap(data, cur, left); cur = left; &#125; &#125; private static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125; @Override public String toString() &#123; return "MaxHeap&#123;" + "data=" + Arrays.toString(data) + ", size=" + size + ", capacity=" + capacity + '&#125;'; &#125;&#125;//堆排序public void heapSort(int arr[],MaxHeap heap)&#123; for(int i = 0; i &lt; arr.length; i++)&#123; heap.insert(arr[i]); &#125; for(int i = arr.length-1; i &gt;=0 ; i--)&#123; arr[i] = heap.deleteMax(); &#125;&#125;// 上面的那个堆排序需要先将数组中的数存到堆中，这里的时间复杂度是n(log2n)，// 可以通过改变建堆的过程从而将建堆的时间复杂度变为O(n)级别。//堆排序O(n)+O(nlog2n)public void heapSort2(int arr[])&#123; MaxHeap maxHeap = new MaxHeap(arr,100); for(int i=arr.length-1; i &gt;= 0 ; i--)&#123; arr[i] = maxHeap.deleteMax(); &#125;&#125; 快速排序要比堆排序性能好 堆排序数据访问的方式没有快排友好。对于快速排序来说，数据是顺序访问的。而对于堆排序来说，数据是跳着访问的。 比如，堆排序中，最重要的一个操作就是数据的堆化。比如下面这个例子，对 堆顶节点进行堆化，会依次访问数组下标是$1，2，4，8$的元素，而不是像快速排序那样，局部顺序访问，所以，这样对CPU缓存是不友好的。 对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。 我们在讲排序的时候，提过两个概念，有序度和逆序度。对于基于比较的排序算法来说，整个排序过程就是由两个基本的操作组成的，比较和交换（或移动）。快速排序数据交换的次数不会比逆序度多。 但是堆排序的第一步是建堆，建堆的过程会打乱数据原有的相对先后顺序，导致原数据的有序度降低。比如，对于一组已经有序的数据来说，经过建堆之后，数 据反而变得更无序了。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时间复杂度]]></title>
    <url>%2Falg-timeComplex%2F</url>
    <content type="text"><![CDATA[时间复杂度是衡量算法好坏的重要指标之一。时间复杂度反映的是不确定性样本量的增长对于算法操作所需时间的影响程度，与算法操作是否涉及到样本量以及涉及了几次直接相关。 时间复杂度 时间复杂度是衡量算法好坏的重要指标之一。时间复杂度反映的是不确定性样本量的增长对于算法操作所需时间的影响程度，与算法操作是否涉及到样本量以及涉及了几次直接相关，如遍历数组时时间复杂度为数组长度n（对应时间复杂度为O(n)），而对数据的元操作（如加减乘除与或非等）、逻辑操作（如if判断）等都属于常数时间内的操作（对应时间复杂度O(1)）。 常数时间操作： 一个操作如果和数据量没有关系，每次都子啊固定时间内完成的操作，叫做常数操作。 在化简某算法时间复杂度表达式时需遵循以下规则： 对于同一样本量，可省去低阶次数项，仅保留高阶次数项，如O(n^2)+O(n)可化简为O(n^2)，O(n)+O(1)可化简为O(n) 可省去样本量前的常量系数，如O(2n)可化简为O(n)，O(8)可化简为O(1) 对于不同的不确定性样本量，不能按照上述两个规则进行化简，要根据实际样本量的大小分析表达式增量。如O(logm)+O(n^2)不能化简为O(n^2)或O(logm)。而要视m、n两者之间的差距来化简，比如m&gt;&gt;n时可以化简为O(logm)，因为表达式增量是由样本量决定的。 举个例子例1. 对一个长度为N的数组进行排序： 算法：依次从0—-N-1个数中选出最小的数，放在数组的0位置从1—N-2个数中选出最小的数，放在数组的1位置从2—N-3个数中选出最小的数，放在数组的2位置time=N+(N-1)+(N-2)*+1=(N+1)N/2只要高阶项，不要低阶项，也不要高阶项的系数所以时间复杂度位O（NN） ### 例2. 一个有序数组A，另一个无序数组B，请打印B中所有不在A中的数，A数组的长度为N，B数组的长度为M。 >- 算法1：对于数组B中的每一个数，都在A中通过遍历的方式找一下； >- 算法2：对于数组B中的每一个数，都在A中通过二分的方式查找一下； >- 算法3：先把B中的数进行排序，然后用类似外排的方式打印所有不在A中出现的数。 计算时间复杂度： >> 1、O(M*N) >> 2、 ①对有序的数组，二分查找的时间复杂度O（logN） 底数为2 在1,3,5,6,8,10中找出x L………………R mid=(L+R)/2 ，根据,数组[mid]与x比较大小的结果，确定下一次二分的方向，N个数二分最多能分logN次。 ②所以算法2的时间复杂度为 O（M*logN） >>3、 ①对无序数组使用基于比较的排序算法O(M*logM) ②1,3,5,7,10,16,18;2,4,8,17,20 ….a…………………….b……]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>复杂度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好，陌生人]]></title>
    <url>%2Fhello-stranger%2F</url>
    <content type="text"><![CDATA[#post-js{width:980px;height:630px;color:#0099ff;margin:auto;font-size:25px;font-family:"华文行楷";} 你好, 陌生人]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>杂记</tag>
        <tag>blog</tag>
      </tags>
  </entry>
</search>
